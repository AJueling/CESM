{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xesmf as xe\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cmocean\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file_paper')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from maps import add_cyclic_POP, add_cyclic_rectangular\n",
    "from grid import generate_lats_lons\n",
    "from paths import path_results, path_prace, path_data,\\\n",
    "                  file_ex_ocn_ctrl, file_ex_ocn_lpd,\\\n",
    "                  file_ex_atm_ctrl, file_ex_atm_lpd,\\\n",
    "                  file_RMASK_ocn, file_RMASK_ocn_low\n",
    "from FW_plots import lat_bounds, lons_lats_from_sdict\n",
    "from FW_budget import load_obj\n",
    "from xr_regression import ocn_field_regression, xr_regression_with_stats\n",
    "from obs_cesm_maps import bias_maps\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsh = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False)\n",
    "dsl = xr.open_dataset(file_ex_ocn_lpd, decode_times=False)\n",
    "RMASK_ocn = xr.open_dataarray(file_RMASK_ocn)\n",
    "RMASK_low = xr.open_dataarray(file_RMASK_ocn_low)\n",
    "Atl_MASK_ocn = xr.DataArray(np.in1d(RMASK_ocn, [6,8,9]).reshape(RMASK_ocn.shape),\n",
    "                            dims=RMASK_ocn.dims, coords=RMASK_ocn.coords)\n",
    "Atl_MASK_low = xr.DataArray(np.in1d(RMASK_low, [6,8,9]).reshape(RMASK_low.shape),\n",
    "                            dims=RMASK_low.dims, coords=RMASK_low.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST(x,y) time mean\n",
    "SST_ctrl = xr.open_dataset(f'{path_prace}/SST/SST_yrly_ctrl.nc', decode_times=False).SST.isel(time=slice(200,230)).mean('time')\n",
    "SST_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_lpd.nc' , decode_times=False).isel(time=slice(500-154,530-154)).mean('time')\n",
    "SST_had  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_had.nc' , decode_times=False).isel(time=slice(-30,-1)).mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing geometry\n",
    "lat_lon_high = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False)[['TLAT', 'TLONG']].drop(['ULAT', 'ULONG'])\n",
    "lat_lon_low  = xr.open_dataset(file_ex_ocn_lpd , decode_times=False)[['TLAT', 'TLONG']].drop(['ULAT', 'ULONG'])\n",
    "SST_ctrl = xr.merge([SST_ctrl, lat_lon_high]).to_array()\n",
    "SST_lpd  = xr.merge([SST_lpd , lat_lon_low ]).to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regridding\n",
    "SST_had_ = SST_had.rename({'latitude':'lat', 'longitude':'lon'})\n",
    "\n",
    "# regrid P-E to ECMWF grid\n",
    "SST_ocn = SST_ctrl.rename({'TLAT': 'lat', 'TLONG': 'lon'})\n",
    "SST_low = SST_lpd.rename({'TLAT': 'lat', 'TLONG': 'lon'})\n",
    "\n",
    "# replace NaNs in continents with values from original grid file\n",
    "lats,lons = generate_lats_lons('ocn')\n",
    "SST_ocn['lat'].values = lats\n",
    "SST_ocn['lon'].values = lons\n",
    "\n",
    "regridder_ocn = xe.Regridder(SST_ocn, SST_had_, 'nearest_s2d', reuse_weights=True, periodic=True)\n",
    "regridder_low = xe.Regridder(SST_low, SST_had_, 'nearest_s2d', reuse_weights=True, periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# calculate RCP trends\n",
    "# 52 min for rcp, 40 sec for lr1\n",
    "stats_rcp = xr_regression_with_stats(xr.open_dataarray(f'{path_prace}/SST/SST_yrly_rcp.nc', decode_times=False), fn=f'{path_prace}/SST/SST_yrly_rcp_stats.nc')\n",
    "stats_lr1 = xr_regression_with_stats(xr.open_dataset(f'{path_prace}/SST/SST_yrly_lr1.nc', decode_times=False).SST, fn=f'{path_prace}/SST/SST_yrly_lr1_stats.nc')\n",
    "stats_lr1 = stats_lr1.assign_coords({'TLAT':SST_lpd.TLAT,'TLONG':SST_lpd.TLONG})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_rcp = 365*100*stats_rcp.slope\n",
    "SST_lr1 = 365*100*stats_lr1.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw1 = dict(lat='lat', lon='lon', label='SST  [$\\!^\\circ\\!$C]', cmap=plt.get_cmap('Spectral_r', 32), vmin=-2, vmax=30)\n",
    "kw2 = dict(lat='lat', lon='lon', label='CTRL SST bias  [K]', cmap=plt.get_cmap('bwr', 20), vmin=-5, vmax=5)\n",
    "dh = (regridder_ocn(SST_ocn)-SST_had_).squeeze()\n",
    "dl = (regridder_low(SST_low)-SST_had_).squeeze()\n",
    "weights = np.cos(np.deg2rad(dh.lat))\n",
    "biases = {'HR-CESM':f'mean = {dh.weighted(weights).mean().values:+.2f} K\\nRMSE = {abs(dh).weighted(weights).mean().values:+.2f} K',\n",
    "          'LR-CESM':f'mean = {dl.weighted(weights).mean().values:+.2f} K\\nRMSE = {abs(dl).weighted(weights).mean().values:+.2f} K',\n",
    "         }\n",
    "fn = f'{path_results}/thesis/2_SST_bias'\n",
    "bias_maps(do=SST_had_.squeeze(), dh=dh, dl=dl, kw1=kw1, kw2=kw2, biases=biases, fn=fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P-E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dah = xr.open_dataset(file_ex_atm_ctrl, decode_times=False)\n",
    "dal = xr.open_dataset(file_ex_atm_lpd , decode_times=False)\n",
    "doh = xr.open_mfdataset(f'{path_prace}/ctrl/ocn_yrly_EVAP_F_PREC_F_ROFF_F_*.nc', combine='nested', concat_dim='time', decode_times=False)\n",
    "dol = xr.open_mfdataset(f'{path_prace}/lpd/ocn_yrly_EVAP_F_PREC_F_ROFF_F_*.nc' , combine='nested', concat_dim='time', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai = xr.open_dataset('../../../AMWG/obs_data/EP.ERAI_ANN_climo.nc')  # Budget Evaporation minus Precipitation\n",
    "whoi = xr.open_dataset('../../../AMWG/obs_data/WHOI_ANN_climo.nc')     # monthly mean evaporation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = xr.open_dataset(f'{path_prace}/AMWG/HIGH_CTRL_vs_OBS/diag/spinup_pd_maxcores_f05_t12_ANN_plotvars.nc', decode_times=False)\n",
    "dl = xr.open_dataset(f'{path_prace}/AMWG/LOW_CTRL_vs_OBS/diag/spinup_B_2000_cam5_f09_g16_ANN_plotvars.nc', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid P-E to ECMWF grid\n",
    "PE_ocn = (doh.PREC_F+doh.EVAP_F).rename({'TLAT': 'lat', 'TLONG': 'lon'}).drop(['ULONG', 'ULAT']).mean('time').where(RMASK_ocn>0)\n",
    "PE_low = (dol.PREC_F+dol.EVAP_F).rename({'TLAT': 'lat', 'TLONG': 'lon'}).drop(['ULONG', 'ULAT']).mean('time').where(RMASK_low>0)\n",
    "\n",
    "# replace NaNs in continents with values from original grid file\n",
    "lats,lons = generate_lats_lons('ocn')\n",
    "PE_ocn['lat'].values = lats\n",
    "PE_ocn['lon'].values = lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder_ocn = xe.Regridder(PE_ocn, erai.EP, 'nearest_s2d', reuse_weights=True, periodic=True)\n",
    "regridder_low = xe.Regridder(PE_low, erai.EP, 'nearest_s2d', reuse_weights=True, periodic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erai_ = xr.open_dataset(f'{path_data}/ERAI_E-P/ERAI.EP.1979-2016.t-106.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PmE = minus = r'$P - E$'\n",
    "kw1 = dict(lat='lat', lon='lon', label=f'{PmE}  [mm/d]', cmap=plt.get_cmap('cmo.tarn', 40), vmin=-8, vmax=8)\n",
    "kw2 = dict(lat='lat', lon='lon', label=f'CTRL {PmE} bias  [mm/d]', cmap=plt.get_cmap('PuOr',40), vmin=-4, vmax=4)\n",
    "do = -erai.EP.squeeze()*3600*24\n",
    "do.data = gaussian_filter(do, sigma=1)  # otherwise checkerboard pattern\n",
    "dh = regridder_ocn(PE_ocn).values*3600*24 - do\n",
    "dl = regridder_low(PE_low).values*3600*24 - do\n",
    "weights = np.cos(np.deg2rad(dh.lat))\n",
    "biases = {'HR-CESM':f'mean = {dh.weighted(weights).mean().values:+.2f} mm/d\\nRMSE = {abs(dh).weighted(weights).mean().values:+.2f} mm/d',\n",
    "          'LR-CESM':f'mean = {dl.weighted(weights).mean().values:+.2f} mm/d\\nRMSE = {abs(dl).weighted(weights).mean().values:+.2f} mm/d',\n",
    "         }\n",
    "fn = f'{path_results}/thesis/2_P-E_bias'\n",
    "bias_maps(do=do, dh=dh, dl=dl, kw1=kw1, kw2=kw2, biases=biases, fn=fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langle, rangle, deg = r'$\\langle$', r'$\\rangle$', r'$^{\\!\\circ}\\!$'\n",
    "y1 = np.tanh((np.linspace(0,1, 64)-.5)*4)/2+.5 # nonlinear sampling to enhance center of colormap\n",
    "y2 = np.tanh((np.linspace(0,1, 64)-.5)*3)/2+.5 # nonlinear sampling to enhance center of colormap\n",
    "\n",
    "colors1 = cmocean.tools.crop_by_percent(cmocean.cm.dense, 10, which='max', N=None)(np.linspace(0., 1, 128))\n",
    "colors2 = cmocean.tools.crop_by_percent(cmocean.cm.solar, 10, which='min', N=None)(np.linspace(0, 1, 128))\n",
    "colors = np.vstack((colors1, colors2))\n",
    "mymap  = matplotlib.colors.LinearSegmentedColormap.from_list('my_colormap', colors)(y1)\n",
    "mycmap = matplotlib.colors.LinearSegmentedColormap.from_list('my_colormap', mymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALT_mean_orig = xr.open_dataset(f'{path_prace}/EN4/EN4_mean.nc').salinity\n",
    "SALT_mean_ctrl = xr.open_dataarray(f'{path_prace}/ctrl/SALT_mean_ctrl_200-229.nc')\n",
    "SALT_mean_high = xr.open_dataarray(f'{path_prace}/EN4/EN4_mean_salinity_high.nc')\n",
    "SALT_mean_lpd  = xr.open_dataarray(f'{path_prace}/lpd/SALT_mean_lpd_500-529.nc')\n",
    "SALT_mean_low  = xr.open_dataarray(f'{path_prace}/EN4/EN4_mean_salinity_low.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_high = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False).dz\n",
    "dz_low  = xr.open_dataset(file_ex_ocn_lpd , decode_times=False).dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALT_mean_ctrl_top100m = (SALT_mean_ctrl*dz_high).isel(z_t=slice(0,9)).sum('z_t')/dz_high.isel(z_t=slice(0,9)).sum('z_t')\n",
    "SALT_mean_high_top100m = (SALT_mean_high*dz_high).isel(z_t=slice(0,9)).sum('z_t')/dz_high.isel(z_t=slice(0,9)).sum('z_t')\n",
    "SALT_mean_lpd_top100m  = (SALT_mean_lpd *dz_low).isel(z_t=slice(0,10)).sum('z_t')/dz_low.isel(z_t=slice(0,10)).sum('z_t')\n",
    "SALT_mean_low_top100m  = (SALT_mean_low *dz_low).isel(z_t=slice(0,10)).sum('z_t')/dz_low.isel(z_t=slice(0,10)).sum('z_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PmE = minus = r'$P - E$'\n",
    "kw1 = dict(lat='TLAT', lon='TLONG', label='top 100 m salinity  [1]', cmap=mycmap, vmin=31, vmax=39)\n",
    "kw2 = dict(label='top 100 m salinity CTRL bias  [1]', cmap=plt.get_cmap('BrBG_r', 30), vmin=-1.5, vmax=1.5)\n",
    "do = SALT_mean_high_top100m.where(RMASK_ocn>0)\n",
    "dh = (SALT_mean_ctrl_top100m-SALT_mean_high_top100m).where(RMASK_ocn>0)\n",
    "dl = add_cyclic_POP((SALT_mean_lpd_top100m-SALT_mean_low_top100m).where(RMASK_low>0))\n",
    "biases = {'HR-CESM':f'mean = {dh.weighted(dsh.TAREA).mean().values:+.2f}\\nRMSE = {abs(dh).weighted(dsh.TAREA).mean().values:+.2f}',\n",
    "          'LR-CESM':f'mean = {dl.weighted(add_cyclic_POP(dsl.TAREA)).mean().values:+.2f}\\nRMSE = {abs(dl).weighted(add_cyclic_POP(dsl.TAREA)).mean().values:+.2f}',\n",
    "         }\n",
    "fn = f'{path_results}/thesis/2_salinity_bias'\n",
    "bias_maps(do=do, dh=dh, dl=dl, kw1=kw1, kw2=kw2, biases=biases, fn=fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## std(SSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cesm_dict = dict(concat_dim='time', decode_times=False, combine='nested')\n",
    "obs_dict = dict(combine='nested', concat_dim='Time', chunks={'Latitude':96, 'Longitude':270, 'Time':73})\n",
    "ctrl = xr.open_mfdataset(file_ex_ocn_ctrl[:-5]+'*.nc', **cesm_dict).mean('time')\n",
    "lpd = xr.open_mfdataset(file_ex_ocn_lpd[:-5]+'*.nc', **cesm_dict).mean('time')\n",
    "obs = xr.open_mfdataset(f'{path_prace}/SSH/ssh_grids_v1812_*.nc', **obs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_std = np.sqrt(np.abs(ctrl.SSH2-ctrl.SSH**2))\n",
    "ctrl_std = ctrl_std.where(RMASK_ocn!=-1)\n",
    "lpd_std = np.sqrt(lpd.SSH2-lpd.SSH**2)\n",
    "obs_std = np.sqrt((obs.SLA**2).mean('Time')-obs.SLA.mean('Time')**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = ctrl_std.weighted(dsh.TAREA).mean().compute().values\n",
    "ml = lpd_std.weighted(dsl.TAREA).mean().compute().values\n",
    "mo = obs_std.weighted(np.cos(np.deg2rad(obs_std.Latitude))).mean().compute().values*100\n",
    "means = {'OBS'    :f'mean = {mo:+.2f} cm',\n",
    "         'HR-CESM':f'mean = {mh:+.2f} cm',\n",
    "         'LR-CESM':f'mean = {ml:+.2f} cm',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kw = dict(lat='Latitude', lon='Longitude', label='std(SSH)  [cm]', cmap='viridis', vmin=2, vmax=64, log=True, ticks = [2**x for x in range(1,7)])\n",
    "bias_maps(do=obs_std.T*100, dh=ctrl_std, dl=add_cyclic_POP(lpd_std), kw1=kw, kw2=None, biases=means, fn=f'{path_results}/thesis/2_std_SSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
