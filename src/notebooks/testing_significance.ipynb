{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "from timeseries import lowpass\n",
    "from xr_regression import lag_linregress_3D\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation significance testing under filtering\n",
    "We always expect distribution of p-values to be uniform in [0,1] when randomly generated time series are correlated.\n",
    "For example, for an x% threshold, ca. x% of correlations should be randomly \"significant\" under that threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating artifical time series; methods to calculate d.o.f. reduction; MC experiment + visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AR1(n):\n",
    "    AR_object = ArmaProcess(np.array([1, -.9]), np.array([1]))\n",
    "    return AR_object.generate_sample(nsample=n)\n",
    "\n",
    "def AR1_03(n):\n",
    "    AR_object = ArmaProcess(np.array([1, -.3]), np.array([1]))\n",
    "    return AR_object.generate_sample(nsample=n)\n",
    "    \n",
    "def white_noise(n):\n",
    "    return np.random.rand(n)\n",
    "\n",
    "def filtered_noise_5(n):\n",
    "    return lowpass(np.random.rand(n), 5)\n",
    "\n",
    "def filtered_noise_10(n):\n",
    "    return lowpass(np.random.rand(n), 10)\n",
    "\n",
    "def filtered_noise_20(n):\n",
    "    return lowpass(np.random.rand(n), 20)\n",
    "\n",
    "def filtered_AR1(n):\n",
    "    return lowpass(AR1(n), 10)\n",
    "\n",
    "def filtered_AR1_03(n):\n",
    "    return lowpass(AR1_03(n), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dof_filter(x, y, cutoffs):\n",
    "    if type(cutoffs)==tuple:\n",
    "        red_dof = 1./min(cutoffs)\n",
    "    else:\n",
    "        red_dof = 1\n",
    "    return red_dof\n",
    "\n",
    "def dof_ac_x(x, y, cutoffs=None):\n",
    "    rx = np.corrcoef(x[1:], x[:-1])[0,1]\n",
    "    return (1-abs(rx))/(1+abs(rx))*2\n",
    "\n",
    "def dof_ac_y(x, y, cutoffs=None):\n",
    "    ry = np.corrcoef(y[1:], y[:-1])[0,1]\n",
    "    return (1-abs(ry))/(1+abs(ry))*2\n",
    "\n",
    "def dof_ac_xy(x, y, cutoffs=None):\n",
    "    rx = np.corrcoef(x[1:], x[:-1])[0,1]\n",
    "    ry = np.corrcoef(y[1:], y[:-1])[0,1]\n",
    "    return (1-abs(rx*ry))/(1+abs(rx*ry))\n",
    "\n",
    "def dof_choose_max(x, y, cutoffs=None):\n",
    "    dof1 = dof_ac_xy(x, y, cutoffs=None)\n",
    "    dof2 = dof_filter(x, y, cutoffs)\n",
    "    return max(dof1, dof2)\n",
    "\n",
    "def dof_choose_min(x, y, cutoffs=None):\n",
    "    dof1 = dof_ac_xy(x, y, cutoffs=None)\n",
    "    dof2 = dof_filter(x, y, cutoffs)\n",
    "    return min(dof1, dof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(A):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "    ax[0].hist(A[0,0,:], alpha=.4, label='n=100');\n",
    "    ax[0].hist(A[0,1,:], alpha=.4, label='n=1000');\n",
    "    ax[0].legend();\n",
    "\n",
    "    ax[1].hist(A[1,0,:], alpha=.4);\n",
    "    ax[1].hist(A[1,1,:], alpha=.4);\n",
    "\n",
    "def significance_experiment(fcn1, fcn2, cutoffs=None, red_dof=None):\n",
    "    if red_dof is None:\n",
    "        red_dof = 1\n",
    "    A = np.zeros((2, 2, 1000))\n",
    "    for l, length in enumerate([100, 1000]):\n",
    "        x = xr.DataArray(data=np.zeros((length)), coords={'time':range(length)}, dims='time' )\n",
    "        y = xr.DataArray(data=np.zeros((length)), coords={'time':range(length)}, dims='time' )\n",
    "        for i in range(1000):\n",
    "            x.values = fcn1(length)\n",
    "            y.values = fcn2(length)\n",
    "            if callable(red_dof)==True:\n",
    "                dof_corr = red_dof(x, y, cutoffs)\n",
    "            else:\n",
    "                dof_corr = red_dof\n",
    "            ds = lag_linregress_3D(x, y, dof_corr=dof_corr)\n",
    "            A[0,l,i] = ds.cor\n",
    "            A[1,l,i] = ds.pval\n",
    "    plot_results(A)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: correlate two white noise random time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(white_noise, white_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: effects of filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.1: correlate two filtered time series\n",
    "shwoing that we have to use reduced degrees of freedom in calculation of t-statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, filtered_noise_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with filtered data, $N'=N\\frac{\\Delta T}{T_0}$ with $T_0=10$ being the cutoff period and $\\Delta T=1$ in the following case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, filtered_noise_10, cutoffs=(10,10), red_dof=dof_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.2: correlate one filtered with one unfiltered time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, white_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.3: two different filter cutoff periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, filtered_noise_20, cutoffs=(5,20), red_dof=dof_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the higher of the two reduced numbers of freedom results in somewhat overestimated p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 2.4: Does the AR dof estimation method work for filtered time series? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, filtered_noise_20, red_dof=dof_ac_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: autocorrelated time series from AR(1) process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with autocorrelation, one needs to apply a correction for the dof:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp. 3.1: two AR(1) with $r=0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(AR1, AR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(AR1, AR1, red_dof=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(AR1, AR1, red_dof=dof_ac_x)  # same as `dof_ac_y`\n",
    "# this is by chance correct, I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(AR1, AR1, red_dof=dof_ac_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp. 3.2: two different $r$-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(AR1, AR1_03, red_dof=dof_ac_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: one AR(1) time series and one filtered time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, AR1_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the `dof_ac_xy` estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, AR1_03, red_dof=dof_ac_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, AR1, red_dof=dof_ac_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the `dof_filter` estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, AR1_03, cutoffs=(5,), red_dof=dof_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, AR1, cutoffs=(5,), red_dof=dof_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compromise: choose maximum of DOF correction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, AR1_03, cutoffs=(10,), red_dof=dof_choose_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_10, AR1_03, cutoffs=(10,), red_dof=dof_choose_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, AR1, cutoffs=(5,), red_dof=dof_choose_max)  # this went wrng with `ac_xy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_5, AR1, cutoffs=(5,), red_dof=dof_choose_min)  # this went wrng with `ac_xy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_20, AR1_03, cutoffs=(20,), red_dof=dof_choose_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_noise_20, AR1_03, cutoffs=(20,), red_dof=dof_choose_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1, AR1_03, cutoffs=(10,), red_dof=dof_choose_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1, AR1_03, cutoffs=(10,), red_dof=dof_choose_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1_03, AR1_03, cutoffs=(10,), red_dof=dof_choose_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1_03, AR1_03, cutoffs=(10,), red_dof=dof_choose_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1_03, AR1, cutoffs=(10,), red_dof=dof_choose_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_experiment(filtered_AR1_03, AR1, cutoffs=(10,), red_dof=dof_choose_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this somewhat underestimates the p-tails it seems, i.e. something does not show up as significant when in fact it would be under a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
