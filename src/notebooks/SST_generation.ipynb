{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import path_samoc, path_results\n",
    "from timeseries import IterateOutputCESM\n",
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bc_analysis_fields import AnalyzeField as AF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. generating full SST fields\n",
    "### annual: from yearly TEMP_PD averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 mins for ctrl\n",
    "for run in ['ctrl', 'lpd', 'had']:\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_yrly_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        DS().generate_yrly_SST_files(run)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly: from monthly averaged model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# DS.generate_monthly_SST_files('ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 22 sec for ctrl, 11 sec for lpd\n",
    "# DS.generate_monthly_mock_linear_GMST_files('lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. detrending/deseasonalizing\n",
    "### full SST time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ctrl: 2:40 mins for 149 years\n",
    "# lpd: < 1 min for 149 years\n",
    "# had: 4:38 mins for both single and two factor detrending\n",
    "for run in ['ctrl', 'lpd']:\n",
    "    print(run)\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_sldt_yrly_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'  file exists: {fn}')\n",
    "    except:\n",
    "        DS().SST_remove_forced_signal(run=run, tres='yrly', detrend_signal='GMST', time_slice='full')\n",
    "    \n",
    "print('had')\n",
    "try:\n",
    "    for dt in ['sfdt', 'tfdt']:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_{dt}_yrly_had.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'  file exists: {fn}')\n",
    "except:\n",
    "    DS().SST_remove_forced_signal(run='had', tres='yrly', detrend_signal='GMST', time_slice='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over 149 year long segments 10 years apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting years of 149 year long segments\n",
    "ctrl_starts = np.arange(1, 152, 10)\n",
    "lpd_starts = np.arange(154, 415, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ctrl_starts:\n",
    "#     print(t, t+148)\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_sldt_yrly_ctrl_{t}_{t+148}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        DS().SST_remove_forced_signal(run='ctrl', tres='yrly', detrend_signal='GMST', time_slice=(t,t+148))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in lpd_starts:\n",
    "#     print(t, t+148)\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_sldt_yrly_lpd_{t}_{t+148}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        DS().SST_remove_forced_signal(run='lpd', tres='yrly', detrend_signal='GMST', time_slice=(t,t+148))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. derive raw SST indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bd_analysis_indices import AnalyzeIndex as AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ca. 1:10 min for single ctrl run, 8:45 for all\n",
    "# 11 seconds for lpd and had combined\n",
    "for run in ['had',  'lpd', 'ctrl']:\n",
    "    if run in ['ctrl', 'lpd']:  dt = 'sldt'\n",
    "    elif run=='rcp':            dt = 'sqdt'\n",
    "    elif run=='had':            dt = 'tfdt'  # 'sfdt'\n",
    "    \n",
    "    try:\n",
    "        for idx in ['AMO', 'SOM', 'TPI1', 'TPI2', 'TPI3']:\n",
    "            fn = f'{path_samoc}/SST/{idx}_GMST_{dt}_raw_{run}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "        print(f'raw index files for {run} exist')\n",
    "    except:\n",
    "        AI().derive_all_SST_avg_indices(run, 'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            for idx in ['AMO', 'SOM', 'TPI1', 'TPI2', 'TPI3']:\n",
    "                fn = f'{path_samoc}/SST/{idx}_GMST_sldt_raw_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                assert os.path.exists(fn)\n",
    "            print(f'raw index files for {run} of segment {tslice} exist')\n",
    "        except:\n",
    "            AI().derive_all_SST_avg_indices(run, tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. filter SST indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 sec\n",
    "for run in ['ctrl', 'lpd', 'had']:\n",
    "    AI().derive_final_SST_indices(run=run, tslice='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 7 sec\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            for idx in ['AMO', 'SOM', 'TPI']:\n",
    "                fn = f'{path_samoc}/SST/{idx}_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                assert os.path.exists(fn)\n",
    "            print(f'filtered index files for {run} of segment {tslice} exist')\n",
    "        except:\n",
    "            AI().derive_final_SST_indices(run, tslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    f, ax = plt.subplots(3, 1, figsize=(8,8), sharex=True)\n",
    "    ax[2].set_xlabel('time [year]', fontsize=14)\n",
    "    for j, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        for k, t in enumerate([ctrl_starts, lpd_starts][i]):\n",
    "            tslice = (t, t+148)\n",
    "            fn = f'{path_samoc}/SST/{idx}_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "            da = xr.open_dataarray(fn)\n",
    "            ax[j].plot(da[7:-7].time/365, da[7:-7], c=f'C{k%10}')\n",
    "            ax[j].plot(da[:7].time/365, da[:7]  , ls=':', c=f'C{k%10}')\n",
    "            ax[j].plot(da[-7:].time/365, da[-7:], ls=':', c=f'C{k%10}')\n",
    "        ax[j].set_ylabel(idx, fontsize=14)\n",
    "        ax[j].axhline(0, c='k', lw=.5)\n",
    "        ax[j].tick_params(labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path_results}/SST/SST_indices_segments_lowpass13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autocorrelation fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 5:40 mins for all\n",
    "# 2:17 for all lpd and had\n",
    "for run in ['ctrl']:  # 'lpd', 'had'\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_autocorrelation_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        AI().derive_yrly_autocorrelations(run, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3 mins for 149 year segment of ctrl\n",
    "for i, run in enumerate(['ctrl', 'lpd']): #\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            fn = f'{path_samoc}/SST/SST_autocorrelation_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "            print(f'file exists: {fn}')\n",
    "        except:\n",
    "            AI().derive_yrly_autocorrelations(run, tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 sec for  lpd\n",
    "# 4 sec for had\n",
    "for run in ['lpd', 'had']:  # ctrl autocorrelation file does not exist for full\n",
    "    try:\n",
    "        for idx in ['AMO', 'SOM', 'TPI']:\n",
    "            fn = f'{path_samoc}/SST/{idx}_regr_{run}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "        print(f'regression files for {run} exist')\n",
    "    except:\n",
    "        AI().make_yrly_regression_files(run, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ca. 5 mins mins for 149 year segment of ctrl\n",
    "# 3 sec for lpd, 1:30 mins for all\n",
    "for i, run in enumerate(['ctrl', 'lpd']): #\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            for idx in ['AMO', 'SOM', 'TPI']:\n",
    "                fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                assert os.path.exists(fn)\n",
    "            print(f'regression files for {run} of segment {tslice} exist')\n",
    "        except:\n",
    "            AI().make_yrly_regression_files(run, tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pattern correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import file_ex_ocn_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ? for 149 year segment of ctrl\n",
    "# 1 mins for all lpd\n",
    "\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    region = [{'longitude':slice(-80,0), 'latitude':slice(60,0)}, 1, 2][i]\n",
    "    had   = xr.open_dataset(f'{path_samoc}/SST/{idx}_regr_had.nc').slope\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):  \n",
    "        starts = [ctrl_starts, lpd_starts][j]\n",
    "        fn_new = f'{path_samoc}/SST/{idx}_spatial_correlations_{run}.nc'\n",
    "        \n",
    "        try:\n",
    "            assert os.path.exists(fn_new)\n",
    "            print(f'file exists: {fn_new}')\n",
    "        except:\n",
    "            da = xr.DataArray(data=np.zeros(len(starts)),\n",
    "                          coords={'time': starts},\n",
    "                          dims=('time'))\n",
    "            if run=='ctrl':\n",
    "                TLAT = xr.open_dataset(file_ex_ocn_ctrl,\\\n",
    "                                       decode_times=False).TLAT.coords['TLAT']\n",
    "            for k, t in enumerate(starts):\n",
    "                tslice = (t, t+148)\n",
    "                fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                segment = xr.open_dataset(fn).slope\n",
    "                if run=='ctrl':\n",
    "                    segment.coords['TLAT'] = TLAT\n",
    "                da.values[k] = AF().spatial_correlation(field_A=had, field_B=segment,\n",
    "                                                        selection=region)\n",
    "                da.to_netcdf(fn_new)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10,5), sharey=True)\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):  # , \n",
    "        fn = f'{path_samoc}/SST/{idx}_spatial_correlations_{run}.nc'\n",
    "        da = xr.open_dataarray(fn)\n",
    "        da.plot(label=idx, ax=ax[j])\n",
    "        ax[j].set_xlabel('starting year of segment', fontsize=14)\n",
    "        ax[j].text(da.time[0], .7, run.upper(), fontsize=14)\n",
    "    for j in range(2):\n",
    "        ax[j].tick_params(labelsize=14)\n",
    "        ax[j].axhline(0, c='k', lw=.5)\n",
    "    \n",
    "    \n",
    "ax[0].axvline(100, c='grey', lw=.5)\n",
    "ax[0].axvline(151, c='grey', lw=.5)\n",
    "ax[1].axvline(268, c='grey', lw=.5)\n",
    "\n",
    "ax[0].legend(fontsize=14, ncol=3, loc=8)\n",
    "ax[0].set_ylabel('spatial correlation coefficient', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{path_results}/SST/spatial_correlation(t)_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
