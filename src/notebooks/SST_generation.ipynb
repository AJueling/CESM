{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot\n",
    "matplotlib.rc_file('rc_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import path_samoc, path_results, file_ex_ocn_ctrl\n",
    "from timeseries import IterateOutputCESM\n",
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bc_analysis_fields import AnalyzeField as AF\n",
    "from bd_analysis_indices import AnalyzeIndex as AI\n",
    "from xr_regression import xr_quadtrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. generating full SST fields\n",
    "### annual: from yearly TEMP_PD averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 mins for ctrl\n",
    "for run in ['ctrl', 'lpd', 'had']:\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_yrly_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        DS().generate_yrly_SST_files(run)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in ['ctrl', 'lpd']:\n",
    "    plt.figure()\n",
    "    da = xr.open_dataarray(f'{path_samoc}/SST/SST_yrly_{run}.nc', decode_times=False)\n",
    "    da[0,:,:].plot(vmin=-1.8, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly: from monthly averaged model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# DS.generate_monthly_SST_files('ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 22 sec for ctrl, 11 sec for lpd\n",
    "# DS.generate_monthly_mock_linear_GMST_files('lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. detrending/deseasonalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 1:32 min for both\n",
    "for run in ['ctrl', 'lpd']:\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/GMSST_yrly_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        DS().generate_yrly_global_mean_SST(run=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in ['ctrl', 'lpd']:\n",
    "    da = xr.open_dataarray(f'{path_samoc}/SST/GMSST_yrly_{run}.nc')\n",
    "    plt.plot(da.time/365, da, lw=.5)\n",
    "    if run=='ctrl':  x = da[40:]\n",
    "    else:            x = da    \n",
    "    pf = np.polynomial.polynomial.polyfit(x.time, x, 2)\n",
    "    plt.plot(x.time/365, pf[2]*x.time**2 + pf[1]*x.time + pf[0])\n",
    "#     plt.axvline(40, c='grey', lw=.5)\n",
    "    plt.ylabel('global mean SST [$^\\circ$C]')\n",
    "    plt.xlabel('time [years]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 6:16 for both ctrl and lpd\n",
    "# ctrl: 2:40 mins for 149 years\n",
    "# lpd: < 1 min for 149 years\n",
    "# had: 4:38 mins for both single and two factor detrending\n",
    "for run in ['ctrl', 'lpd']:\n",
    "    print(run)\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_sqdt_yrly_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'  file exists: {fn}')\n",
    "    except:\n",
    "        DS().SST_remove_forced_signal(run=run, tres='yrly', detrend_signal='GMST', time_slice='full')\n",
    "    \n",
    "print('had')\n",
    "try:\n",
    "    for dt in ['sfdt', 'tfdt']:\n",
    "        fn = f'{path_samoc}/SST/SST_GMST_{dt}_yrly_had.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'  file exists: {fn}')\n",
    "except:\n",
    "    DS().SST_remove_forced_signal(run='had', tres='yrly', detrend_signal='GMST', time_slice='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, run in enumerate(['ctrl', 'lpd', 'had']):\n",
    "#     dt = ['sqdt', 'sqdt', 'tfdt'][i]\n",
    "#     fn = f'{path_samoc}/SST/SST_GMST_{dt}_yrly_{run}.nc'\n",
    "#     assert os.path.exists(fn)\n",
    "#     if run=='ctrl':\n",
    "#         AREA = xr_AREA(domain='ocn')\n",
    "#         REGION_MASK = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False).REGION_MASK\n",
    "#     elif run=='lpd':\n",
    "#         AREA = xr_AREA(domain='ocn_low')\n",
    "#         REGION_MASK = xr.open_dataset(file_ex_ocn_lpd, decode_times=False).REGION_MASK\n",
    "#     elif run=='had':\n",
    "#         AREA = xr_AREA(domain='ocn_low')\n",
    "#         REGION_MASK = xr.open_dataset(file_ex_ocn_lpd, decode_times=False).REGION_MASK\n",
    "#     da = xr.open_dataarray(fn, decode_times=False)\n",
    "#     da.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over 149 year long segments 10 years apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting years of 149 year long segments\n",
    "ctrl_starts = np.arange(1, 152, 10)\n",
    "lpd_starts = np.arange(154, 415, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. derive raw SST indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ca. 1:10 min for single ctrl run, 8:45 for all\n",
    "# 11 seconds for lpd and had combined\n",
    "for run in ['had',  'lpd', 'ctrl']:\n",
    "    if run=='had':\n",
    "        dt = 'tfdt'  # two-factor detrending, or 'sfdt' single-factor detrending\n",
    "    elif run in ['ctrl', 'lpd', 'rcp']:\n",
    "        dt = 'sqdt'  # scaled quadratic detrending\n",
    "    \n",
    "    try:\n",
    "        for idx in ['AMO', 'SOM', 'TPI1', 'TPI2', 'TPI3']:\n",
    "            fn = f'{path_samoc}/SST/{idx}_GMST_{dt}_raw_{run}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "        print(f'raw index files for {run} exist')\n",
    "    except:\n",
    "        AI().derive_all_SST_avg_indices(run, 'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. filter SST indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 sec\n",
    "for run in ['ctrl', 'lpd', 'had']:\n",
    "    AI().derive_final_SST_indices(run=run, tslice='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 7 sec\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            for idx in ['AMO', 'SOM', 'TPI']:\n",
    "                fn = f'{path_samoc}/SST/{idx}_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                assert os.path.exists(fn)\n",
    "            print(f'filtered index files for {run} of segment {tslice} exist')\n",
    "        except:\n",
    "            AI().derive_final_SST_indices(run, tslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(['ctrl', 'lpd', 'had']):\n",
    "    f, ax = plt.subplots(3, 1, figsize=(8,8), sharex=True)\n",
    "    ax[2].set_xlabel('time [year]', fontsize=14)\n",
    "    for j, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        if run=='had':\n",
    "            fn = f'{path_samoc}/SST/{idx}_{run}.nc'\n",
    "            da = xr.open_dataarray(fn)\n",
    "            ax[j].plot(da[7:-7].time/365+1870, da[7:-7], c=f'C{k%10}')\n",
    "            ax[j].plot(da[:7].time/365+1870, da[:7]  , ls=':', c=f'C{k%10}')\n",
    "            ax[j].plot(da[-7:].time/365+1870, da[-7:], ls=':', c=f'C{k%10}')\n",
    "        elif run in ['ctrl', 'lpd']:\n",
    "            for k, t in enumerate([ctrl_starts, lpd_starts][i]):\n",
    "                tslice = (t, t+148)\n",
    "                fn = f'{path_samoc}/SST/{idx}_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                da = xr.open_dataarray(fn)\n",
    "                ax[j].plot(da[7:-7].time/365, da[7:-7], c=f'C{k%10}')\n",
    "                ax[j].plot(da[:7].time/365, da[:7]  , ls=':', c=f'C{k%10}')\n",
    "                ax[j].plot(da[-7:].time/365, da[-7:], ls=':', c=f'C{k%10}')\n",
    "        ax[j].set_ylabel(idx, fontsize=14)\n",
    "        ax[j].axhline(0, c='k', lw=.5)\n",
    "        ax[j].tick_params(labelsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path_results}/SST/SST_indices_segments_lowpass13_{run}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autocorrelation fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 5:40 mins for all\n",
    "# 2:17 for all lpd and had\n",
    "for run in ['ctrl']:  # 'lpd', 'had'\n",
    "    try:\n",
    "        fn = f'{path_samoc}/SST/SST_autocorrelation_{run}.nc'\n",
    "        assert os.path.exists(fn)\n",
    "        print(f'file exists: {fn}')\n",
    "    except:\n",
    "        AI().derive_yrly_autocorrelations(run, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 3 mins for 149 year segment of ctrl\n",
    "for i, run in enumerate(['ctrl', 'lpd']): #\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            fn = f'{path_samoc}/SST/SST_autocorrelation_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "            print(f'file exists: {fn}')\n",
    "        except:\n",
    "            AI().derive_yrly_autocorrelations(run, tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 sec for  lpd\n",
    "# 4 sec for had\n",
    "for run in ['lpd', 'had']:  # ctrl autocorrelation file does not exist for full\n",
    "    try:\n",
    "        for idx in ['AMO', 'SOM', 'TPI']:\n",
    "            fn = f'{path_samoc}/SST/{idx}_regr_{run}.nc'\n",
    "            assert os.path.exists(fn)\n",
    "        print(f'regression files for {run} exist')\n",
    "    except:\n",
    "        AI().make_yrly_regression_files(run, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maps import regr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, run in enumerate([ 'lpd', 'had']):  # 'ctrl',\n",
    "    if run=='ctrl':\n",
    "        TLAT = xr.open_dataset(file_ex_ocn_ctrl,\\\n",
    "                                       decode_times=False).TLAT.coords['TLAT']\n",
    "    for idx in ['AMO', 'SOM', 'TPI']:\n",
    "        print(run, idx)\n",
    "        if run in ['lpd', 'had']:  # full run\n",
    "            fn = f'{path_samoc}/SST/{idx}_regr_{run}.nc'\n",
    "            ds = xr.open_dataset(fn)\n",
    "            fn_new = f'{path_results}/SST/{idx}_regr_map_{run}'\n",
    "            regr_map(ds, index=idx, run='had', fn=fn_new)\n",
    "        if run in ['ctrl', 'lpd']:  # segments\n",
    "            for t in [ctrl_starts, lpd_starts][i]:\n",
    "                tslice = (t, t+148)\n",
    "                fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                ds = xr.open_dataset(fn)\n",
    "                if run=='ctrl':\n",
    "                    ds.coords['TLAT'] = TLAT\n",
    "                fn_new = f'{path_results}/SST/{idx}_regr_map_{run}_{tslice[0]}_{tslice[1]}'\n",
    "                regr_map(ds, index=idx, run='had', fn=fn_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ca. 5 mins mins for 149 year segment of ctrl\n",
    "# 3 sec for lpd, 1:30 mins for all\n",
    "for i, run in enumerate(['ctrl', 'lpd']): #\n",
    "    for t in [ctrl_starts, lpd_starts][i]:\n",
    "        tslice = (t, t+148)\n",
    "        try:\n",
    "            for idx in ['AMO', 'SOM', 'TPI']:\n",
    "                fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                assert os.path.exists(fn)\n",
    "            print(f'regression files for {run} of segment {tslice} exist')\n",
    "        except:\n",
    "            AI().make_yrly_regression_files(run, tslice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pattern correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ? for 149 year segment of ctrl\n",
    "# 1 mins for all lpd\n",
    "\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    region = [{'longitude':slice(-80,0), 'latitude':slice(60,0)}, 1, 2][i]\n",
    "    had   = xr.open_dataset(f'{path_samoc}/SST/{idx}_regr_had.nc').slope\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):  \n",
    "        starts = [ctrl_starts, lpd_starts][j]\n",
    "        fn_new = f'{path_samoc}/SST/{idx}_spatial_correlations_{run}.nc'\n",
    "        \n",
    "        try:\n",
    "            assert os.path.exists(fn_new)\n",
    "            print(f'file exists: {fn_new}')\n",
    "        except:\n",
    "            da = xr.DataArray(data=np.zeros(len(starts)),\n",
    "                          coords={'time': starts},\n",
    "                          dims=('time'))\n",
    "            if run=='ctrl':\n",
    "                TLAT = xr.open_dataset(file_ex_ocn_ctrl,\\\n",
    "                                       decode_times=False).TLAT.coords['TLAT']\n",
    "            for k, t in enumerate(starts):\n",
    "                tslice = (t, t+148)\n",
    "                fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "                segment = xr.open_dataset(fn).slope\n",
    "                if run=='ctrl':\n",
    "                    segment.coords['TLAT'] = TLAT\n",
    "                da.values[k] = AF().spatial_correlation(field_A=had, field_B=segment,\n",
    "                                                        selection=region)\n",
    "                da.to_netcdf(fn_new)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10,5), sharey=True)\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):  # , \n",
    "        fn = f'{path_samoc}/SST/{idx}_spatial_correlations_{run}.nc'\n",
    "        da = xr.open_dataarray(fn)\n",
    "        da.plot(label=idx, ax=ax[j])\n",
    "        ax[j].set_xlabel('starting year of segment', fontsize=14)\n",
    "        ax[j].text(da.time[0], .7, run.upper(), fontsize=14)\n",
    "    for j in range(2):\n",
    "        ax[j].tick_params(labelsize=14)\n",
    "        ax[j].axhline(0, c='k', lw=.5)\n",
    "    \n",
    "    \n",
    "ax[0].axvline(100, c='grey', lw=.5)\n",
    "ax[0].axvline(151, c='grey', lw=.5)\n",
    "ax[1].axvline(268, c='grey', lw=.5)\n",
    "\n",
    "ax[0].legend(fontsize=14, ncol=3, loc=8)\n",
    "ax[0].set_ylabel('spatial correlation coefficient', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{path_results}/SST/spatial_correlation(t)_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
