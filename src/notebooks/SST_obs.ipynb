{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HadISST3\n",
    "https://climatedataguide.ucar.edu/climate-data/sst-data-hadsst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maps import make_map\n",
    "from paths import file_HadISST, path_results, file_RMASK_ocn_had, path_samoc\n",
    "from plotting import discrete_cmap, shifted_color_map\n",
    "from timeseries import deseasonalize\n",
    "from xr_regression import xr_linear_trends_2D\n",
    "from xr_DataArrays import xr_AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(file_HadISST, decode_times=False)  # time in days since 1.1.1870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.where(ds['sst'] != -1000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'fraction of data available'\n",
    "text1 = 'HadISST'\n",
    "text2 = '1870-2018'\n",
    "cmap = plt.get_cmap('viridis', 10)\n",
    "fn = f'{path_results}/SST/SST_HadISST_data_fraction'\n",
    "make_map(xa=ds.sst.count(dim='time')/len(ds.time), domain='ocn_had', proj='rob', cmap=cmap, minv=0.5, maxv=1,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.count(dim='time').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.count(dim='time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.count(dim='time').where(ds.sst.count(dim='time')!=len(ds.time)).sel({'latitude':slice(60,-60)}).plot(vmin=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating monthly SST field without missing values\n",
    "# replacing missing values with -1.8, as the missing values occur in polar latitudes during winter.\n",
    "sst_had = ds.sst.where(np.isnan(ds.sst)==False, -1.8)\n",
    "sst_had.to_netcdf(f'{path_samoc}/SST/SST_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ds.sst.sel({'latitude':80, 'longitude':0}, method='nearest')\n",
    "print(test[5].values)\n",
    "print(np.dtype(test[5]))\n",
    "\n",
    "print(np.isnan(test).any().values)\n",
    "print(test.mean('time').values)\n",
    "\n",
    "print(test.where(test!=np.nan).count('time').values)    # 1641\n",
    "print(test.where(np.isnan(test)).count('time').values)  #0\n",
    "\n",
    "print(test.count(dim='time').values)\n",
    "print(test.time.count(dim='time').values)\n",
    "\n",
    "test[:30].plot()\n",
    "test = test.where(np.isnan(test)==False, -1.8)\n",
    "print(np.isnan(test).any().values)\n",
    "(test[:30]+1).plot()\n",
    "print(test.where(test==np.nan).count('time').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yearly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.open_dataset(file_HadISST)\n",
    "ds2 = ds2.where(ds2['sst'] != -1000.)\n",
    "ds2 = ds2.sst.where(np.isnan(ds2.sst)==False, -1.8)\n",
    "ds2 = ds2.groupby('time.year').mean('time')\n",
    "ds2 = ds2.rename({'year':'time'})\n",
    "ds2.coords['time'] = (ds2.coords['time']-1870)*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.to_netcdf(f'{path_samoc}/SST/SST_yrly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_np = np.where(ds.sst.count(dim='time')!=0, 1, 0)\n",
    "MASK = ds.sst[0,:,:].drop(['time']).copy()\n",
    "MASK.values = MASK_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataarray(f'{file_RMASK_ocn_had}').plot(vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use with caution: there are some interpolation errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_AREA('ocn_had').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_1980_2010 = ds.sst.sel(time=slice(110*365.25, 140*365.25)).where(MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'temperature [$^\\circ$C]'\n",
    "text1 = 'HadISST\\nmean'\n",
    "text2 = '1980-2010'\n",
    "cmap = discrete_cmap(base_cmap=cmocean.cm.thermal, N=17)\n",
    "fn = f'{path_results}/SST/SST_HadISST_mean_1980_2010'\n",
    "make_map(xa=sst_1980_2010.mean(dim='time'),\n",
    "         domain='ocn_had', proj='rob', cmap=cmap, minv=-2, maxv=32,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'std(temperature) [K]'\n",
    "text1 = 'HadISST\\nmonthly\\nstd'\n",
    "text2 = '1980-2010'\n",
    "cmap = discrete_cmap(base_cmap=cmocean.cm.haline, N=12)\n",
    "fn = f'{path_results}/SST/SST_HadISST_std_1980_2010'\n",
    "make_map(xa=sst_1980_2010.std(dim='time'),\n",
    "         domain='ocn_had', proj='rob', cmap=cmap, minv=0, maxv=6,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'std(temperature) [K]'\n",
    "text1 = 'HadISST\\ndeseas.\\nstd'\n",
    "text2 = '1980-2010'\n",
    "cmap = discrete_cmap(base_cmap=cmocean.cm.haline, N=12)\n",
    "fn = f'{path_results}/SST/SST_HadISST_ds_std_1980_2010'\n",
    "make_map(xa=deseasonalize(sst_1980_2010).std(dim='time'),\n",
    "         domain='ocn_had', proj='rob', cmap=cmap, minv=0, maxv=1.2,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60$^\\circ$S-60$^\\circ$N mean timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA = xr_AREA('ocn_had')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_AREA = AREA.sel(latitude=slice(60, -60)).where(MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_area_sum = x_AREA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_area_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_AREA.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_xm = ((sst_had.sel(latitude=slice(60, -60))*x_AREA).sum(dim=['latitude', 'longitude']))/x_area_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_xm.plot()\n",
    "deseasonalize(SST_xm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_xm.to_netcdf(f'{path_samoc}/SST/SST_60S_60N_mean_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.sst[-12:,:,:].mean(dim='time')-ds.sst[:12,:,:].mean(dim='time')).plot(vmin=-2, vmax=2, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_linear_trends_2D1(da, dim_names, with_nans=False):\n",
    "    \"\"\" calculate linear trend of 2D field in time\n",
    "    \n",
    "    input:\n",
    "    da        .. 3D xr DataArray with (dim_names) dimensions\n",
    "    dim_names .. tuple of 2 strings: e.g. lat, lon dimension names\n",
    "    \n",
    "    output:\n",
    "    da_trend  .. slope of linear regression\n",
    "    \"\"\"\n",
    "    \n",
    "    def xr_linear_trend_with_nans(x):\n",
    "        \"\"\" function to compute a linear trend coeficient of a timeseries \"\"\"\n",
    "        if np.isnan(x).any():\n",
    "            x = x.dropna(dim='time')\n",
    "            if x.size>1:\n",
    "                pf = np.polynomial.polynomial.polyfit(x.time, x, 1)\n",
    "            else:\n",
    "                pf = np.array([np.nan, np.nan])\n",
    "        else:\n",
    "            pf = np.polynomial.polynomial.polyfit(x.time, x, 1)\n",
    "        return xr.DataArray(pf[1])\n",
    "    \n",
    "    (dim1, dim2) = dim_names\n",
    "    # stack lat and lon into a single dimension called allpoints\n",
    "    stacked = da.stack(allpoints=[dim1, dim2])\n",
    "    # apply the function over allpoints to calculate the trend at each point\n",
    "    if with_nans==False:\n",
    "        trend = stacked.groupby('allpoints').apply(xr_linear_trend)\n",
    "        # unstack back to lat lon coordinates\n",
    "        da_trend = trend.unstack('allpoints')\n",
    "    if with_nans==True:\n",
    "        trend = stacked.groupby('allpoints').apply(xr_linear_trend_with_nans)\n",
    "        # unstack back to lat lon coordinates\n",
    "        da_trend = trend.unstack('allpoints')\n",
    "    #da_trend = da_trend.rename({'allpoints_level_0':dim1, 'allpoints_level_1':dim2})\n",
    "    return da_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trend_full1 = xr_linear_trends_2D1(da=ds.sst.where(MASK), \n",
    "                                    dim_names=('latitude', 'longitude'), with_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_trend_full = xr_linear_trends_2D(da=ds.sst.where(MASK), \n",
    "                                    dim_names=('latitude', 'longitude'), with_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trend_full1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_trend_1980_2010 = xr_linear_trends_2D(da=ds.sst.sel(time=slice(110*365.25, 140*365.25)).where(MASK),\n",
    "                                         dim_names=('latitude', 'longitude'), with_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_trend_1968_2018 = xr_linear_trends_2D(da=ds.sst.sel(time=slice(98*365.25, 148*365.25)).where(MASK),\n",
    "                                         dim_names=('latitude', 'longitude'), with_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trend_full      = ds_trend_full     .squeeze()\n",
    "ds_trend_1980_2010 = ds_trend_1980_2010.squeeze()\n",
    "ds_trend_1968_2018 = ds_trend_1968_2018.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'SST trend [K/centrury]'\n",
    "text1 = 'HadISST'\n",
    "text2 = '1870-2018'\n",
    "cmap = discrete_cmap(base_cmap=shifted_color_map(start=.33, stop=1, midpoint=.5, \n",
    "                                                 cmap=cmocean.cm.balance), N=16)\n",
    "fn = f'{path_results}/SST/SST_HadISST_trend_1870_2018'\n",
    "make_map(xa=ds_trend_full*365.25*100, domain='ocn_had', proj='rob', cmap=cmap, minv=-.5, maxv=1.5,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'SST trend [K/centrury]'\n",
    "text1 = 'HadISST'\n",
    "text2 = '1980-2010'\n",
    "cmap = discrete_cmap(base_cmap=shifted_color_map(start=.3, stop=1, midpoint=.5, \n",
    "                                                 cmap=cmocean.cm.balance), N=14)\n",
    "fn = f'{path_results}/SST/SST_HadISST_trend_1980_2010'\n",
    "make_map(xa=ds_trend_1980_2010*365.25*100, domain='ocn_had', proj='rob', cmap=cmap, minv=-2, maxv=5,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'SST trend [K/centrury]'\n",
    "text1 = 'HadISST'\n",
    "text2 = '1968-2018'\n",
    "cmap = discrete_cmap(base_cmap=shifted_color_map(start=.3, stop=1, midpoint=.5, \n",
    "                                                 cmap=cmocean.cm.balance), N=14)\n",
    "fn = f'{path_results}/SST/SST_HadISST_trend_1968_2018'\n",
    "make_map(xa=ds_trend_1968_2018*365.25*100, domain='ocn_had', proj='rob', cmap=cmap, minv=-2, maxv=5,\n",
    "         label=label, filename=fn, text1=text1, text2=text2, rects=[], sig=None, clon=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xr_regression import xr_lintrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries import lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds.time/365+1870,         ds.sst.sel({'latitude':0, 'longitude':-120}, method='nearest')      )\n",
    "plt.plot(ds.time/365+1870, lowpass(ds.sst.sel({'latitude':0, 'longitude':-120}, method='nearest'), 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the forced signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_natural = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_natural.nc', decode_times=False)\n",
    "forcing_anthro  = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_anthro.nc' , decode_times=False)\n",
    "forcing_all     = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_all.nc'    , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forcing in [forcing_natural, forcing_anthro, forcing_all]:\n",
    "    print(len(forcing))\n",
    "    forcing.coords['time'] = (forcing.time-9)*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrending with one scaled signal (all forcings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[:, 100, 10].plot()\n",
    "forcing_all[:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(forcing_all[:].values)\n",
    "y = ds2[:, 100, 10].values\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(f'all forcing    R^2: {model.rsquared:4.2e} \\n params:\\n{model.params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrending with two scaled signals (anthropogenic + natural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcings = forcing_natural.to_dataframe(name='natural').join(\n",
    "                     [forcing_anthro.to_dataframe( name='anthro'),\n",
    "                      forcing_all.to_dataframe(name='all')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcings.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(forcings[['all']])\n",
    "y = ds2[:, 100, 10].values\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(f'all forcing    R^2: {model.rsquared:4.2e} \\n params:\\n{model.params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(forcings[['anthro', 'natural']])\n",
    "y = ds2[:, 100, 10].values\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(f'all forcing    R^2: {model.rsquared:4.2e} \\n params:\\n{model.params}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params['anthro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3 = ds2.stack(z=('latitude', 'longitude'))\n",
    "ds_anthro = ds3[0,:].squeeze().copy()\n",
    "ds_natural = ds3[0,:].squeeze().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = sm.add_constant(forcings[['anthro', 'natural']])\n",
    "for i, coordinate in enumerate(ds3.z):\n",
    "    y = ds3[:, i].values\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    ds_anthro[i] = model.params['anthro']\n",
    "    ds_natural[i] = model.params['natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anthro.unstack('z').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_natural.unstack('z').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_natural.unstack('z').mean(dim='longitude').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the Pacific there is negative values for the natural forcing coefficient, implying warming for negative forcings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ds2.sel({'longitude':-140, 'latitude':0}, method='nearest')\n",
    "ts -= ts.mean()\n",
    "ts.plot()\n",
    "forcing_natural.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(forcing_natural, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of the difference between then two methods as Rˆ2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = xr.open_dataarray(f'{path_samoc}/SST/SST_GMST_sfdt_yrly_had.nc')\n",
    "dat = xr.open_dataarray(f'{path_samoc}/SST/SST_GMST_tfdt_yrly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((das-dat)**2).sum(dim='time').plot(vmax=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
