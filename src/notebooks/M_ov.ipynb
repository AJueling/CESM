{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability of the AMOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cmocean\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "%matplotlib inline\n",
    "matplotlib.rc_file('../rc_file')\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $M_{ov}$ calculation\n",
    "\n",
    "The fundamental idea behind the $M_{ov}$ parameter is the effect of a MOC shutdown has on the salinity in the North Atlantic and hence NADW formation.\n",
    "If the overturning circulation imports freshwater to the Atlantic, a MOC shutdown will increase salinity which counteracts the shutdown.\n",
    "Vice versa, a freshwater export due to the MOC will lead to freshening of the North Atlantic in case of a shutdown and hence a strengthening of the shut down state.\n",
    "\n",
    "The Atlantic freshwater budget in steady state is\n",
    "\n",
    "$$\\left[E - P - R \\right] = M_{ov} + M_{az} + M_{dif} + M_{BS}$$\n",
    "\n",
    "with evaporation $E$, precipitation $P$, runoff $R$, as well as freshwater transport terms due to the overturning circulation $M_{ov}$, the azonal gyre circulation $M_{az}$, diffusion $M_{dif}$, and exchange via the Bering Strait $M_{BS}$.\n",
    "\n",
    "\n",
    "The overturning freswater transport term $M_{ov}$ is given differently in different publications:\n",
    "\n",
    "_de Vries et al. (2005)_:\n",
    "\n",
    "$$M_{ov} = - \\frac{1}{S_0} \\int \\bar{v}(z) \\left[ \\langle S(z) \\rangle - S_0 \\right] \\,\\mathrm{d}z$$\n",
    "\n",
    "where $\\bar{v}(z) = \\int v(x,z) \\,\\mathrm{d}x$ is the zonal integral and $\\langle S \\rangle (z) = \\int S(x,z) \\,\\mathrm{d}x \\, \\big/ \\int \\mathrm{d}x$ is the zonal mean, such that\n",
    "\n",
    "\\begin{align}\n",
    "M_{ov} & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x} - S_0 \\right] \\,\\mathrm{d}z \\\\\n",
    " & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x} \\right] \\,\\mathrm{d}z + \\int \\int v(x,z) \\, \\mathrm{d}x \\mathrm{d}z  \\tag{1}\n",
    "\\end{align}\n",
    "\n",
    "_Mecking et al. (2017)_:\n",
    "\n",
    "$$M_{ov} = - \\frac{1}{S_0} \\int \\int v^*(z) \\langle S(z) \\rangle \\, \\mathrm{d}x \\mathrm{d}z$$\n",
    "\n",
    "where $v^*(z) = \\langle v \\rangle (z) - \\bar{v} = \\int v(x,z) \\,\\mathrm{d}x \\, \\big/ \\int \\mathrm{d}x - \\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z \\, \\big/ \\int \\int \\mathrm{d}x \\mathrm{d}z$ such that\n",
    "\n",
    "\\begin{align}\n",
    "M_{ov} & = - \\frac{1}{S_0} \\int \\int \\left[ \\frac{\\int v(x,z) \\,\\mathrm{d}x}{ \\int \\mathrm{d}x} - \\frac{\\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z}{\\int \\int \\mathrm{d}x \\mathrm{d}z} \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}x \\mathrm{d}z \\\\\n",
    " & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x - \\frac{\\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z}{\\int \\mathrm{d}z} \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}z  \\\\\n",
    " & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}z  + \\frac{1}{S_0} \\int  \\left[ \\frac{\\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z}{\\int \\mathrm{d}z} \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}z \\\\\n",
    "  & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}z  + \\frac{1}{S_0} \\int \\left[ \\frac{ \\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z  \\times   \\int S(x,z) \\,\\mathrm{d}x }{\\int \\int \\mathrm{d}x \\mathrm{d}z } \\right] \\, \\mathrm{d}z \\\\\n",
    "  & = - \\frac{1}{S_0} \\int \\left[ \\int v(x,z) \\,\\mathrm{d}x \\right] \\left[ \\frac{\\int S(x,z) \\,\\mathrm{d}x}{\\int \\mathrm{d}x}\\right] \\, \\mathrm{d}z  + \\left[ \\frac{1}{S_0} \\frac{  \\int \\int S(x,z) \\,\\mathrm{d}x \\mathrm{d}z}{\\int \\int \\mathrm{d}x \\mathrm{d}z } \\right] \\int \\int v(x,z) \\,\\mathrm{d}x \\mathrm{d}z  \\tag{2}\n",
    "\\end{align}\n",
    "\n",
    "Equations (2) and (1) are equal if the reference salinity is equal to the section average: $S_0 = \\int \\int S(x,z) \\,\\mathrm{d}x \\mathrm{d}z \\, \\big/ \\int \\int \\mathrm{d}x \\mathrm{d}z $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MOC import approx_lats\n",
    "from tqdm import tqdm_notebook\n",
    "from paths import file_ex_ocn_ctrl, file_ex_ocn_rcp, file_ex_ocn_lpd, path_prace, path_results, file_RMASK_ocn, file_RMASK_ocn_low\n",
    "from filters import lowpass\n",
    "from constants import rho_sw  # [kg/m^3]\n",
    "from timeseries import IterateOutputCESM\n",
    "from xr_regression import xr_lintrend, xr_linear_trend, xr_linear_trends_2D\n",
    "from xr_DataArrays import xr_DZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salinity bias\n",
    "_Mecking et al. (2017)_ point out that the CMIP5 $M_{ov}$ values are influenced by salinity biases, so it is of interest to quantify these in the CESM simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsh = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False)\n",
    "dsl = xr.open_dataset(file_ex_ocn_lpd, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ocn = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False)\n",
    "ds_low = xr.open_dataset(file_ex_ocn_lpd, decode_times=False)\n",
    "RMASK_ocn = xr.open_dataarray(file_RMASK_ocn)\n",
    "RMASK_low = xr.open_dataarray(file_RMASK_ocn_low)\n",
    "Atl_MASK_ocn = xr.DataArray(np.in1d(RMASK_ocn, [6,8,9]).reshape(RMASK_ocn.shape),\n",
    "                            dims=RMASK_ocn.dims, coords=RMASK_ocn.coords)\n",
    "Atl_MASK_low = xr.DataArray(np.in1d(RMASK_low, [6,8,9]).reshape(RMASK_low.shape),\n",
    "                            dims=RMASK_low.dims, coords=RMASK_low.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALT_mean_low  = xr.open_dataarray(f'{path_prace}/EN4/EN4_mean_salinity_low.nc')\n",
    "SALT_mean_high = xr.open_dataarray(f'{path_prace}/EN4/EN4_mean_salinity_high.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Fov_Faz_Sov_Saz_Se(ds, SALT=None, MASK=None):\n",
    "    \"\"\" calculate F_{ov/az}, S_{ov,az} \n",
    "    \n",
    "    ds   .. dataset with geometry fields dz and DXU\n",
    "    SALT .. if None: taken from ds; else external SALT field for bias corrected calculation\n",
    "    MASK .. which \n",
    "    \n",
    "    \"\"\"\n",
    "    S0 = 35.  # [g/kg]\n",
    "    if SALT is None:  SALT = ds.SALT\n",
    "    if MASK is None:  MASK = xr.where(ds.REGION_MASK==6, 1, 0)\n",
    "    SALT = SALT.where(MASK)\n",
    "    VVEL = ds.VVEL.where(MASK)\n",
    "    \n",
    "    DXU_intx_z  = ds.DXU.where(MASK).where(SALT>0).sum(dim='nlon', skipna=True)  # zonal length of section (z)\n",
    "    SALT_mean_z = (ds.DXU*SALT).sum(dim='nlon', skipna=True)/DXU_intx_z          # zonal mean salinity     (z) [g/kg]\n",
    "\n",
    "    VVEL_intx_z = (ds.DXU*VVEL).sum(dim='nlon', skipna=True)                     # zonal integral velocity (z) [cm^2/s]\n",
    "    VVEL_mean_z = VVEL_intx_z/DXU_intx_z                                         # zonal mean velocity     (z) [cm/s]\n",
    "    \n",
    "    SALT_prime_x_z = (SALT - SALT_mean_z)                                        # azonal salt component (x,z) [g/kg]\n",
    "    VVEL_prime_x_z = (VVEL - VVEL_mean_z)                                        # azonal velocity comp. (x,z) [cm/s]\n",
    "    \n",
    "    Fov = ( -1/S0*(VVEL_intx_z*(SALT_mean_z - S0)*ds.dz).sum(dim='z_t'))/1e12  # 1 Sv = 1e12 cm^3/s\n",
    "    Sov = (VVEL_intx_z*SALT_mean_z*ds.dz).sum(dim='z_t')*rho_sw/1e9            # 1 kg/s = rho_w * 1e-9 g/kg cm^3/s\n",
    "    \n",
    "    vSp = (ds.DXU*ds.dz*VVEL_prime_x_z*SALT_prime_x_z).sum(dim=['nlon','z_t'])   # [cm^3/s * g/kg]\n",
    "    Saz = vSp*rho_sw/1e9\n",
    "    Faz = -vSp/1e12/S0\n",
    "    \n",
    "    Se = (ds.DXU*ds.dz*(ds.VNS.where(MASK)*ds.DYT - VVEL*SALT)).sum(dim=['nlon','z_t'])*rho_sw/1e9\n",
    "    \n",
    "    St = (ds.VNS.where(MASK)*ds.DYT*ds.DXU*ds.dz/1e9*rho_sw).sum(dim=['z_t','nlon'])\n",
    "    \n",
    "    Fov.name, Faz.name, Sov.name, Saz.name, Se.name, St.name = 'Fov', 'Faz', 'Sov', 'Saz', 'Se', 'St'\n",
    "    ds = xr.merge([Fov, Faz, Sov, Saz, Se, St])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# testing low res data\n",
    "ds = calc_Fov_Faz_Sov_Saz_Se(dsl, MASK=Atl_MASK_low)\n",
    "f, ax = plt.subplots(1,2, figsize=(10,3))\n",
    "for i in range(2):  ax[i].axhline(0, c='k', lw=.5)\n",
    "ds['Fov'].plot(ax=ax[0], label='Fov')\n",
    "ds['Faz'].plot(ax=ax[0], label='Faz')\n",
    "(ds['Fov']+ds['Faz']).plot(ax=ax[0], label='Fov+Faz', c='C3')\n",
    "ds['Sov'].plot(ax=ax[1], label='Sov')\n",
    "ds['Saz'].plot(ax=ax[1], label='Saz')\n",
    "ds['Se'] .plot(ax=ax[1], label='Se')\n",
    "ds['St'] .plot(ax=ax[1], label='St')\n",
    "(ds['Sov']+ds['Saz']+ds['Se']).plot(ax=ax[1], label='St')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds['St']-(ds['Sov']+ds['Saz']+ds['Se'])).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# testing high res data\n",
    "ds = calc_Fov_Faz_Sov_Saz_Se(dsh, MASK=Atl_MASK_ocn)\n",
    "f, ax = plt.subplots(1,2, figsize=(10,3))\n",
    "for i in range(2):  ax[i].axhline(0, c='k', lw=.5)\n",
    "ds['Fov'].plot(ax=ax[0], label='Fov')\n",
    "ds['Faz'].plot(ax=ax[0], label='Faz')\n",
    "ds['Sov'].plot(ax=ax[1], label='Sov')\n",
    "ds['Saz'].plot(ax=ax[1], label='Saz')\n",
    "ds['Se'] .plot(ax=ax[1], label='Se')\n",
    "ds['St'] .plot(ax=ax[1], label='St')\n",
    "(ds['Sov']+ds['Saz']+ds['Se']).plot(ax=ax[1], label='St')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(217,230):\n",
    "#     ds = xr.open_dataset(f'{path_prace}/{run}/FW_SALT_fluxes_{run}_{y}.nc')\n",
    "#     print(y, os.path/.exists(f'{path_prace}/{run}/FW_SALT_fluxes_{run}_{y}.nc'), 'St' in ds.keys())\n",
    "    !rm /projects/0/prace_imau/prace_2013081679/andre/ctrl/FW_SALT_fluxes_ctrl_{y}.nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso.to_netcdf(f'{path_prace}/{run}/FW_SALT_fluxes_{run}.nc')    \n",
    "dsc.to_netcdf(f'{path_prace}/{run}/FW_SALT_fluxes_bias_corrected_{run}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(fno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating for all years\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    if i==0:  continue\n",
    "    DXU = ([dsh, dsl][i]).DXU\n",
    "    DYT = ([dsh, dsl][i]).DYT\n",
    "    dz = ([dsh, dsl][i]).dz\n",
    "    MASK = [Atl_MASK_ocn, Atl_MASK_low][i]\n",
    "    for j, y in tqdm_notebook(enumerate(range(30))):\n",
    "#     for j, y in tqdm_notebook(enumerate(np.arange(2000,2101))):\n",
    "        y_ = [200, 500][i]+y\n",
    "        print(y_)\n",
    "#         y_ = y\n",
    "        fno = f'{path_prace}/{run}/FW_SALT_fluxes_{run}_{y_}.nc'\n",
    "        fnc = f'{path_prace}/{run}/FW_SALT_fluxes_bias_corrected_{run}_{y_}.nc'\n",
    "        if os.path.exists(fno) and os.path.exists(fnc):\n",
    "            print('test')\n",
    "            dso_ = xr.open_dataset(fno, decode_times=False)\n",
    "            dsc_ = xr.open_dataset(fnc, decode_times=False)\n",
    "        else:\n",
    "            SALT_VNS_UES = xr.open_dataset(f'{path_prace}/{run}/ocn_yrly_SALT_VNS_UES_{y_:04d}.nc', decode_times=False).drop(['TLONG','TLAT','ULONG','ULAT'])\n",
    "            UVEL_VVEL = xr.open_dataset(f'{path_prace}/{run}/ocn_yrly_UVEL_VVEL_{y_:04d}.nc', decode_times=False).drop(['TLONG','TLAT','ULONG','ULAT'])\n",
    "            ds = xr.merge([SALT_VNS_UES, UVEL_VVEL, DYT, DXU, dz]).drop(['TLONG','TLAT','ULONG','ULAT'])\n",
    "#             print(ds)\n",
    "            dso_ = calc_Fov_Faz_Sov_Saz_Se(ds, MASK=MASK)\n",
    "            dsc_ = calc_Fov_Faz_Sov_Saz_Se(ds, MASK=MASK, SALT=[SALT_mean_high, SALT_mean_low][i])\n",
    "#             print(dso_, dsc_)\n",
    "            dso_.to_netcdf(fno)\n",
    "            dsc_.to_netcdf(fnc)\n",
    "       \n",
    "        if j==0:  dso, dsc = dso_.copy(), dsc_.copy()\n",
    "        else:     dso, dsc = xr.concat([dso, dso_], dim='time'), xr.concat([dsc, dsc_], dim='time')\n",
    "    dso.to_netcdf(f'{path_prace}/{run}/FW_SALT_fluxes_{run}.nc')    \n",
    "    dsc.to_netcdf(f'{path_prace}/{run}/FW_SALT_fluxes_bias_corrected_{run}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /projects/0/prace_imau/prace_2013081679/andre/lpd/FW_SALT_fluxes*.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,2, figsize=(12,8), sharex='col', sharey='row')\n",
    "ov, az, eddy = r'$_{ov}$', r'$_{az}$', r'$_{eddy}$'\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    ax[0,i].set_title(['HIGH','LOW'][i])\n",
    "    ax[i,0].set_ylabel(['northward FW transport [Sv]','northward Salt transport [kg/s]'][i])\n",
    "    for j in range(2):\n",
    "        ax[i,j].axhline(0, c='k')\n",
    "        ax[i,j].axvline(0, c='k')\n",
    "        ax[i,j].set_xlim((-34.5,70))\n",
    "        ax[i,j].grid()\n",
    "    lats = [approx_lats('ocn'), dsl.TLAT.where(Atl_MASK_low).mean(dim='nlon', skipna=True)][i]\n",
    "    dso = xr.open_dataset(f'{path_prace}/{run}/FW_SALT_fluxes_{run}.nc', decode_times=False)\n",
    "    dsc = xr.open_dataset(f'{path_prace}/{run}/FW_SALT_fluxes_bias_corrected_{run}.nc', decode_times=False)\n",
    "    \n",
    "    # original\n",
    "    ax[0,i].plot(lats, dso.Fov.mean('time')                                         , c='C0', label=f'F{ov}')\n",
    "    ax[0,i].plot(lats, dso.Faz.mean('time')                                         , c='C1', label=f'F{az}')\n",
    "    ax[0,i].plot(lats, dso.Fov.mean('time')+dso.Faz.mean('time')                    , c='C3', label=f'F{ov}+F{az}')\n",
    "    ax[1,i].plot(lats, dso.Sov.mean('time')                                         , c='C0', label=f'S{ov}')\n",
    "    ax[1,i].plot(lats, dso.Saz.mean('time')                                         , c='C1', label=f'S{az}')\n",
    "    ax[1,i].plot(lats, dso.Se .mean('time')                                         , c='C2', label=f'S{eddy}')\n",
    "    ax[1,i].plot(lats, dso.Sov.mean('time')+dso.Saz.mean('time')+dso.Se.mean('time'), c='C3', label=f'S{ov}+S{az}+S{eddy}')\n",
    "    \n",
    "    # bias corrected\n",
    "    # VNS is not bias corrected, so this term does not make sense\n",
    "    ax[0,i].plot(lats, dsc.Fov.mean('time')                     , c='C0', ls='--', lw=.5, label=f'F{ov} corr.')\n",
    "    ax[0,i].plot(lats, dsc.Faz.mean('time')                     , c='C1', ls='--', lw=.5, label=f'F{az} corr.')\n",
    "    ax[0,i].plot(lats, dsc.Fov.mean('time')+dsc.Faz.mean('time'), c='C3', ls='--', lw=.5, label=f'F{ov}+F{az} corr.')\n",
    "    ax[1,i].plot(lats, dsc.Sov.mean('time')                     , c='C0', ls='--', lw=.5, label=f'S{ov} corr.')\n",
    "    ax[1,i].plot(lats, dsc.Saz.mean('time')                     , c='C1', ls='--', lw=.5, label=f'S{az} corr.')\n",
    "    ax[1,i].plot(lats, dsc.Sov.mean('time')+dsc.Saz.mean('time'), c='C3', ls='--', lw=.5, label=f'S{ov}+S{az} corr.')\n",
    "#     ax[1,i].set_ylim((-1.5e8,1.5e8))\n",
    "    ax[1,i].set_xlabel(r'latitude [$^\\circ$N]')\n",
    "    for j in range(2):  ax[j,i].legend(ncol=2)\n",
    "plt.savefig(f'{path_results}/Mov/Mov_lat_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salt bias corrected meridional FW/SALT fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well can we approximate the FW eddy term with averaging monthly fields to a yearly field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in ['ctrl', 'lpd']:\n",
    "    SALT_VNS_UES = xr.open_dataset(f'{path_prace}/{run}/ocn_yrly_SALT_VNS_UES_0200.nc', decode_times=False)\n",
    "    UVEL_VVEL = xr.open_dataset(f'{path_prace}/{run}/ocn_yrly_UVEL_VVEL_0200.nc', decode_times=False)\n",
    "    ds = xr.merge([SALT_VNS_UES, UVEL_VVEL])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the error inducesd due to the grid distortion?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
