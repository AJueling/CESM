{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import scipy.stats as stats\n",
    "import cmocean\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file_paper')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from maps import rect_polygon\n",
    "from tqdm import tqdm_notebook\n",
    "from paths import path_samoc, path_results, path_prace\n",
    "from paths import file_ex_ocn_ctrl, file_ex_ocn_lpd, file_RMASK_ocn\n",
    "from regions import SST_index_bounds\n",
    "from filters import lowpass\n",
    "from constants import spy, A_earth\n",
    "from xr_regression import xr_quadtrend\n",
    "from scipy.optimize import curve_fit\n",
    "from SST_index_generation import times_ctrl, times_lpd, times_had\n",
    "from bb_analysis_timeseries import AnalyzeTimeSeries as ATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color conventions:\n",
    "- global black\n",
    "- Atlantic blue\n",
    "- Pacific orange\n",
    "- Southern red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHC data\n",
    "ctrl = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl.nc').isel(time=np.arange(50,300))\n",
    "lpd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd.nc' ).isel(time=np.arange(0,250))\n",
    "\n",
    "ctrl_qd = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl_qd.nc', decode_times=False)\n",
    "lpd_qd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd_qd.nc' , decode_times=False)\n",
    "\n",
    "# top of atmosphere imbalance\n",
    "TOA_ctrl = xr.open_dataarray(f'{path_prace}/TOA/TOM_ctrl.nc', decode_times=False).isel(time=slice(50,300))\n",
    "TOA_lpd  = xr.open_dataarray(f'{path_prace}/TOA/TOM_lpd.nc' , decode_times=False).isel(time=slice(0,250))\n",
    "\n",
    "# surface heat flux into the ocean\n",
    "SHF_ctrl = xr.open_dataset(f'{path_prace}/OHC/SHF_ctrl.nc', decode_times=False).isel(time=slice(50,300))\n",
    "SHF_lpd  = xr.open_dataset(f'{path_prace}/OHC/SHF_lpd.nc' , decode_times=False).isel(time=slice(0,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1 alternative: global SHF + TOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharey=True, figsize=(6.4, 2.5))\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    da_SHF = [SHF_ctrl, SHF_lpd][i]['Global_Ocean']\n",
    "    da_OHC = [ctrl, lpd][i]['OHC_Global_Ocean']\n",
    "    da_TOA = [TOA_ctrl, TOA_lpd][i]\n",
    "    ax[i].axhline(0, c='grey', lw=.5)\n",
    "    ax[i].plot(da_SHF.time/365, da_SHF/1e21, c='C0', label='SHF', lw=.5, alpha=.7)\n",
    "    ax[i].plot(da_SHF.time/365, xr_quadtrend(da_SHF)/1e21, c='C0', ls='--')\n",
    "    ax[i].plot(da_SHF.time[7:-7]/365, lowpass(da_SHF,13)[7:-7]/1e21, c='C0')\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "    ax[i].text(.05,.9, ['HIGH', 'LOW'][i], transform=ax[i].transAxes)\n",
    "#     ax[i].tick_params(labeltop=False, labelright=True)\n",
    "# ax[0].legend(loc=3)\n",
    "# Delta = r'$\\Delta$'\n",
    "ax[0].set_ylabel(f'heat flux into ocean [ZJ/yr]')\n",
    "plt.savefig(f'{path_results}/paper/SHF_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: $\\Delta$OHC mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    means, stds = [], []\n",
    "    for j, da in enumerate([ctrl, lpd]):\n",
    "        da_ = (da[f'OHC_{ocean}_Ocean']-da[f'OHC_{ocean}_Ocean'].shift(time=1)).sel(time=slice(200,300))/1e21\n",
    "#         print(da_.time.sel(time=slice(200,300)))\n",
    "        means.append(da_.mean().values)\n",
    "        stds.append(da_.std().values)\n",
    "    print(f'{ocean:8} & ${means[0]:4.1f} \\pm {stds[0]:3.1f}$ & ${means[1]:3.1f} \\pm {stds[1]:3.1f}$ \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2: SST index regression patterns\n",
    "from `OHC-ctrl_vs_lpd.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test presence of index files\n",
    "f, ax = plt.subplots(2,3, sharey='row', figsize=(12,8))\n",
    "for i, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "    if run=='ctrl':   ts = '_51_301'\n",
    "    elif run=='lpd':  ts = '_154_404'\n",
    "    elif run=='had':  ts = ''\n",
    "    for j, idx in enumerate(['AMO', 'SOM', 'TPI', 'PMV_EOF_20N', 'PMV_EOF_Eq', 'PMV_EOF_38S']):\n",
    "        if idx in ['AMO', 'SOM', 'TPI']:  dt = '_ds_dt_raw'\n",
    "        else:                             dt = ''\n",
    "        fn = f'{path_prace}/SST/{idx}{dt}_{run}{ts}.nc'\n",
    "        try:  assert os.path.exists(fn)\n",
    "        except:  print(f'does not exists: {fn}')\n",
    "        if idx in ['AMO', 'SOM', 'TPI']:\n",
    "            da = xr.open_dataarray(fn, decode_times=False)\n",
    "            ax[0,i].plot(da.time[7*12:-7*12], lowpass(da, 12*13)[7*12:-7*12], label=idx)\n",
    "            ax[0,i].legend()\n",
    "        else:\n",
    "            ds = xr.open_dataset(fn, decode_times=False)\n",
    "            ax[1,i].plot(ds.time[7*12:-7*12], lowpass(ds.pcs.isel(mode=0).squeeze()[7*12:-7*12], 12*13), c=f'C{j}', ls='-' , label=idx)\n",
    "            ax[1,i].plot(ds.time[7*12:-7*12], lowpass(ds.pcs.isel(mode=1).squeeze()[7*12:-7*12], 12*13), c=f'C{j}', ls='--', label=idx)\n",
    "            ax[1,i].plot(ds.time[7*12:-7*12], lowpass(ds.pcs.isel(mode=2).squeeze()[7*12:-7*12], 12*13), c=f'C{j}', ls=':' , label=idx)\n",
    "            vfs = ds.variance_fractions.values*100\n",
    "            print(f'{run:4} {idx:12} variance fraction:     mode 0: {vfs[0]:4.1f}%,  mode 1: {vfs[1]:4.1f}%,   mode 2: {vfs[2]:4.1f}%')\n",
    "        for k in range(2):  ax[k,i].axhline(c='k')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,7.8), constrained_layout=False)\n",
    "\n",
    "for i, idx in enumerate(['AMO', 'TPI', 'SOM']):\n",
    "#     maxv = [.4, .3, .25][i]\n",
    "    maxv = [3, 2, 1.5][i]\n",
    "    ticks = np.arange(-3,4,1)\n",
    "    ax = f.add_subplot(3, 5, 1+i*5)\n",
    "    ax.set_position([.009,.01+(2-i)*.32,.02,.3])\n",
    "    ax.text(.5, .5, ['AMV', 'TPI', 'SOM'][i], transform=ax.transAxes, rotation='vertical', va='center', ha='right', fontsize=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    rects = [[rect_polygon(SST_index_bounds('AMO'))], \n",
    "             [rect_polygon(SST_index_bounds('TPI1')),\n",
    "              rect_polygon(SST_index_bounds('TPI2')),\n",
    "              rect_polygon(SST_index_bounds('TPI3'))],\n",
    "             [rect_polygon(SST_index_bounds('SOM'))]\n",
    "            ][i]\n",
    "    \n",
    "    for j, run in tqdm_notebook(enumerate(['had', 'ctrl', 'lpd'])):\n",
    "        if run=='had':   ts = ''\n",
    "        if run=='ctrl':  ts = '_51_301' #'_mean'\n",
    "        if run=='lpd':   ts = '_154_404'#'_mean'\n",
    "        xa = xr.open_dataset(f'{path_prace}/SST/{idx}_regr_{run}{ts}.nc')\n",
    "            \n",
    "        if run=='had':     lats, lons = xa.latitude, xa.longitude; lons, lats = np.meshgrid(lons, lats)\n",
    "        elif run=='ctrl':  lats, lons = xa.t_lat, xa.t_lon; lons, lats = np.meshgrid(lons, lats)\n",
    "        elif run=='lpd':   lats, lons = xa.TLAT.values, xa.TLONG.values\n",
    "        \n",
    "        ax = f.add_subplot(3, 5, j+2+i*5, projection=ccrs.Robinson(central_longitude=[-60, 200, -60][i]))\n",
    "        if i==0:  ax.text(.5, 1.05, ['HIST', 'HIGH', 'LOW'][j], transform=ax.transAxes, fontsize=20, ha='center')\n",
    "        ax.set_global()\n",
    "        ax.set_position([.02+j*.31,.01+(2-i)*.32,.305,.3])\n",
    "\n",
    "#         im = ax.pcolormesh(lons, lats, xa.values, cmap='RdBu_r',\n",
    "        im = ax.pcolormesh(lons, lats, xa.slope, cmap='cmo.balance',\n",
    "                           vmin=-maxv, vmax=maxv, transform=ccrs.PlateCarree())\n",
    "#         ax.tricontour(lons.flatten(), lats.flatten(), xa.pval.values.flatten(),\n",
    "#                    levels=[-.01,0.01,.99,1.01], colors='purple', linestyles='dashed', transform=ccrs.PlateCarree())\n",
    "        plt.tricontour(lons.flatten(), lats.flatten(), xa.pval.where(np.isnan(xa.pval.values)==False, .5).values.flatten(),\n",
    "                       levels=[.01,.99], colors='purple', linestyles='dashed', transform=ccrs.PlateCarree())\n",
    "        ax.add_feature(cartopy.feature.LAND, zorder=2, edgecolor='black', facecolor='grey')\n",
    "\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False)\n",
    "        gl.ylocator = matplotlib.ticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "        \n",
    "        for rect in rects:\n",
    "            ax.add_patch(matplotlib.patches.Polygon(xy=rect,\n",
    "                                          facecolor='none', edgecolor='k',\n",
    "                                          linewidth=1, zorder=2,\n",
    "                                          transform=ccrs.PlateCarree(), ), )\n",
    "            \n",
    "    ax = f.add_subplot(3, 5, 5+i*5)\n",
    "    ax.set_position([.955,.03+(2-i)*.32,.01,.26])\n",
    "    cbar = plt.colorbar(im, cax=ax, shrink=.9, pad=.0, orientation='vertical', extend='both', ticks=ticks)\n",
    "    cbar.ax.set_yticklabels(ticks, fontsize=12)\n",
    "\n",
    "plt.savefig(f'{path_results}/paper/regression_patterns_full_nonstandardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(['AMO', 'TPI', 'SOM']):    \n",
    "    \n",
    "    for j, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "        if run=='ctrl':   ts = '_51_301' \n",
    "        elif run=='lpd':  ts = '_154_404'\n",
    "        elif run=='had':  ts = ''\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,7.8), constrained_layout=False)\n",
    "\n",
    "for i, idx in enumerate(['AMO', 'TPI', 'SOM']):\n",
    "#     maxv = [.4, .3, .25][i]\n",
    "#     maxv = [3, 2, 1.5][i]\n",
    "    maxv = [.25, .1, .1][i]\n",
    "    ticks = np.arange(-.3,.3,.05)\n",
    "    ax = f.add_subplot(3, 5, 1+i*5)\n",
    "    ax.set_position([.009,.01+(2-i)*.32,.02,.3])\n",
    "    ax.text(.5, .5, ['AMV', 'TPI', 'SOM'][i], transform=ax.transAxes, rotation='vertical', va='center', ha='right', fontsize=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    rects = [[rect_polygon(SST_index_bounds('AMO'))], \n",
    "             [rect_polygon(SST_index_bounds('TPI1')),\n",
    "              rect_polygon(SST_index_bounds('TPI2')),\n",
    "              rect_polygon(SST_index_bounds('TPI3'))],\n",
    "             [rect_polygon(SST_index_bounds('SOM'))]\n",
    "            ][i]\n",
    "    \n",
    "    for j, run in tqdm_notebook(enumerate(['had', 'ctrl', 'lpd'])):\n",
    "        if run=='had':   ts = ''\n",
    "        if run=='ctrl':  ts = '_51_301' #'_mean'\n",
    "        if run=='lpd':   ts = '_154_404'#'_mean'\n",
    "        std = lowpass(xr.open_dataarray(f'{path_prace}/SST/{idx}_ds_dt_raw_{run}{ts}.nc'), 12*13).std().values\n",
    "        xa = xr.open_dataset(f'{path_prace}/SST/{idx}_regr_{run}{ts}.nc')\n",
    "            \n",
    "        if run=='had':     lats, lons = xa.latitude, xa.longitude; lons, lats = np.meshgrid(lons, lats)\n",
    "        elif run=='ctrl':  lats, lons = xa.t_lat, xa.t_lon; lons, lats = np.meshgrid(lons, lats)\n",
    "        elif run=='lpd':   lats, lons = xa.TLAT.values, xa.TLONG.values\n",
    "        \n",
    "        ax = f.add_subplot(3, 5, j+2+i*5, projection=ccrs.Robinson(central_longitude=[-60, 200, -60][i]))\n",
    "        if i==0:  ax.text(.5, 1.05, ['HIST', 'HIGH', 'LOW'][j], transform=ax.transAxes, fontsize=20, ha='center')\n",
    "        ax.set_global()\n",
    "        ax.set_position([.02+j*.31,.01+(2-i)*.32,.305,.3])\n",
    "\n",
    "#         im = ax.pcolormesh(lons, lats, xa.values, cmap='RdBu_r',\n",
    "        im = ax.pcolormesh(lons, lats, xa.slope*std, cmap='cmo.balance',\n",
    "                           vmin=-maxv, vmax=maxv, transform=ccrs.PlateCarree())\n",
    "#         ax.tricontour(lons.flatten(), lats.flatten(), xa.pval.values.flatten(),\n",
    "#                    levels=[-.01,0.01,.99,1.01], colors='purple', linestyles='dashed', transform=ccrs.PlateCarree())\n",
    "        plt.tricontour(lons.flatten(), lats.flatten(), xa.pval.where(np.isnan(xa.pval.values)==False, .5).values.flatten(),\n",
    "                       levels=[.01,.99], colors='purple', linestyles='dashed', transform=ccrs.PlateCarree())\n",
    "        ax.add_feature(cartopy.feature.LAND, zorder=2, edgecolor='black', facecolor='grey')\n",
    "\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False)\n",
    "        gl.ylocator = matplotlib.ticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "        \n",
    "        for rect in rects:\n",
    "            ax.add_patch(matplotlib.patches.Polygon(xy=rect,\n",
    "                                          facecolor='none', edgecolor='k',\n",
    "                                          linewidth=1, zorder=2,\n",
    "                                          transform=ccrs.PlateCarree(), ), )\n",
    "            \n",
    "    ax = f.add_subplot(3, 5, 5+i*5)\n",
    "    ax.set_position([.955,.03+(2-i)*.32,.01,.26])\n",
    "    cbar = plt.colorbar(im, cax=ax, shrink=.9, pad=.0, orientation='vertical', extend='both', ticks=ticks)\n",
    "    cbar.ax.set_yticklabels(ticks, fontsize=12)\n",
    "\n",
    "# plt.savefig(f'{path_results}/paper/regression_patterns_full_nonstandardized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,7.8), constrained_layout=False)\n",
    "\n",
    "for i, idx in enumerate(['AMO', 'TPI', 'SOM']):\n",
    "#     maxv = [.4, .3, .25][i]\n",
    "    maxv = [3, 2, 1.5][i]\n",
    "    ticks = np.arange(-3,4,1)\n",
    "    ax = f.add_subplot(3, 5, 1+i*5)\n",
    "    ax.set_position([.009,.01+(2-i)*.32,.02,.3])\n",
    "    ax.text(.5, .5, ['AMV', 'TPI', 'SOM'][i], transform=ax.transAxes, rotation='vertical', va='center', ha='right', fontsize=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    rects = [[rect_polygon(SST_index_bounds('AMO'))], \n",
    "             [rect_polygon(SST_index_bounds('TPI1')),\n",
    "              rect_polygon(SST_index_bounds('TPI2')),\n",
    "              rect_polygon(SST_index_bounds('TPI3'))],\n",
    "             [rect_polygon(SST_index_bounds('SOM'))]\n",
    "            ][i]\n",
    "    \n",
    "    for j, run in tqdm_notebook(enumerate(['had', 'ctrl', 'lpd'])):\n",
    "        if run=='had':   ts = ''\n",
    "        if run=='ctrl':  ts = '_mean'\n",
    "        if run=='lpd':   ts = '_mean'\n",
    "        xa = xr.open_dataset(f'{path_prace}/SST/{idx}_regr_{run}{ts}.nc').slope\n",
    "            \n",
    "        if run=='had':\n",
    "            lats = xa.latitude\n",
    "            lons = xa.longitude\n",
    "        elif run=='ctrl':\n",
    "            lats = xa.t_lat\n",
    "            lons = xa.t_lon\n",
    "        elif run=='lpd':\n",
    "            lats = xa.TLAT\n",
    "            lons = xa.TLONG\n",
    "        \n",
    "        ax = f.add_subplot(3, 5, j+2+i*5, projection=ccrs.Robinson(central_longitude=[-60, 200, -60][i]))\n",
    "        if i==0:  ax.text(.5, 1.05, ['HIST', 'HIGH', 'LOW'][j], transform=ax.transAxes, fontsize=20, ha='center')\n",
    "        ax.set_global()\n",
    "        ax.set_position([.02+j*.31,.01+(2-i)*.32,.305,.3])\n",
    "\n",
    "#         im = ax.pcolormesh(lons, lats, xa.values, cmap='RdBu_r',\n",
    "        im = ax.pcolormesh(lons, lats, xa.values, cmap='cmo.balance',\n",
    "                           vmin=-maxv, vmax=maxv, transform=ccrs.PlateCarree())\n",
    "        ax.add_feature(cartopy.feature.LAND, zorder=2, edgecolor='black', facecolor='grey')\n",
    "\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False)\n",
    "        gl.ylocator = matplotlib.ticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "        \n",
    "        for rect in rects:\n",
    "            ax.add_patch(matplotlib.patches.Polygon(xy=rect,\n",
    "                                          facecolor='none', edgecolor='k',\n",
    "                                          linewidth=1, zorder=2,\n",
    "                                          transform=ccrs.PlateCarree(), ), )\n",
    "            \n",
    "    ax = f.add_subplot(3, 5, 5+i*5)\n",
    "    ax.set_position([.955,.03+(2-i)*.32,.01,.26])\n",
    "    cbar = plt.colorbar(im, cax=ax, shrink=.9, pad=.0, orientation='vertical', extend='both', ticks=ticks)\n",
    "    cbar.ax.set_yticklabels(ticks, fontsize=12)\n",
    "\n",
    "plt.savefig(f'{path_results}/paper/regression_patterns_mean_nonstandardized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make orthographic AMO maps as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f'{path_prace}/SST/AMO_regr_had.nc')\n",
    "plt.contourf(ds.pval, levels=[0,0.01,.99,1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(8,3))\n",
    "for i, fn in enumerate([f'{path_prace}/SST/AMO_regr_ctrl_51_301.nc', f'{path_prace}/SST/AMO_regr_ctrl_mean.nc']):\n",
    "    ds = xr.open_dataset(fn)\n",
    "    ax[i].contourf(ds.pval, levels=[0,0.01,.99,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(8,3))\n",
    "for i, fn in enumerate([f'{path_prace}/SST/AMO_regr_lpd_154_404.nc', f'{path_prace}/SST/AMO_regr_lpd_mean.nc']):\n",
    "    ds = xr.open_dataset(fn)\n",
    "    ax[i].contourf(ds.pval, levels=[0,0.01,.99,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.plot(cmap='cmo.balance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.plot(cmap='cmo.curl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3: SST index spectra\n",
    "from `SST_indices.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spectra and put them into dictionary\n",
    "spec_dict = {}\n",
    "ft = 'lowpass'\n",
    "\n",
    "for i, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "    if run=='ctrl':   ts = '_51_301' \n",
    "    elif run=='lpd':  ts = '_154_404'\n",
    "    elif run=='had':  ts = ''\n",
    "    for j, idx in tqdm_notebook(enumerate(['AMO', 'SOM', 'TPI', 'PMV_EOF_20N', 'PMV_EOF_Eq', 'PMV_EOF_38S'])):\n",
    "        if idx in ['AMO','SOM','TPI']: dt = '_ds_dt_raw'\n",
    "        else:                          dt = ''\n",
    "        fc = 12*13\n",
    "        fn = f'{path_prace}/SST/{idx}{dt}_{run}{ts}.nc'\n",
    "        assert os.path.exists(fn), f'{fn} does not exist'\n",
    "        if idx in ['AMO', 'SOM', 'TPI']:  da = xr.open_dataarray(fn, decode_times=False)\n",
    "        else:                             da = xr.open_dataset(fn, decode_times=False).pcs.isel(mode=0).squeeze()\n",
    "        da = da.isel(time=slice(0,int(250*12)))\n",
    "        assert len(da) in [12*149, 12*250]\n",
    "        spec_dict[f'{idx}_{run}_spec'] = ATS(da).spectrum(filter_type=ft, filter_cutoff=fc)\n",
    "        spec_dict[f'{idx}_{run}_rnnh'] = ATS(da).mc_ar1_spectrum(filter_type=ft, filter_cutoff=fc)  # red noise spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spectra\n",
    "for k in range(2):\n",
    "    f, ax = plt.subplots(3, 3, figsize=(6.4,4), sharex=True, sharey='row', constrained_layout=True)\n",
    "    for i, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "        for j, idx in enumerate([['AMO', 'TPI', 'SOM'],['PMV_EOF_20N', 'PMV_EOF_Eq', 'PMV_EOF_38S']][k]):\n",
    "            factor = 12\n",
    "            spec = spec_dict[f'{idx}_{run}_spec']\n",
    "            rnnh = spec_dict[f'{idx}_{run}_rnnh']\n",
    "            ax[j,i].set_xscale('log', basex=2)\n",
    "            ax[j,i].set_yscale('log', basey=2)\n",
    "            ax[j,i].set_xlim((2**-3.5,2**-6))\n",
    "            power = [[0,-2,0],[5,4,5]][k][j]\n",
    "            ax[j,i].set_ylim(bottom=2**(power-6), top=2**power )\n",
    "            ax[j,i].plot(rnnh[1,:]*factor, rnnh[3,:]/factor, c='C1', label='AR(1) 95% C.I.')\n",
    "            ax[j,i].plot(spec[1]  *factor, spec[0]  /factor, c='C0', label='MT spectrum')\n",
    "\n",
    "    #         ax[j,i].set_yticklabels([])\n",
    "    #         ax[j,i].xaxis.set_minor_formatter(NullFormatter())\n",
    "            ax[j,0].set_ylabel(f'{idx} index\\nspectral power')\n",
    "    #         ax[j,i].set_xticklabels([])\n",
    "    #         ax[j,i].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "        ax[2,i].set_xticks([2**float(-n) for n in np.arange(6,3, -1)])\n",
    "        ax[2,i].set_xticklabels([2**n for n in np.arange(6,3, -1)])\n",
    "\n",
    "        ax[0,i].title.set_text(['HIST', 'HIGH', 'LOW'][i])\n",
    "        ax[-1,i].set_xlabel('period [years]')\n",
    "    ax[0,0].legend(loc=3, fontsize=8, frameon=False, handlelength=1)\n",
    "#     if k==0:  plt.savefig(f'{path_results}/paper/spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# matplotlib.rcParams.update({\"text.usetex\": True, 'text.latex.preamble': [r'\\usepackage{nicefrac}']})\n",
    "matplotlib.rcParams.update({'text.latex.preamble': [r'\\usepackage{nicefrac}']})\n",
    "plt.figure()\n",
    "plt.text(0.5,0.5,r'$\\nicefrac{2}{2}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 4: OHC time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(6.4,2.5), sharey='row', constrained_layout=True)\n",
    "for i, SHF in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    ax[i].axhline(0, c='k')\n",
    "    for j, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "        c = ['k' ,'C0','C1','C3'][j]\n",
    "        SHF_ = SHF[f'{ocean}_Ocean']\n",
    "        ax[i].plot(SHF.time[7:-7]/365, lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21, c=c, lw=1, label=ocean)\n",
    "#         if j==0:\n",
    "#             SHF_ = SHF[f'Atlantic_Ocean']+SHF['Labrador_Sea']\n",
    "#             ax[i].plot(SHF.time[7:-7]/365, lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21, c='C0', ls='--', lw=1, label='Atl.+Lab.')\n",
    "#             SHF_ = SHF[f'Atlantic_Ocean']+SHF['Labrador_Sea']+SHF['Greenland_Sea']\n",
    "#             ax[i].plot(SHF.time[7:-7]/365, lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21, c='C0', ls=':', lw=1, label='Atl.+Lab.+GL')\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "    ax[i].text(.05,.9, ['HIGH', 'LOW'][i], transform=ax[i].transAxes)\n",
    "ax[0].set_yticks(np.arange(-2,3,1))\n",
    "ax[0].set_ylabel('heat flux anomaly [ZJ/yr]')\n",
    "ax[0].set_ylim(-2,2)\n",
    "ax[1].legend(ncol=2, fontsize=8, frameon=False)\n",
    "plt.savefig(f'{path_results}/paper/SHF_anomaly_time_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene's test of heteroscedasticity\n",
    "print('ocean     std(HIGH) std(LOW) ratio    Levene')\n",
    "for j, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    A = np.zeros((2,250-14))\n",
    "    for i, SHF in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "        SHF_ = SHF[f'{ocean}_Ocean']\n",
    "        A[i] = lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21\n",
    "\n",
    "    print(f'{ocean:8}  {np.std(A[0]):=9.2f}  {np.std(A[1]):7.2f}  {np.std(A[0])/np.std(A[1]):4.2f}  {stats.levene(A[0], A[1])[1]:4.2e}')\n",
    "    \n",
    "for i, SHF in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    SHF_ = SHF[f'Atlantic_Ocean']+SHF['Labrador_Sea']\n",
    "    A[i] = lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21\n",
    "print(f'Atl.+Lab. {np.std(A[0]):=9.2f}  {np.std(A[1]):7.2f}  {np.std(A[0])/np.std(A[1]):4.2f}  {stats.levene(A[0], A[1])[1]:4.2e}')\n",
    "for i, SHF in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    SHF_ = SHF[f'Atlantic_Ocean']+SHF['Labrador_Sea']+SHF['Greenland_Sea']\n",
    "    A[i] = lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21\n",
    "print(f'Atl.+Lab.+GL {np.std(A[0]):=9.2f}  {np.std(A[1]):7.2f}  {np.std(A[0])/np.std(A[1]):4.2f}  {stats.levene(A[0], A[1])[1]:4.2e}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 2 , figsize=(6.4,7), sharey='row')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].axhline(0, c='grey', lw=.5)\n",
    "        ax[i,j].set_xlabel('time [model years]')\n",
    "\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    key = f'OHC_{ocean}_Ocean'\n",
    "    c = ['k' ,'C0','C1','C3'][i]\n",
    "    for j, da in enumerate([ctrl_qd, lpd_qd]):\n",
    "        x = da[key]/1e21\n",
    "        ax[0,j].plot(x.time, lowpass(x,13), c=c ,label=f'{ocean}')\n",
    "        ax[1,j].plot(x.time, np.gradient(lowpass(x,13).values), c=c ,label=f'{ocean}')\n",
    "\n",
    "for i, SHF in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    ax[2,i].axhline(0, c='k')\n",
    "    for j, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "        c = ['k' ,'C0','C1','C3'][j]\n",
    "        SHF_ = SHF[f'{ocean}_Ocean']\n",
    "        ax[2,i].plot(SHF.time[7:-7]/365, lowpass(SHF_-xr_quadtrend(SHF_), 13)[7:-7]/1e21, c=c, lw=1, label=ocean)\n",
    "\n",
    "\n",
    "for j in range(2):\n",
    "    ax[0,j].text(.05,.9, ['HIGH', 'LOW'][j], transform=ax[0,j].transAxes)\n",
    "ax[0,0].set_ylabel('OHC anomaly [ZJ]')\n",
    "ax[1,0].set_ylabel('d/dt OHC anomaly [ZJ/yr]')\n",
    "ax[2,0].set_ylabel('SHF anomaly [ZJ/yr]')\n",
    "ax[0,1].legend(fontsize=8, ncol=2, frameon=False)\n",
    "# plt.savefig(f'{path_results}/paper/OHC_time_series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(6.4,2.5), sharey=True)\n",
    "for i in range(2):\n",
    "    ax[i].axhline(0, c='grey', lw=.5)\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    key = f'OHC_{ocean}_Ocean'\n",
    "    c = ['k' ,'C0','C1','C3'][i]\n",
    "    for j, da in enumerate([ctrl_qd, lpd_qd]):\n",
    "        x = da[key]/1e21\n",
    "#         ax[j].plot(x.time, x, lw=.5, c=c ,label=f'{ocean}')\n",
    "        ax[j].plot(x.time, np.gradient(lowpass(x,13).values), c=c ,label=f'{ocean}')\n",
    "#         if i==0:  \n",
    "#             x = (da['OHC_Atlantic_Ocean']+da['OHC_Labrador_Sea'])/1e21\n",
    "#             ax[j].plot(x.time, lowpass(x,13), c='C0', ls='--', label=f'Atlantic+Labrador')\n",
    "for j in range(2):\n",
    "    ax[j].text(.05,.9, ['HIGH', 'LOW'][j], transform=ax[j].transAxes)\n",
    "ax[0].set_ylabel('OHC anomaly [ZJ]')\n",
    "ax[1].legend(fontsize=8, ncol=2, frameon=False)\n",
    "# plt.savefig(f'{path_results}/paper/OHC_time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inclusion of the Labrador Sea does not change the results significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmst_had  = xr.open_dataarray(f'{path_prace}/GMST/GMST_dt_yrly_had.nc', decode_times=False)\n",
    "gmst_had  = gmst_had.isel({'time':slice(9,158)})\n",
    "gmst_ctrl = xr.open_dataset(f'{path_prace}/GMST/GMST_ctrl.nc').GMST.isel({'time':slice(50,300)})\n",
    "gmst_ctrl['time'] = (gmst_ctrl.time/365).astype(dtype=int)\n",
    "gmst_ctrl -= xr_quadtrend(gmst_ctrl)\n",
    "gmst_lpd  = xr.open_dataset(f'{path_prace}/GMST/GMST_lpd.nc').GMST.isel({'time':slice(0,250)})\n",
    "gmst_lpd['time'] = (gmst_lpd.time/365).astype(dtype=int)\n",
    "gmst_lpd -= xr_quadtrend(gmst_lpd)\n",
    "\n",
    "TOA_ctrl = xr.open_dataarray(f'{path_prace}/TOA/TOM_ctrl.nc', decode_times=False).isel(time=slice(50,300))\n",
    "TOA_lpd  = xr.open_dataarray(f'{path_prace}/TOA/TOM_lpd.nc' , decode_times=False).isel(time=slice(0,250))\n",
    "\n",
    "SHF_ctrl = xr.open_dataset(f'{path_prace}/OHC/SHF_ctrl.nc', decode_times=False).isel(time=slice(50,300))\n",
    "SHF_lpd  = xr.open_dataset(f'{path_prace}/OHC/SHF_lpd.nc' , decode_times=False).isel(time=slice(0,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2**(i/2) for i in range(16)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4,7))\n",
    "# plt.gca().tick_params(labelsize=14)\n",
    "\n",
    "h, h_ = [], []\n",
    "for i, gmst in enumerate([gmst_had, gmst_ctrl, gmst_lpd]):\n",
    "    ls = [':','-','--'][i]\n",
    "    (spec, freq, jackknife) = ATS(gmst).spectrum()\n",
    "    l_, = plt.plot([0,0], [0,0], c='k', ls=ls, label=['HIST', 'HIGH', 'LOW'][i])\n",
    "    h_.append(l_)\n",
    "    l, = plt.plot(freq, spec*1e5, label='GMST', c='C2', ls=ls)\n",
    "    if i==1: h.append(l)\n",
    "l1 = plt.legend(handles=h_, bbox_to_anchor=(.3, .75), loc='center left', frameon=False)\n",
    "plt.gca().add_artist(l1)\n",
    "\n",
    "for i, ts in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    ls = ['-', '--'][i]\n",
    "    \n",
    "    toa = [TOA_ctrl, TOA_lpd][i]\n",
    "    toa_ = (toa-xr_quadtrend(toa))*spy/1e21\n",
    "    (spec, freq, jackknife) = ATS(toa_).spectrum()\n",
    "    l, = plt.plot(freq, spec, label='TOA', c=f'grey', ls=ls)\n",
    "    if i==0: h.append(l)\n",
    "    \n",
    "    \n",
    "    for j, basin in enumerate(['Global', 'Atlantic','Pacific', 'Southern']):\n",
    "        c = ['k' ,'C0','C1','C3'][j]\n",
    "        ts_ = (ts[f'{basin}_Ocean'] - xr_quadtrend(ts[f'{basin}_Ocean']))/1e21\n",
    "        (spec, freq, jackknife) = ATS(ts_).spectrum()\n",
    "        l, = plt.plot(freq, spec*[1,1/4,1/200,1/400][j],\n",
    "                      label=f'SHF {basin}',\n",
    "                      ls=ls, c=c, alpha=[1,.7,.7,.7][j])\n",
    "        if i==0: h.append(l)\n",
    "l2 = plt.legend(handles=h, bbox_to_anchor=(.01, .75), loc='center left', frameon=False)\n",
    "\n",
    "plt.xlim(1/64,1/2)\n",
    "plt.xlabel(r'period [year]')\n",
    "plt.ylabel('spectral power')\n",
    "# plt.semilogx()\n",
    "plt.gca().set_yscale('log', basey=10)\n",
    "plt.gca().set_xscale('log', basex=2)\n",
    "plt.gca().set_xticks([2.0**j for j in np.arange(-6,0)])\n",
    "plt.gca().set_xticklabels([int(2.0**-j) for j in np.arange(-6,0)])\n",
    "# plt.savefig(f'{path_results}/paper/GMST_SHF_spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4,3))\n",
    "# plt.gca().tick_params(labelsize=14)\n",
    "\n",
    "h, h_ = [], []\n",
    "for i, gmst in enumerate([gmst_had, gmst_ctrl, gmst_lpd]):\n",
    "    ls = [':','-','--'][i]\n",
    "    (spec, freq, jackknife) = ATS(gmst).spectrum()\n",
    "#     l_, = plt.plot([0,0], [0,0], c='k', ls=ls, label=['HIST', 'HIGH', 'LOW'][i])\n",
    "#     h_.append(l_)\n",
    "    l, = plt.plot(freq, spec, label='GMST', c='C9', ls=ls)\n",
    "    l_, = plt.plot([0,0],[0,1], ls=ls, c='grey', label=['HIST','HIGH','LOW'][i])\n",
    "    h_.append(l_)\n",
    "    \n",
    "    if i==1: h.append(l)\n",
    "l1 = plt.legend(handles=h_, bbox_to_anchor=(.3, .75), loc='center left', frameon=False)\n",
    "\n",
    "for i in range(2):\n",
    "    ls = ['-','--'][i]\n",
    "    toa = [TOA_ctrl, TOA_lpd][i]\n",
    "    toa_ = (toa-xr_quadtrend(toa))*spy/1e21\n",
    "    shf  = [SHF_ctrl, SHF_lpd][i]\n",
    "    shf_ = (shf[f'Global_Ocean'] - xr_quadtrend(shf[f'Global_Ocean']))/1e21\n",
    "    div = toa_.assign_coords(time=shf_.time.values)-shf_\n",
    "    (spec, freq, jackknife) = ATS(div).spectrum()\n",
    "    l, = plt.plot(freq, spec, label=r'TOA$-$SHF', c='C8', ls=ls)\n",
    "    if i==0: h.append(l)\n",
    "l1 = plt.legend(handles=h_, loc='lower left', frameon=False, ncol=3)\n",
    "plt.gca().add_artist(l1)\n",
    "l2 = plt.legend(handles=h, loc='upper left', frameon=False, ncol=2)\n",
    "\n",
    "plt.xlim(1/64,1/2)\n",
    "plt.xlabel('period [year]')\n",
    "plt.ylabel(r'spectral power')\n",
    "# plt.semilogx()\n",
    "plt.gca().set_yscale('log', basey=10)\n",
    "plt.gca().set_xscale('log', basex=2)\n",
    "plt.gca().set_xticks([2.0**j for j in np.arange(-6,0)])\n",
    "plt.gca().set_xticklabels([int(2.0**-j) for j in np.arange(-6,0)])\n",
    "plt.savefig(f'{path_results}/paper/GMST_TOA-SHF_spectra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xr.DataArray(data=[3*np.sin(t/np.pi) + 2*np.sin(2*t/np.pi) for t in np.arange(10000)/10], dims='time', coords={'time':np.arange(10000)/10})\n",
    "(spec, freq, jackknife) = ATS(a).spectrum()\n",
    "f, ax = plt.subplots(2,1)\n",
    "ax[0].plot(a.time, a)\n",
    "ax[1].plot(freq, spec)\n",
    "ax[1].loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot([0,1],[0,i], label=i)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.4,4))\n",
    "# plt.gca().tick_params(labelsize=14)\n",
    "h, h_ = [], []\n",
    "for i, ts in enumerate([SHF_ctrl, SHF_lpd]):\n",
    "    ls = ['-', '--'][i]\n",
    "    for j, basin in enumerate(['Global', 'Atlantic','Pacific', 'Southern']):\n",
    "        c = ['k' ,'C0','C1','C3'][j]\n",
    "        ts_ = (ts[f'{basin}_Ocean'] - xr_quadtrend(ts[f'{basin}_Ocean']))/1e21\n",
    "        (spec, freq, jackknife) = ATS(ts_).spectrum()\n",
    "        shift= [1,1/5,1/400,1/600][j]\n",
    "        l, = plt.plot(freq, spec*shift,\n",
    "                      label=f'SHF {basin}',\n",
    "                      ls=ls, c=c, alpha=[1,.7,.7,.7][j])\n",
    "        l_, = plt.plot([0,0],[0,1], ls=ls, c='grey', label=['HIGH','LOW'][i])\n",
    "        if j==0:  h_.append(l_)\n",
    "        if i==0:\n",
    "            h.append(l)\n",
    "            if j>0:  plt.arrow(2**(-6+0.03*j), spec[4], 0, -(spec[4]-spec[4]*shift),\\\n",
    "                               length_includes_head=True, width=1e-5, head_width=.0004, head_length=.01, color=c)\n",
    "l1 = plt.legend(handles=h_, loc='lower left', frameon=False, ncol=2)\n",
    "plt.gca().add_artist(l1)\n",
    "l2 = plt.legend(handles=h, loc='upper left', frameon=False, ncol=2)\n",
    "\n",
    "plt.xlim(1/64,1/2)\n",
    "plt.xlabel(r'period [year]')\n",
    "plt.ylabel('surface heat flux anomaly spectral power')\n",
    "# plt.semilogx()\n",
    "plt.gca().set_yscale('log', basey=10)\n",
    "plt.gca().set_xscale('log', basex=2)\n",
    "plt.gca().set_xticks([2.0**j for j in np.arange(-6,0)])\n",
    "plt.gca().set_xticklabels([int(2.0**-j) for j in np.arange(-6,0)])\n",
    "plt.savefig(f'{path_results}/paper/SHF_spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 5: OHC depth-zonal integral Hovmöller diagram + standard deviation (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lpd_lat = lpd.TLAT.mean(axis=1)\n",
    "extents = [(-78,90), (-34,70), (-34,70), (-34,30)]\n",
    "height_ratios = [a[1]-a[0] for a in extents]\n",
    "f, ax = plt.subplots(4, 4, figsize=(6.4,8), sharex='col',\n",
    "                     gridspec_kw={\"width_ratios\":[1, 1, 0.05, .5], \"height_ratios\":height_ratios, \"wspace\":0.03, \"hspace\":0.03})\n",
    "cY, cX = np.meshgrid(ctrl.t_lat, ctrl.time)\n",
    "lY, lX = np.meshgrid(lpd.TLAT.mean(axis=1), lpd.time)\n",
    "vex, ims = [2.5e16, 1.5e16, 2e16, .7e16], []\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Indian']):\n",
    "    kwargs = {'cmap':cmocean.cm.balance, 'vmin':-vex[i], 'vmax':vex[i]}\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    im = ax[i,0].pcolormesh(cX, cY, ctrl[key]-xr_quadtrend(ctrl[key]), **kwargs)\n",
    "    ims.append(im)\n",
    "    ax[i,1].pcolormesh(lX, lY, (lpd[key]-xr_quadtrend(lpd[key]))/100, **kwargs)\n",
    "    for j in [0,1,3]:  \n",
    "        ax[i,j].axhline(0, c='grey', lw=.5, ls='--')\n",
    "        ax[i,j].set_yticks(np.arange(-60,100,30))\n",
    "        ax[i,j].set_ylim(extents[i])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,0].text(60, extents[i][1]-10, ocean, c='g')\n",
    "    ax[i,0].set_ylabel('latitude')\n",
    "    \n",
    "    ax[i,3].plot((ctrl[key]-xr_quadtrend(ctrl[key])).std(dim='time')    , ctrl.t_lat, c='k')\n",
    "    ax[i,3].plot((lpd[key] -xr_quadtrend(lpd[key] )).std(dim='time')/100, lpd_lat   , c='k', ls='--')\n",
    "    ax[i,3].set_yticklabels([])\n",
    "    \n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,3])\n",
    "    \n",
    "    cb = f.colorbar(ims[i], cax=ax[i,2])#, ticks=np.arange(-3e16,4e16,1e16))\n",
    "    cb.outline.set_visible(False)\n",
    "    \n",
    "ax[0,0].text(60, -75, 'Southern Ocean', c='g')\n",
    "for j in range(2):\n",
    "    ax[0,j].axhline(-31.5, c='g', lw=.8)\n",
    "    ax[0,j].text(.5, 1.02, ['HIGH', 'LOW'][j], transform=ax[0,j].transAxes, ha='center')\n",
    "    ax[-1,j].set_xlabel('time [model years]')\n",
    "    ax[-1,-j-1].set_xlabel('[ZJ/m]')\n",
    "ax[0,3].text(.5, 1.02, 'st. dev.', transform=ax[0,3].transAxes, ha='center')\n",
    "    \n",
    "f.align_xlabels()\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_Hovmoeller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpd_lat = lpd.TLAT.mean(axis=1)\n",
    "extents = [(-78,90), (-34,70), (-34,70), (-34,30)]\n",
    "height_ratios = [a[1]-a[0] for a in extents]\n",
    "f, ax = plt.subplots(4, 4, figsize=(6.4,8), sharex='col',\n",
    "                     gridspec_kw={\"width_ratios\":[1, 1, 0.05, .5], \"height_ratios\":height_ratios, \"wspace\":0.03, \"hspace\":0.03},\n",
    "                     constrained_layout=True)\n",
    "cY, cX = np.meshgrid(ctrl.t_lat, ctrl.time/365)\n",
    "lY, lX = np.meshgrid(lpd.TLAT.mean(axis=1), lpd.time/365)\n",
    "# vex, ims = [15, 10, 10, 5], []\n",
    "\n",
    "vex, ims = [12, 9, 9, 6], []\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Indian']):\n",
    "    kwargs = {'cmap':cmocean.cm.balance, 'vmin':-vex[i], 'vmax':vex[i]}\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    im = ax[i,0].pcolormesh(cX, cY, lowpass(ctrl[key]-xr_quadtrend(ctrl[key]),13)/1e15, **kwargs)\n",
    "    ims.append(im)\n",
    "    ax[i,1].pcolormesh(lX, lY, lowpass((lpd[key]-xr_quadtrend(lpd[key]))/100,13)/1e15, **kwargs)\n",
    "    for j in [0,1,3]:  \n",
    "        ax[i,j].axhline(0, c='grey', lw=.5, ls='--')\n",
    "        ax[i,j].set_yticks(np.arange(-60,100,30))\n",
    "        ax[i,j].set_ylim(extents[i])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "#     ax[i,0].text(60, extents[i][1]-10, ocean, c='g')\n",
    "    ax[i,0].yaxis.set_label_coords(-0.14,.5)\n",
    "    ax[i,0].set_ylabel(f'{ocean} Ocean\\nlatitude')\n",
    "    \n",
    "    ax[i,3].plot(lowpass(ctrl[key]-xr_quadtrend(ctrl[key]),13).std(dim='time')/1e15    , ctrl.t_lat, c='k', label='HIGH')\n",
    "    ax[i,3].plot(lowpass(lpd[key] -xr_quadtrend(lpd[key] ),13).std(dim='time')/1e15/100, lpd_lat   , c='k', label='LOW' , ls='--')\n",
    "    ax[i,3].set_yticklabels([])\n",
    "    \n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,3])\n",
    "    \n",
    "    cb = f.colorbar(ims[i], cax=ax[i,2], ticks=np.arange(-12,13,3))#, ticks=np.arange(-3e16,4e16,1e16))\n",
    "    cb.outline.set_visible(False)\n",
    "    \n",
    "ax[0,3].legend(fontsize=6, handlelength=1.5, bbox_to_anchor=(1.05, .88), loc='center right', frameon=False)\n",
    "# ax[0,0].text(60, -75, 'Southern Ocean', c='g')\n",
    "for j in range(2):\n",
    "    ax[0,j].axhline(-31.5, c='g', lw=.8)\n",
    "    ax[0,j].text(.5, 1.02, ['HIGH', 'LOW'][j], transform=ax[0,j].transAxes, ha='center')\n",
    "    ax[-1,j].set_xlabel('time [model years]')\n",
    "    ax[-1,-j-1].set_xlabel('[PJ/m]')\n",
    "ax[0,3].text(.5, 1.02, 'st. dev.', transform=ax[0,3].transAxes, ha='center')\n",
    "    \n",
    "f.align_xlabels()\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_Hovmoeller_lowpass13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 6: OHC horizontal integral Hovmöller diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "oceans = ['Global', 'Atlantic', 'Pacific', 'Southern']\n",
    "das = [ctrl_qd, lpd_qd]\n",
    "maxv = 60\n",
    "\n",
    "fig = plt.figure(figsize=(6.4,9), constrained_layout=True)\n",
    "gs0 = matplotlib.gridspec.GridSpec(4, 3, left=.1, right=.98, bottom=.11, top=.98, wspace=.05, hspace=.045, width_ratios=[1, 1, .25])\n",
    "\n",
    "# ax[0,3].text(.5, 1.02, 'st. dev.', transform=ax[0,3].transAxes, ha='center')\n",
    "\n",
    "# if offset==True: x = (da-da.isel(time=slice(0,30)).mean(dim='time')).T/1e21\n",
    "\n",
    "for i, ocean in enumerate(oceans):\n",
    "    name = f'{ocean}_Ocean'    \n",
    "    \n",
    "    for j, da in enumerate(das):\n",
    "        \n",
    "        if j==0:\n",
    "            gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,2], hspace=0)\n",
    "            ax_t = fig.add_subplot(gs00[0])\n",
    "            ax_t.set_ylim((-1500,0))\n",
    "            ax_t.set_xticks([])\n",
    "            ax_t.set_yticks([-1500, -1000, -500, 0])\n",
    "#             ax_t.spines['top'].set_visible(False)\n",
    "#             ax_t.spines['right'].set_visible(False)\n",
    "            \n",
    "            ax_b = fig.add_subplot(gs00[1])\n",
    "            ax_b.set_ylim((-6000,-1500))\n",
    "            ax_b.set_yticks([-6000,-4500,-3000])\n",
    "#             ax_b.spines['top'].set_visible(False)\n",
    "#             ax_b.spines['right'].set_visible(False)\n",
    "            \n",
    "        \n",
    "        gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,j], hspace=0)\n",
    "        ax_top = fig.add_subplot(gs00[0])\n",
    "        ax_top.set_ylim((-1500,0))\n",
    "        ax_top.set_xticks([])\n",
    "        ax_top.set_yticks([-1500, -1000, -500, 0])\n",
    "        \n",
    "        ax_bot = fig.add_subplot(gs00[1])\n",
    "        ax_bot.set_ylim((-6000,-1500))\n",
    "        ax_bot.set_yticks([-6000,-4500,-3000])\n",
    "        \n",
    "        da = das[j][f'OHC_levels_{name}']\n",
    "        x = da.T/1e18\n",
    "        X, Y = np.meshgrid(da.time, da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j])\n",
    "        \n",
    "        for k, ax in enumerate([ax_t, ax_b]):\n",
    "            ax.plot(da.std(dim='time').values/1e18, -da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j], ls=['-','--'][j], c='k')\n",
    "\n",
    "        for k, ax in enumerate([ax_top, ax_bot]):\n",
    "            im = ax.pcolormesh(X, -Y, x, vmin=-maxv, vmax=maxv, cmap=cmocean.cm.balance)\n",
    "        if i==0:\n",
    "            ax_top.text(.5,1.05,['HIGH', 'LOW'][j], transform=ax_top.transAxes)\n",
    "                \n",
    "        if j==2:\n",
    "            for ax in [ax_top, ax_bot]:\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.plot(da)\n",
    "            \n",
    "        \n",
    "        if j==0:\n",
    "            ax_bot.set_ylabel(f'{ocean} Ocean', horizontalalignment = 'left')\n",
    "        \n",
    "        if j>0:\n",
    "            ax_top.set_yticklabels([])\n",
    "            ax_bot.set_yticklabels([])\n",
    "            ax_t.set_yticklabels([])\n",
    "            ax_b.set_yticklabels([])\n",
    "            \n",
    "                \n",
    "        \n",
    "        if i==len(oceans)-1:\n",
    "            ax_bot.set_xlabel('time [model years]')\n",
    "            ax_b.set_xlabel('std [EJ/m]')\n",
    "        else:\n",
    "            ax_bot.set_xticklabels([])\n",
    "            ax_t.set_xticklabels([])\n",
    "            ax_b.set_xticklabels([])\n",
    "            \n",
    "            \n",
    "cax = fig.add_axes([0.1, 0.04, 0.88, 0.02])\n",
    "fig.colorbar(im, cax=cax, orientation='horizontal', label='OHC anomaly [EJ/m]', extend='both')\n",
    "plt.savefig(f'{path_results}/paper/OHC_vertical_Hovmoeller_0-6km_ctrl_lpd_qd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oceans = ['Global', 'Atlantic', 'Pacific', 'Southern']\n",
    "das = [ctrl_qd, lpd_qd]\n",
    "maxv = 50\n",
    "\n",
    "fig = plt.figure(figsize=(6.4,9), constrained_layout=True)\n",
    "gs0 = matplotlib.gridspec.GridSpec(4, 3, left=.12, right=.98, bottom=.11, top=.98, wspace=.07, hspace=.06, width_ratios=[1, 1, .25])\n",
    "\n",
    "\n",
    "#     \n",
    "# if offset==True: x = (da-da.isel(time=slice(0,30)).mean(dim='time')).T/1e21\n",
    "for i in range(3):\n",
    "    ax_title = fig.add_subplot(gs0[0,i])\n",
    "    ax_title.axis('off')\n",
    "    ax_title.text(.5, 1.02, ['HIGH', 'LOW', 'st. dev.'][i], transform=ax_title.transAxes, ha='center')\n",
    "\n",
    "for i, ocean in enumerate(oceans):\n",
    "    \n",
    "    name = f'{ocean}_Ocean'    \n",
    "    \n",
    "    for j, da in enumerate(das):\n",
    "        \n",
    "        if j==0:  # std plots\n",
    "            gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,2], hspace=0)\n",
    "            ax_t = fig.add_subplot(gs00[0])\n",
    "            ax_t.set_ylim((-1500,0))\n",
    "            ax_t.set_xticks([])\n",
    "            ax_t.set_yticks([-1500, -1000, -500, 0])\n",
    "            \n",
    "            ax_b = fig.add_subplot(gs00[1])\n",
    "            ax_b.set_ylim((-6000,-1500))\n",
    "            ax_b.set_yticks([-6000,-4500,-3000])\n",
    "            \n",
    "        \n",
    "        da = das[j][f'OHC_levels_{name}']\n",
    "        x = da.T/1e18\n",
    "        X, Y = np.meshgrid(da.time, da.coords[['depth_t', 'z_t'][j]]/[1e3, 1e5][j])\n",
    "        \n",
    "        gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,j], hspace=0)\n",
    "        ax_top = fig.add_subplot(gs00[0])\n",
    "        ax_top.set_ylim((-1.5,0.0))\n",
    "        ax_top.set_xticks([])\n",
    "        ax_top.set_yticks([-1.5, -1.0, -0.5, 0.0])\n",
    "        \n",
    "        ax_bot = fig.add_subplot(gs00[1])\n",
    "        ax_bot.set_ylim((-6.0,-1.5))\n",
    "        ax_bot.set_yticks([-6.0,-4.5,-3.0])\n",
    "        \n",
    "        for k, ax in enumerate([ax_t, ax_b]):\n",
    "            ax.plot(lowpass(da,13).std(dim='time').values/1e18, -da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j], ls=['-','--'][j], c='k', label=['HIGH', 'LOW'][j])\n",
    "                \n",
    "        for k, ax in enumerate([ax_top, ax_bot]):\n",
    "            im = ax.pcolormesh(X, -Y, lowpass(x.T,13).T, vmin=-maxv, vmax=maxv, cmap=cmocean.cm.balance)\n",
    "        \n",
    "        if j==0:\n",
    "            ax_bot.yaxis.set_label_coords(-0.17,1)\n",
    "            ax_bot.set_ylabel(f'{ocean} Ocean\\ndepth [km]', horizontalalignment = 'center')\n",
    "#             ax_bot.text(60, -5.5, f'{ocean} Ocean', horizontalalignment = 'left', c='green')\n",
    "        \n",
    "        if j>0:\n",
    "            ax_top.set_yticklabels([])\n",
    "            ax_bot.set_yticklabels([])\n",
    "            ax_t.set_yticklabels([])\n",
    "            ax_b.set_yticklabels([])\n",
    "            \n",
    "                \n",
    "        \n",
    "        if i==len(oceans)-1:\n",
    "            ax_bot.set_xlabel('time [model years]')\n",
    "            ax_b.set_xlabel('[EJ/m]')\n",
    "        else:\n",
    "            ax_bot.set_xticklabels([])\n",
    "            ax_t.set_xticklabels([])\n",
    "            ax_b.set_xticklabels([])\n",
    "            \n",
    "            \n",
    "    if i==0: ax_b.legend(frameon=False, handlelength=1.5, fontsize=6, loc=4)\n",
    "            \n",
    "            \n",
    "cax = fig.add_axes([0.1, 0.04, 0.88, 0.015])\n",
    "fig.colorbar(im, cax=cax, orientation='horizontal', label='OHC anomaly [EJ/m]', extend='both')\n",
    "plt.savefig(f'{path_results}/paper/OHC_vertical_Hovmoeller_0-6km_ctrl_lpd_qd_lowpass13')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: variances for different bandpass filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much area/volume do the major ocean basins represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xr_DataArrays import xr_DZ, xr_AREA\n",
    "from paths import file_RMASK_ocn\n",
    "from regions import regions_dict\n",
    "DZT = xr_DZ('ocn')\n",
    "AREA = xr_AREA('ocn')\n",
    "MASK = xr.open_dataarray(file_RMASK_ocn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = AREA.where(MASK>0).sum(dim=['nlat','nlon'],skipna=True).values\n",
    "total_volume = (DZT*AREA.where(MASK>0)).sum(dim=['z_t','nlat','nlon'],skipna=True).values\n",
    "print(f'total area {total_area} volume {total_volume}')\n",
    "for i in [1,2,6]:\n",
    "    area = AREA.where(MASK==i).sum(dim=['nlat','nlon'],skipna=True).values\n",
    "    volume = (DZT*AREA.where(MASK==i)).sum(dim=['z_t','nlat','nlon'],skipna=True).values\n",
    "    print(f'{regions_dict[i]:15}: area {area/total_area*100:2.0f}%; volume {volume/total_volume*100:2.0f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25.8+38.1+17.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26.8+41.2+17.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
