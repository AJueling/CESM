{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file_paper')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from paths import path_samoc, path_results\n",
    "from xr_regression import xr_quadtrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color conventions:\n",
    "- global black\n",
    "- Atlantic blue\n",
    "- Pacific orange\n",
    "- Southern red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1: exp decay $\\Delta$OHC / SST\n",
    "from `OHC-ctrl_vs_lpd.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHC data\n",
    "ctrl = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl.nc')\n",
    "ctrl = ctrl.assign_coords(time=ctrl.time.values/365)\n",
    "lpd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd.nc' )\n",
    "lpd  = lpd.assign_coords(time=lpd .time.values/365)\n",
    "\n",
    "ctrl_qd = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl_qd.nc', decode_times=False)\n",
    "lpd_qd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd_qd.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST data\n",
    "SST_ctrl = xr.open_dataarray(f'{path_samoc}/SST/SST_global_mean_timeseries_ctrl.nc')\n",
    "SST_lpd  = xr.open_dataarray(f'{path_samoc}/SST/SST_global_mean_timeseries_lpd.nc')\n",
    "SST_ctrl = SST_ctrl.assign_coords(time=SST_ctrl.time.values/365)\n",
    "SST_lpd = SST_lpd.assign_coords(time=SST_lpd.time.values/365)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SST_ctrl-SST_ctrl.shift(time=1)).plot()\n",
    "(SST_lpd-SST_lpd.shift(time=1)).plot()\n",
    "plt.axhline(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(x, a, b):\n",
    "    return a*np.exp(-x/b)\n",
    "\n",
    "def exp_fit(da_fit):\n",
    "    initial_guess = (da_fit.values[0], 1000.)\n",
    "    return curve_fit(exp_decay, da_fit.time, da_fit.values, p0=initial_guess)[0]\n",
    "   \n",
    "def adjustment_time(da):\n",
    "    Delta_da = (da - da.shift(time=1))[1:]\n",
    "    if len(da.coords)==1:  # 1D time series\n",
    "        popt = exp_fit(Delta_da)  # array of size ((2))\n",
    "    else:\n",
    "        stacked = False\n",
    "        if len(da.coords)>2:  # need to be stacked\n",
    "            stacked = True\n",
    "            Delta_da = Delta_da.stack(stacked_coord=list(da.coords.keys())[1:])\n",
    "            print(Delta_da)\n",
    "        assert len(Delta_da.coords)==2\n",
    "        coord = list(Delta_da.coords)[1]\n",
    "        A = np.zeros((len(Delta_da[coord]), 2))\n",
    "        for i, c in tqdm(enumerate(Delta_da[coord])):\n",
    "            if np.any(np.isnan(c)):  continue  # skipping nans\n",
    "            A[i,:] = exp_fit(Delta_da[:,i])\n",
    "        D = Delta_da.isel({'time':0}).drop('time')  # skeleton DataArray with correct dimensions\n",
    "        popt0 = D.copy(data=A[:,0])\n",
    "        popt1 = D.copy(data=A[:,1])\n",
    "        if stacked==True:  # unstacking\n",
    "            popt0 = popt0.unstack()\n",
    "            popt1 = popt1.unstack()\n",
    "        popt0.name, popt1.name= 'popt0','popt1'\n",
    "        popt = xr.merge([popt0, popt1])\n",
    "    return popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series: depth-lat-lon integrated OHC\n",
    "def plot_adjustment_timeseries(da, ax):\n",
    "    Delta_da = (da - da.shift(time=1))\n",
    "    popt = adjustment_time(da)\n",
    "    print(popt)\n",
    "    ax.axhline(0, c='k', lw=.5)\n",
    "    ax.plot(Delta_da.time[1:], Delta_da.values[1:], lw=.2)\n",
    "    ax.plot(Delta_da.time[1:], exp_decay(Delta_da.time[1:], *popt), 'r-', label=\"Fitted Curve\")\n",
    "    tau_symbol = r'$\\tau$'\n",
    "    if popt[1]>1000:\n",
    "        tau = '>1000'\n",
    "    elif popt[1]<5:\n",
    "        tau = '<5'\n",
    "    else:\n",
    "        tau= f'{popt[1]:3.0f}'\n",
    "    ax.text(.1, .85, f'{tau_symbol} = {tau} years', transform=ax.transAxes, fontsize=8)\n",
    "#     cax.set_ylim((-10,20))\n",
    "    return\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(6.4,5), sharex='col')\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    Delta = r'$\\Delta$'\n",
    "    for j in range(2):\n",
    "        ax[i,2*j+1].set_yticklabels([])\n",
    "        if i==0: plot_adjustment_timeseries([SST_ctrl, SST_lpd][j], ax[i,j])\n",
    "    \n",
    "        plot_adjustment_timeseries([ctrl,lpd][j][f'OHC_{ocean}_Ocean']/1e21, ax[i,j+2])\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    ax[i,2].get_shared_y_axes().join(ax[i,2], ax[i,3])\n",
    "        \n",
    "    ax[i,0].set_ylabel(f'{ocean} Ocean\\n{Delta}SST [K]')\n",
    "    ax[i,2].set_ylabel(f'{Delta}OHC [ZJ]')\n",
    "\n",
    "for j in range(4):\n",
    "    ax[-1,j].set_xlabel('time (model years)')\n",
    "    ax[0,j].title.set_text(['CTRL', 'LPD'][j%2])\n",
    "\n",
    "fig.align_ylabels()\n",
    "    # share x-axis\n",
    "#     if i<4:\n",
    "        \n",
    "    \n",
    "    \n",
    "    #     for k in range(4):\n",
    "#     ax[-2].get_shared_x_axes().join(ax[-2], ax[j+3])\n",
    "#     ax[j].set_xticklabels([])\n",
    "#     ax[j+1].set_xticklabels([])\n",
    "\n",
    "# for i in range(4):\n",
    "\n",
    "# plt.subplots_adjust(bottom=0.08, left=.12, right=0.99, top=0.99, wspace=.06, hspace=.1)\n",
    "fig.savefig(f'{path_results}/paper/equilibration_SST_OHC')  # comment out time selection above\n",
    "# plt.savefig(f'{path_results}/OHC/OHC_equilibration_select')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinup = 50  # how many years to ignore due to spinup effects: data from year 51 of ctrl run\n",
    "\n",
    "ctrl = ctrl.isel(time=np.arange(50,300))\n",
    "lpd  = lpd .isel(time=np.arange(0,300-spinup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2: SST index regression patterns\n",
    "from `OHC-ctrl_vs_lpd.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpd_lat = lpd.TLAT.mean(axis=1)\n",
    "\n",
    "f, ax = plt.subplots(1, 2 , sharex=True, figsize=(6.4,2.5))\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    c = ['k' ,'C0','C1','C3'][i]\n",
    "# mean\n",
    "    ax[0].plot(ctrl.t_lat, ctrl[key].mean(dim='time')    , c=c , label=ocean)\n",
    "    ax[0].plot(lpd_lat   , lpd [key].mean(dim='time')/100, c=c , ls='--')\n",
    "    ax[0].set_ylabel('mean OHC [J/m]')\n",
    "# std of quad. detrended\n",
    "    ax[1].plot(ctrl.t_lat, (ctrl[key]-xr_quadtrend(ctrl[key])).std(dim='time'), c=c)\n",
    "    ax[1].plot(lpd_lat   , (lpd[key] -xr_quadtrend(lpd[key] )).std(dim='time')/100, c=c , ls='--')\n",
    "    ax[1].set_ylabel('standard deviation OHC [J/m]')\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('latitude')\n",
    "    ax[i].set_xlim((-80,92))\n",
    "    ax[i].set_xticks(np.arange(-60,100,30))\n",
    "    ax[i].set_xticklabels(np.arange(-60,100,30))\n",
    "ax[0].legend(fontsize=8, frameon=False)\n",
    "\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_mean_std_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3: spatial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 4: SST index spectra\n",
    "from `SST_indices.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bb_analysis_timeseries import AnalyzeTimeSeries as ATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(6.4,4), sharex=True, constrained_layout=True)\n",
    "for i, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "    if run=='had':\n",
    "        dt = 'GMST_tfdt'\n",
    "    else:\n",
    "        dt = 'quadratic_pwdt'\n",
    "    \n",
    "    for j, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        if idx=='TPI':\n",
    "            da1 = xr.open_dataarray(f'{path_samoc}/SST/{idx}1_{dt}_raw_{run}.nc')\n",
    "            da2 = xr.open_dataarray(f'{path_samoc}/SST/{idx}2_{dt}_raw_{run}.nc')\n",
    "            da3 = xr.open_dataarray(f'{path_samoc}/SST/{idx}3_{dt}_raw_{run}.nc')\n",
    "            da = da2 - (da1+da3)/2\n",
    "        else:\n",
    "            da = xr.open_dataarray(f'{path_samoc}/SST/{idx}_{dt}_raw_{run}.nc')\n",
    "        \n",
    "        ft, fc = 'lowpass', 13\n",
    "        spec = ATS(da).spectrum(filter_type=ft, filter_cutoff=fc)  # spectrum\n",
    "        rnsp = ATS(da).mc_ar1_spectrum(filter_type=ft, filter_cutoff=fc)  # red noise spectrum\n",
    "\n",
    "        ax[j,i].plot(1/rnsp[1,:], rnsp[3,:]   , c='C1',                 label='AR(1) 95% C.I.')\n",
    "#         ax[j,i].plot(1/rnsp[1,:], rnsp[0,:]   , c='C1', lw=.5, ls=':' , label='AR(1) median')\n",
    "        ax[j,i].plot(1/spec[1]  , spec[0]     , c='C0',                 label='MT spectrum')\n",
    "        ax[j,i].loglog(1/spec[1], spec[2].T[1], c='C0', lw=.5, ls='--', label='jackknife est.')\n",
    "        ax[j,i].set_xscale('log')\n",
    "        ax[j,i].set_yscale('log')     \n",
    "        ax[j,i].set_xlim((10,100))\n",
    "        ax[j,i].set_ylim((1e-4, 1.5*np.max(spec[2].T[1])))\n",
    "        ax[j,i].set_yticklabels([])\n",
    "        ax[j,0].set_ylabel(f'{idx} index\\nspectral power')\n",
    "        if i==0 and j==0:  ax[j,i].legend(loc=4, fontsize=8, frameon=False)\n",
    "#         ax[j,i].set_xticklabels([])\n",
    "        ax[j,i].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ax[2,i].set_xticks([10,20,40,80])\n",
    "    ax[2,i].set_xticklabels([10,20,40,80])\n",
    "    \n",
    "    ax[0,i].title.set_text(run.upper())\n",
    "    ax[2,i].set_xlabel('period [years]')\n",
    "plt.savefig(f'{path_results}/paper/spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 5: OHC time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2 , figsize=(6.4,2.5), sharey=True,\n",
    "                     gridspec_kw={\"width_ratios\":[len(ctrl.time), len(lpd.time)]})\n",
    "for i in range(2):\n",
    "    ax[i].axhline(0, c='grey', lw=.5)\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    key = f'OHC_{ocean}_Ocean'\n",
    "    c = ['k' ,'C0','C1','C3'][i]\n",
    "    for j, da in enumerate([ctrl_qd, lpd_qd]):\n",
    "        x = da[key]/1e21\n",
    "        ax[j].plot(x.time, x, lw=.5, c=c ,label=f'{ocean}')\n",
    "#         ax[j].plot(x.time, lowpass(x,5), c=c ,label=f'{ocean}')\n",
    "\n",
    "ax[0].set_ylabel('OHC anomaly [ZJ]')\n",
    "ax[1].legend(fontsize=8, ncol=2, frameon=False)\n",
    "plt.savefig(f'{path_results}/paper/OHC_time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 6: OHC depth-zonal integral mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 7: OHC depth-zonal integral Hovmöller diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = [(-78,90), (-40,80), (-40,70), (-40,30)]\n",
    "height_ratios = [a[1]-a[0] for a in extents]\n",
    "f, ax = plt.subplots(4, 3, figsize=(6.4,8), sharex='col',\n",
    "                     gridspec_kw={\"width_ratios\":[1,1, 0.05], \"height_ratios\":height_ratios})\n",
    "cY, cX = np.meshgrid(ctrl.t_lat, ctrl.time)\n",
    "lY, lX = np.meshgrid(lpd.TLAT.mean(axis=1), lpd.time)\n",
    "vex, ims = [3e16, 2e16, 2e16, 1e16], []\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Indian']):\n",
    "    kwargs = {'cmap':'RdBu', 'vmin':-vex[i], 'vmax':vex[i]}\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    im = ax[i,0].pcolormesh(cX, cY, ctrl[key]-xr_quadtrend(ctrl[key]), **kwargs)\n",
    "    ims.append(im)\n",
    "    ax[i,1].pcolormesh(lX, lY, (lpd[key]-xr_quadtrend(lpd[key]))/100, **kwargs)\n",
    "    for j in range(2):  \n",
    "        ax[i,j].axhline(0, c='grey', lw=.5, ls='--')\n",
    "        ax[i,j].set_yticks(np.arange(-60,100,30))\n",
    "        ax[i,j].set_ylim(extents[i])\n",
    "    if i==0:\n",
    "        ax[0,0].text(.05, .2, 'Southern Ocean', c='g', transform=ax[0,0].transAxes)\n",
    "        for j in range(2):\n",
    "            ax[0,j].axhline(-31.5, c='g', lw=.8)\n",
    "            ax[0,j].text(.5, 1.02, ['CTRL', 'LPD'][j], transform=ax[0,j].transAxes, ha='center')\n",
    "            ax[-1,j].set_xlabel('time [model years]')\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,0].text(.05, .9, ocean, c='g', transform=ax[i,0].transAxes)\n",
    "    ax[i,0].set_ylabel('latitude')\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    cb = f.colorbar(ims[i], cax=ax[i,2], ticks=np.arange(-3e16,4e16,1e16))\n",
    "    cb.outline.set_visible(False)\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_Hovmoeller')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 8: OHC horizontal integral Hovmöller diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertical_Hovmoeller(ctrl, lpd, ylim, fn, offset=True):\n",
    "    oceans = ['Global', 'Atlantic', 'Pacific', 'Southern']\n",
    "    das = [ctrl, lpd]\n",
    "    f, ax = plt.subplots(len(oceans),2, figsize=(6.4,5), sharey=True, sharex='col')\n",
    "    for j, ocean in enumerate(oceans):\n",
    "        if j<5:  name = f'{ocean}_Ocean'\n",
    "        else:    name = ocean\n",
    "        da1 = das[0][f'OHC_levels_{name}']\n",
    "        da2 = das[1][f'OHC_levels_{name}']\n",
    "        maxv = np.max([(da1-da1.isel(time=slice(0,30)).mean(dim='time')).max(), \n",
    "                       (da2-da2.isel(time=slice(0,30)).mean(dim='time')).max()])/1e21/1.2\n",
    "        for i in range(2):\n",
    "            da = das[i][f'OHC_levels_{name}']\n",
    "            X, Y = np.meshgrid(da.time, -da.coords[['depth_t', 'z_t'][i]]/[1e3, 1e5][i])\n",
    "            if offset==True: x = (da-da.isel(time=slice(0,30)).mean(dim='time')).T/1e21\n",
    "            else:            x = da.T/1e21\n",
    "            im = ax[j,i].pcolormesh(X, Y, x, vmin=-maxv, vmax=maxv, cmap=cmocean.cm.balance)\n",
    "#             if i==1:  colorbar(im)\n",
    "            if i==1:  f.colorbar(im, ax=ax[j,i], orientation='vertical', fraction=.1, label='[ZJ/m]')\n",
    "        ax[j,0].set_ylabel(ocean)\n",
    "        ax[j,0].set_ylim(ylim)\n",
    "    for i in range(2):\n",
    "        ax[0,i].text(.5,1.05,['CTRL', 'LPD'][i], transform=ax[0,i].transAxes)\n",
    "        ax[-1,i].set_xlabel('time [model years]')\n",
    "    plt.savefig(fn)\n",
    "    return\n",
    "\n",
    "        \n",
    "c, l = ctrl_qd, lpd_qd\n",
    "for j, ylim in enumerate([(-6,0), (-1,0)]):\n",
    "    ext = '_qd'\n",
    "    fn = f'{path_results}/paper/OHC_vertical_Hovmoeller_0-{-ylim[0]}km_ctrl_lpd{ext}'\n",
    "    print(fn)\n",
    "    plot_vertical_Hovmoeller(c, l, ylim, fn, offset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
