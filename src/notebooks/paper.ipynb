{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file_paper')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from paths import path_samoc, path_results\n",
    "from paths import file_ex_ocn_ctrl, file_ex_ocn_lpd\n",
    "from xr_regression import xr_quadtrend\n",
    "from bb_analysis_timeseries import AnalyzeTimeSeries as ATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color conventions:\n",
    "- global black\n",
    "- Atlantic blue\n",
    "- Pacific orange\n",
    "- Southern red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHC data\n",
    "ctrl = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl.nc')\n",
    "ctrl = ctrl.assign_coords(time=ctrl.time.values/365)\n",
    "lpd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd.nc' )\n",
    "lpd  = lpd.assign_coords(time=lpd .time.values/365)\n",
    "\n",
    "ctrl_qd = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_ctrl_qd.nc', decode_times=False)\n",
    "lpd_qd  = xr.open_dataset(f'{path_samoc}/OHC/OHC_integrals_lpd_qd.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST data\n",
    "SST_ctrl = xr.open_dataset(f'{path_samoc}/SST/SST_mean_timeseries_ctrl.nc')\n",
    "SST_lpd  = xr.open_dataset(f'{path_samoc}/SST/SST_mean_timeseries_lpd.nc')\n",
    "SST_ctrl = SST_ctrl.assign_coords(time=SST_ctrl.time.values/365)\n",
    "SST_lpd  = SST_lpd.assign_coords(time=SST_lpd.time.values/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinup = 50  # how many years to ignore due to spinup effects: data from year 51 of ctrl run\n",
    "\n",
    "ctrl = ctrl.isel(time=np.arange(50,300))\n",
    "lpd  = lpd .isel(time=np.arange(0,300-spinup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1: exp decay $\\Delta$OHC / SST\n",
    "data from `SST.ipynb`\n",
    "\n",
    "plot from `OHC-ctrl_vs_lpd.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharey=True, figsize=(6.4, 2.5))\n",
    "for i, da in enumerate([ctrl, lpd]):\n",
    "    ax[i].axhline(0, c='grey', lw=.5)\n",
    "    ax[i].plot(da.time, (da['OHC_Global_Ocean']-da['OHC_Global_Ocean'].shift(time=1))/1e21, c='k')\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "    ax[i].text(.05,.9, ['HIGH', 'LOW'][i], transform=ax[i].transAxes)\n",
    "Delta = r'$\\Delta$'\n",
    "ax[0].set_ylabel(f'annual difference {Delta}OHC [ZJ]')\n",
    "plt.savefig(f'{path_results}/paper/Delta_OHC_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: $\\Delta$OHC mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    means, stds = [], []\n",
    "    for j, da in enumerate([ctrl, lpd]):\n",
    "        da_ = (da[f'OHC_{ocean}_Ocean']-da[f'OHC_{ocean}_Ocean'].shift(time=1)).sel(time=slice(200,300))/1e21\n",
    "#         print(da_.time.sel(time=slice(200,300)))\n",
    "        means.append(da_.mean().values)\n",
    "        stds.append(da_.std().values)\n",
    "    print(f'{ocean:8} & ${means[0]:4.1f} \\pm {stds[0]:3.1f}$ & ${means[1]:3.1f} \\pm {stds[1]:3.1f}$ \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 2: SST index regression patterns\n",
    "from `OHC-ctrl_vs_lpd.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make orthographic AMO maps as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3: SST index spectra\n",
    "from `SST_indices.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(6.4,4), sharex=True, constrained_layout=True)\n",
    "for i, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "    if run=='had':\n",
    "        dt = 'GMST_tfdt'\n",
    "        tslice = slice(149)\n",
    "    elif run=='ctrl':\n",
    "        dt = 'quadratic_pwdt'\n",
    "        tslice = slice(1,251)  # ctrl AMO time series starts in year 50\n",
    "    elif run=='lpd':\n",
    "        dt = 'quadratic_pwdt'\n",
    "        tslice = slice(250)\n",
    "        \n",
    "    for j, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        if idx=='TPI':\n",
    "            da1 = xr.open_dataarray(f'{path_samoc}/SST/{idx}1_{dt}_raw_{run}.nc')\n",
    "            da2 = xr.open_dataarray(f'{path_samoc}/SST/{idx}2_{dt}_raw_{run}.nc')\n",
    "            da3 = xr.open_dataarray(f'{path_samoc}/SST/{idx}3_{dt}_raw_{run}.nc')\n",
    "            da = da2 - (da1+da3)/2\n",
    "        else:\n",
    "            da = xr.open_dataarray(f'{path_samoc}/SST/{idx}_{dt}_raw_{run}.nc')\n",
    "        \n",
    "        da_select = da.isel(time=tslice)\n",
    "        assert len(da_select) in [149, 250]\n",
    "        \n",
    "        ft, fc = 'lowpass', 13\n",
    "        spec = ATS(da_select).spectrum(filter_type=ft, filter_cutoff=fc)  # spectrum\n",
    "        rnsp = ATS(da_select).mc_ar1_spectrum(filter_type=ft, filter_cutoff=fc)  # red noise spectrum\n",
    "\n",
    "#         ax[j,i].plot(1/rnsp[1,:], rnsp[3,:]   , c='C1',                 label='AR(1) 95% C.I.')\n",
    "        ax[j,i].loglog(1/rnsp[1,:], rnsp[3,:]   , c='C1',                 label='AR(1) 95% C.I.')\n",
    "#         ax[j,i].plot(1/rnsp[1,:], rnsp[0,:]   , c='C1', lw=.5, ls=':' , label='AR(1) median')\n",
    "#         ax[j,i].plot(1/spec[1]  , spec[0]     , c='C0',                 label='MT spectrum')\n",
    "        ax[j,i].loglog(1/spec[1]  , spec[0]     , c='C0',                 label='MT spectrum')\n",
    "#         ax[j,i].loglog(1/spec[1], spec[2].T[1], c='C0', lw=.5, ls='--', label='jackknife est.')\n",
    "        ax[j,i].set_xlim((10,100))\n",
    "        ax[j,i].set_ylim((1e-4, 5*np.max(rnsp[3,:].T[1])))\n",
    "        ax[j,i].set_yticklabels([])\n",
    "        ax[j,i].xaxis.set_minor_formatter(NullFormatter())\n",
    "        ax[j,0].set_ylabel(f'{idx} index\\nspectral power')\n",
    "        if i==0 and j==0:  ax[j,i].legend(loc=4, fontsize=8, frameon=False)\n",
    "#         ax[j,i].set_xticklabels([])\n",
    "        ax[j,i].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ax[2,i].set_xticks([10,20,40,80])\n",
    "    ax[2,i].set_xticklabels([10,20,40,80])\n",
    "    \n",
    "    ax[0,i].title.set_text(['HIST', 'HIGH', 'LOW'][i])\n",
    "    ax[2,i].set_xlabel('period [years]')\n",
    "plt.savefig(f'{path_results}/paper/spectra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 4: OHC time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters import lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2 , figsize=(6.4,2.5), sharey=True)\n",
    "for i in range(2):\n",
    "    ax[i].axhline(0, c='grey', lw=.5)\n",
    "    ax[i].set_xlabel('time [model years]')\n",
    "\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Southern']):\n",
    "    key = f'OHC_{ocean}_Ocean'\n",
    "    c = ['k' ,'C0','C1','C3'][i]\n",
    "    for j, da in enumerate([ctrl_qd, lpd_qd]):\n",
    "        x = da[key]/1e21\n",
    "#         ax[j].plot(x.time, x, lw=.5, c=c ,label=f'{ocean}')\n",
    "        ax[j].plot(x.time, lowpass(x,5), c=c ,label=f'{ocean}')\n",
    "    \n",
    "for j in range(2):\n",
    "    ax[j].text(.05,.9, ['HIGH', 'LOW'][j], transform=ax[j].transAxes)\n",
    "ax[0].set_ylabel('OHC anomaly [ZJ]')\n",
    "ax[1].legend(fontsize=8, ncol=2, frameon=False)\n",
    "plt.savefig(f'{path_results}/paper/OHC_time_series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 5: OHC depth-zonal integral Hovm√∂ller diagram + standard deviation (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpd_lat = lpd.TLAT.mean(axis=1)\n",
    "extents = [(-78,90), (-34,70), (-34,70), (-34,30)]\n",
    "height_ratios = [a[1]-a[0] for a in extents]\n",
    "f, ax = plt.subplots(4, 4, figsize=(6.4,8), sharex='col',\n",
    "                     gridspec_kw={\"width_ratios\":[1, 1, 0.05, .5], \"height_ratios\":height_ratios, \"wspace\":0.03, \"hspace\":0.03})\n",
    "cY, cX = np.meshgrid(ctrl.t_lat, ctrl.time)\n",
    "lY, lX = np.meshgrid(lpd.TLAT.mean(axis=1), lpd.time)\n",
    "vex, ims = [2.5e16, 1.5e16, 2e16, .7e16], []\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Indian']):\n",
    "    kwargs = {'cmap':cmocean.cm.balance, 'vmin':-vex[i], 'vmax':vex[i]}\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    im = ax[i,0].pcolormesh(cX, cY, ctrl[key]-xr_quadtrend(ctrl[key]), **kwargs)\n",
    "    ims.append(im)\n",
    "    ax[i,1].pcolormesh(lX, lY, (lpd[key]-xr_quadtrend(lpd[key]))/100, **kwargs)\n",
    "    for j in [0,1,3]:  \n",
    "        ax[i,j].axhline(0, c='grey', lw=.5, ls='--')\n",
    "        ax[i,j].set_yticks(np.arange(-60,100,30))\n",
    "        ax[i,j].set_ylim(extents[i])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,0].text(60, extents[i][1]-10, ocean, c='g')\n",
    "    ax[i,0].set_ylabel('latitude')\n",
    "    \n",
    "    ax[i,3].plot((ctrl[key]-xr_quadtrend(ctrl[key])).std(dim='time')    , ctrl.t_lat, c='k')\n",
    "    ax[i,3].plot((lpd[key] -xr_quadtrend(lpd[key] )).std(dim='time')/100, lpd_lat   , c='k', ls='--')\n",
    "    ax[i,3].set_yticklabels([])\n",
    "    \n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,3])\n",
    "    \n",
    "    cb = f.colorbar(ims[i], cax=ax[i,2])#, ticks=np.arange(-3e16,4e16,1e16))\n",
    "    cb.outline.set_visible(False)\n",
    "    \n",
    "ax[0,0].text(60, -75, 'Southern Ocean', c='g')\n",
    "for j in range(2):\n",
    "    ax[0,j].axhline(-31.5, c='g', lw=.8)\n",
    "    ax[0,j].text(.5, 1.02, ['HIGH', 'LOW'][j], transform=ax[0,j].transAxes, ha='center')\n",
    "    ax[-1,j].set_xlabel('time [model years]')\n",
    "    ax[-1,-j-1].set_xlabel('[ZJ/m]')\n",
    "ax[0,3].text(.5, 1.02, 'st. dev.', transform=ax[0,3].transAxes, ha='center')\n",
    "    \n",
    "f.align_xlabels()\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_Hovmoeller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpd_lat = lpd.TLAT.mean(axis=1)\n",
    "extents = [(-78,90), (-34,70), (-34,70), (-34,30)]\n",
    "height_ratios = [a[1]-a[0] for a in extents]\n",
    "f, ax = plt.subplots(4, 4, figsize=(6.4,8), sharex='col',\n",
    "                     gridspec_kw={\"width_ratios\":[1, 1, 0.05, .5], \"height_ratios\":height_ratios, \"wspace\":0.03, \"hspace\":0.03})\n",
    "cY, cX = np.meshgrid(ctrl.t_lat, ctrl.time)\n",
    "lY, lX = np.meshgrid(lpd.TLAT.mean(axis=1), lpd.time)\n",
    "vex, ims = [2e16, 1.5e16, 1.5e16, .5e16], []\n",
    "for i, ocean in enumerate(['Global', 'Atlantic', 'Pacific', 'Indian']):\n",
    "    kwargs = {'cmap':cmocean.cm.balance, 'vmin':-vex[i], 'vmax':vex[i]}\n",
    "    key = f'OHC_zonal_{ocean}_Ocean'\n",
    "    im = ax[i,0].pcolormesh(cX, cY, lowpass(ctrl[key]-xr_quadtrend(ctrl[key]),13), **kwargs)\n",
    "    ims.append(im)\n",
    "    ax[i,1].pcolormesh(lX, lY, lowpass((lpd[key]-xr_quadtrend(lpd[key]))/100,13), **kwargs)\n",
    "    for j in [0,1,3]:  \n",
    "        ax[i,j].axhline(0, c='grey', lw=.5, ls='--')\n",
    "        ax[i,j].set_yticks(np.arange(-60,100,30))\n",
    "        ax[i,j].set_ylim(extents[i])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,0].text(60, extents[i][1]-10, ocean, c='g')\n",
    "    ax[i,0].set_ylabel('latitude')\n",
    "    \n",
    "    ax[i,3].plot(lowpass(ctrl[key]-xr_quadtrend(ctrl[key]),13).std(dim='time')    , ctrl.t_lat, c='k')\n",
    "    ax[i,3].plot(lowpass(lpd[key] -xr_quadtrend(lpd[key] ),13).std(dim='time')/100, lpd_lat   , c='k', ls='--')\n",
    "    ax[i,3].set_yticklabels([])\n",
    "    \n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,1])\n",
    "    ax[i,0].get_shared_y_axes().join(ax[i,0], ax[i,3])\n",
    "    \n",
    "    cb = f.colorbar(ims[i], cax=ax[i,2])#, ticks=np.arange(-3e16,4e16,1e16))\n",
    "    cb.outline.set_visible(False)\n",
    "    \n",
    "ax[0,0].text(60, -75, 'Southern Ocean', c='g')\n",
    "for j in range(2):\n",
    "    ax[0,j].axhline(-31.5, c='g', lw=.8)\n",
    "    ax[0,j].text(.5, 1.02, ['HIGH', 'LOW'][j], transform=ax[0,j].transAxes, ha='center')\n",
    "    ax[-1,j].set_xlabel('time [model years]')\n",
    "    ax[-1,-j-1].set_xlabel('[ZJ/m]')\n",
    "ax[0,3].text(.5, 1.02, 'st. dev.', transform=ax[0,3].transAxes, ha='center')\n",
    "    \n",
    "f.align_xlabels()\n",
    "plt.savefig(f'{path_results}/paper/OHC_zonal_Hovmoeller_lowpass13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gulf Stream Separation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1 = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False).TEMP[0,0,:,:]\n",
    "da2 = xr.open_dataset(file_ex_ocn_lpd , decode_times=False).TEMP[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,7))\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    da = [da1, da2][i]\n",
    "    lats = da.TLAT\n",
    "    lons = da.TLONG\n",
    "    \n",
    "    ax = fig.add_subplot(2, 1, i+1,\n",
    "                          projection=ccrs.NearsidePerspective(central_longitude=-70, central_latitude=35, satellite_height=357858))\n",
    "    ax.set_position([[.02,.52][i],.05,.46,.93])\n",
    "    im = ax.pcolormesh(lons, lats, da.values,\n",
    "                        cmap=cmocean.cm.balance, vmin=5, vmax=30,\n",
    "                        transform=ccrs.PlateCarree(),\n",
    "                        )\n",
    "        # grid\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False)\n",
    "    gl.ylocator = matplotlib.ticker.FixedLocator([-90, -60, -30, 0, 30, 60, 90])\n",
    "    gl.xlocator = matplotlib.ticker.FixedLocator([-180, -120, -60, 0, 60, 120, 180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 6: OHC horizontal integral Hovm√∂ller diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oceans = ['Global', 'Atlantic', 'Pacific', 'Southern']\n",
    "das = [ctrl_qd, lpd_qd]\n",
    "maxv = .06\n",
    "\n",
    "fig = plt.figure(figsize=(6.4,9), constrained_layout=True)\n",
    "gs0 = matplotlib.gridspec.GridSpec(4, 2, left=.1, right=.98, bottom=.11, top=.98, wspace=.05, hspace=.045)\n",
    "\n",
    "\n",
    "# if offset==True: x = (da-da.isel(time=slice(0,30)).mean(dim='time')).T/1e21\n",
    "\n",
    "for i, ocean in enumerate(oceans):\n",
    "    name = f'{ocean}_Ocean'    \n",
    "    \n",
    "    for j, da in enumerate([da1, da2]):\n",
    "        da = das[j][f'OHC_levels_{name}']\n",
    "        x = da.T/1e21\n",
    "#         X, Y = np.meshgrid(da.time, -da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j])\n",
    "        X, Y = np.meshgrid(da.time, da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j])\n",
    "        \n",
    "        gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,j], hspace=0)\n",
    "        ax_top = fig.add_subplot(gs00[0])\n",
    "        ax_top.set_ylim((-1500,0))\n",
    "        ax_top.set_xticks([])\n",
    "        ax_top.set_yticks([-1500, -1000, -500, 0])\n",
    "        \n",
    "        ax_bot = fig.add_subplot(gs00[1])\n",
    "        ax_bot.set_ylim((-6000,-1500))\n",
    "        ax_bot.set_yticks([-6000,-4500,-3000])\n",
    "                \n",
    "        for k, ax in enumerate([ax_top, ax_bot]):\n",
    "            im = ax.pcolormesh(X, -Y, x, vmin=-maxv, vmax=maxv, cmap=cmocean.cm.balance)\n",
    "        \n",
    "        if j==0:\n",
    "            ax_bot.set_ylabel(f'{ocean} Ocean', horizontalalignment = 'left')\n",
    "        \n",
    "        if j==1:\n",
    "            ax_top.set_yticks([])\n",
    "            ax_bot.set_yticks([])\n",
    "                \n",
    "        if i==0:\n",
    "            ax_top.text(.5,1.05,['HIGH', 'LOW'][j], transform=ax_top.transAxes)\n",
    "        if i==len(oceans)-1:\n",
    "            ax_bot.set_xlabel('time [model years]')\n",
    "        else:\n",
    "            ax_bot.set_xticks([])\n",
    "            \n",
    "            \n",
    "cax = fig.add_axes([0.1, 0.04, 0.88, 0.02])\n",
    "fig.colorbar(im, cax=cax, orientation='horizontal', label='OHC anomaly [ZJ/m]', extend='both')\n",
    "plt.savefig(f'{path_results}/paper/OHC_vertical_Hovmoeller_0-6km_ctrl_lpd_qd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oceans = ['Global', 'Atlantic', 'Pacific', 'Southern']\n",
    "das = [ctrl_qd, lpd_qd]\n",
    "maxv = .06\n",
    "\n",
    "fig = plt.figure(figsize=(6.4,9), constrained_layout=True)\n",
    "gs0 = matplotlib.gridspec.GridSpec(4, 2, left=.1, right=.98, bottom=.11, top=.98, wspace=.05, hspace=.045)\n",
    "\n",
    "\n",
    "# if offset==True: x = (da-da.isel(time=slice(0,30)).mean(dim='time')).T/1e21\n",
    "\n",
    "for i, ocean in enumerate(oceans):\n",
    "    name = f'{ocean}_Ocean'    \n",
    "    \n",
    "    for j, da in enumerate([da1, da2]):\n",
    "        da = das[j][f'OHC_levels_{name}']\n",
    "        x = da.T/1e21\n",
    "#         X, Y = np.meshgrid(da.time, -da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j])\n",
    "        X, Y = np.meshgrid(da.time, da.coords[['depth_t', 'z_t'][j]]/[1, 1e2][j])\n",
    "        \n",
    "        gs00 = matplotlib.gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[i,j], hspace=0)\n",
    "        ax_top = fig.add_subplot(gs00[0])\n",
    "        ax_top.set_ylim((-1500,0))\n",
    "        ax_top.set_xticks([])\n",
    "        ax_top.set_yticks([-1500, -1000, -500, 0])\n",
    "        \n",
    "        ax_bot = fig.add_subplot(gs00[1])\n",
    "        ax_bot.set_ylim((-6000,-1500))\n",
    "        ax_bot.set_yticks([-6000,-4500,-3000])\n",
    "                \n",
    "        for k, ax in enumerate([ax_top, ax_bot]):\n",
    "            im = ax.pcolormesh(X, -Y, lowpass(x.T,13).T, vmin=-maxv, vmax=maxv, cmap=cmocean.cm.balance)\n",
    "        \n",
    "        if j==0:\n",
    "            ax_bot.set_ylabel(f'{ocean} Ocean', horizontalalignment = 'left')\n",
    "        \n",
    "        if j==1:\n",
    "            ax_top.set_yticks([])\n",
    "            ax_bot.set_yticks([])\n",
    "                \n",
    "        if i==0:\n",
    "            ax_top.text(.5,1.05,['HIGH', 'LOW'][j], transform=ax_top.transAxes)\n",
    "        if i==len(oceans)-1:\n",
    "            ax_bot.set_xlabel('time [model years]')\n",
    "        else:\n",
    "            ax_bot.set_xticks([])\n",
    "            \n",
    "            \n",
    "cax = fig.add_axes([0.1, 0.04, 0.88, 0.02])\n",
    "fig.colorbar(im, cax=cax, orientation='horizontal', label='OHC anomaly [ZJ/m]', extend='both')\n",
    "# plt.savefig(f'{path_results}/paper/OHC_vertical_Hovmoeller_0-6km_ctrl_lpd_qd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: variances for different bandpass filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much area/volume do the major ocean basins represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xr_DataArrays import xr_DZ, xr_AREA\n",
    "from paths import file_RMASK_ocn\n",
    "from regions import regions_dict\n",
    "DZT = xr_DZ('ocn')\n",
    "AREA = xr_AREA('ocn')\n",
    "MASK = xr.open_dataarray(file_RMASK_ocn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = AREA.where(MASK>0).sum(dim=['nlat','nlon'],skipna=True).values\n",
    "total_volume = (DZT*AREA.where(MASK>0)).sum(dim=['z_t','nlat','nlon'],skipna=True).values\n",
    "print(f'total area {total_area} volume {total_volume}')\n",
    "for i in [1,2,6]:\n",
    "    area = AREA.where(MASK==i).sum(dim=['nlat','nlon'],skipna=True).values\n",
    "    volume = (DZT*AREA.where(MASK==i)).sum(dim=['z_t','nlat','nlon'],skipna=True).values\n",
    "    print(f'{regions_dict[i]:15}: area {area/total_area*100:2.0f}%; volume {volume/total_volume*100:2.0f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25.8+38.1+17.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26.8+41.2+17.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
