{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression patterns\n",
    "This notebook visualizes results from `SST_regression.py`.\n",
    "\n",
    "- mean map and correlation to obs\n",
    "- std of maps\n",
    "- stationarity test: correlations of maps with their mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot\n",
    "matplotlib.rc_file('../rc_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maps import regr_map\n",
    "from paths import path_samoc, path_results, file_ex_ocn_ctrl\n",
    "from timeseries import IterateOutputCESM\n",
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bc_analysis_fields import AnalyzeField as AF\n",
    "from bd_analysis_indices import AnalyzeIndex as AI\n",
    "from xr_regression import xr_quadtrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAD Regression patterns in (detrended) observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in ['AMO', 'SOM', 'TPI']:\n",
    "    ds = xr.open_dataset(f'{path_samoc}/SST/{idx}_regr_had.nc')\n",
    "    regr_map(ds=ds, index=idx, run='had', fn=f'{path_results}/SST/{idx}_regr_map_had')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean pattern for ctrl and lpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for j, run in enumerate(['ctrl', 'lpd']):\n",
    "    if run=='ctrl':   starts = np.arange(50, 151, 5)\n",
    "    elif run=='lpd':  starts = np.arange(154, 415, 10)\n",
    "        \n",
    "    for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        for k, t in enumerate(starts):\n",
    "            print(j,k,i)\n",
    "            tslice = (t, t+148)\n",
    "            fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "            ds_temp = xr.open_dataset(fn, decode_times=False)\n",
    "            ds_temp['start_year'] = tslice[0]\n",
    "            ds_temp = ds_temp.expand_dims('start_year')\n",
    "            ds_temp = ds_temp.set_coords('start_year', tslice[0])\n",
    "            if k==0:\n",
    "                ds = ds_temp\n",
    "            else:\n",
    "                ds = xr.concat([ds,ds_temp], dim='start_year')\n",
    "        ds.to_netcdf(f'{path_samoc}/SST/{idx}_regr_{run}_all_segments.nc')\n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean and std\n",
    "for j, run in enumerate(['ctrl', 'lpd']):\n",
    "    for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        print(run, idx)\n",
    "        fn = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments.nc'\n",
    "        da = xr.open_dataset(fn).slope\n",
    "        fn_new = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments_mean.nc'\n",
    "        da.mean(dim='start_year').to_netcdf(fn_new)\n",
    "        fn_new = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments_std.nc'\n",
    "        da.std(dim='start_year').to_netcdf(fn_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regions import boolean_mask, SST_index_bounds\n",
    "from maps import make_map, rect_polygon\n",
    "from plotting import discrete_cmap\n",
    "from paths import file_ex_ocn_lpd\n",
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting mean\n",
    "for j, run in enumerate(['ctrl', 'lpd']):\n",
    "    if run in ['ctrl', 'rcp']:   \n",
    "        domain = 'ocn'\n",
    "    elif run in ['lpd', 'lpi']:  \n",
    "        domain = 'ocn_low'\n",
    "        TLAT = xr.open_dataset(file_ex_ocn_lpd, decode_times=False).TLAT.coords['TLAT']\n",
    "        TLONG = xr.open_dataset(file_ex_ocn_lpd, decode_times=False).TLONG.coords['TLONG']\n",
    "        \n",
    "    MASK = boolean_mask(domain=domain, mask_nr=0)\n",
    "    \n",
    "    for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "        if idx in ['AMO', 'SOM']:\n",
    "            rects = rect_polygon(SST_index_bounds(idx))\n",
    "            clon = 300\n",
    "            nv = .4\n",
    "        elif idx=='TPI':\n",
    "            rects = [rect_polygon(SST_index_bounds('TPI1')),\n",
    "                     rect_polygon(SST_index_bounds('TPI2')),\n",
    "                     rect_polygon(SST_index_bounds('TPI3')),\n",
    "                    ]\n",
    "            clon = 200\n",
    "            nv = .3\n",
    "            \n",
    "        proj = 'rob'\n",
    "        cm = discrete_cmap(16, cmocean.cm.balance)    \n",
    "        label ='regression slope [K/K]'\n",
    "        text1 = f'SST({idx})\\nregr.'\n",
    "        text2 = f'{run.upper()}\\nmean'\n",
    "        if run in ['ctrl', 'rcp']:   domain = 'ocn_T'\n",
    "\n",
    "        # mean\n",
    "        fn = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments_mean.nc'\n",
    "        xa = xr.open_dataarray(fn)\n",
    "        if run=='lpd':\n",
    "            xa.coords['TLAT'] = TLAT\n",
    "            xa.coords['TLONG'] = TLONG\n",
    "        xa = xa.where(MASK)\n",
    "\n",
    "        fn_new = f'{path_results}/SST/{idx}_regr_map_{run}_all_segments_mean'\n",
    "        f, ax = make_map(xa=xa, domain=domain, proj=proj, cmap=cm, minv=-nv, maxv=nv,\n",
    "                     label=label, filename=fn_new, text1=text1, text2=text2,\n",
    "                     rects=rects, clon=clon)\n",
    "        \n",
    "        # std\n",
    "        text2 = f'{run.upper()}\\nstd'\n",
    "        nv = nv/5\n",
    "        fn = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments_std.nc'\n",
    "        xa = xr.open_dataarray(fn)\n",
    "        if run=='lpd':\n",
    "            xa.coords['TLAT'] = TLAT\n",
    "            xa.coords['TLONG'] = TLONG\n",
    "        xa = xa.where(MASK)        \n",
    "        \n",
    "        fn_new = f'{path_results}/SST/{idx}_regr_map_{run}_all_segments_std'\n",
    "        f, ax = make_map(xa=xa, domain=domain, proj=proj, cmap=cm, minv=-nv, maxv=nv,\n",
    "                     label=label, filename=fn_new, text1=text1, text2=text2,\n",
    "                     rects=rects, clon=clon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pattern correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(8,3), sharey=True, constrained_layout=True)\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):\n",
    "        fn = f'{path_samoc}/SST/{idx}_spatial_correlations_{run}.nc'\n",
    "        da = xr.open_dataarray(fn)\n",
    "        da.plot(label=idx, ax=ax[j])\n",
    "        ax[j].set_xlabel('starting year of segment')\n",
    "        ax[j].text(da.time[0], .7, run.upper())\n",
    "        ax[j].tick_params()\n",
    "        ax[j].axhline(0, c='k', lw=.3)\n",
    "\n",
    "ax[0].legend(ncol=3, loc=8)\n",
    "ax[0].set_ylabel('spatial correlation coefficient')\n",
    "plt.savefig(f'{path_results}/SST/spatial_correlation(t)_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity\n",
    "spatial correlation of segments with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import file_ex_ocn_ctrl\n",
    "from bc_analysis_fields import AnalyzeField as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, run in enumerate(['ctrl', 'lpd']):\n",
    "    if run=='ctrl':  TLAT = xr.open_dataset(file_ex_ocn_ctrl, decode_times=False).TLAT.coords['TLAT']\n",
    "\n",
    "    for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "#         region = [{'latitude':slice(1081,1858), 'longitude':slice( 500,1100)}, 1, 2][i]\n",
    "    \n",
    "        if run=='ctrl':   starts = np.arange(50, 151, 5)\n",
    "        elif run=='lpd':  starts = np.arange(154, 415, 10)\n",
    "        \n",
    "        da = xr.DataArray(data=np.zeros(len(starts)),\n",
    "                          coords={'time': starts},\n",
    "                          dims=('time'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        fn = f'{path_samoc}/SST/{idx}_regr_{run}_all_segments_mean.nc'\n",
    "        xa = xr.open_dataarray(fn)\n",
    "        for k, t in enumerate(starts):\n",
    "            print(i,j,k)\n",
    "            tslice = (t, t+148)\n",
    "            fn = f'{path_samoc}/SST/{idx}_regr_{run}_{tslice[0]}_{tslice[1]}.nc'\n",
    "            xa_temp = xr.open_dataset(fn, decode_times=False).slope\n",
    "            if run=='ctrl':\n",
    "                xa_temp.coords['TLAT'] = TLAT\n",
    "            \n",
    "            da.values[k] = AF().spatial_correlation(field_A=xa, field_B=xa_temp, selection=region)\n",
    "        da.to_netcdf(f'{path_samoc}/SST/{idx}_spatial_correlations_segments_to_mean_{run}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(8,3), sharey=True, constrained_layout=True)\n",
    "for i, idx in enumerate(['AMO', 'SOM', 'TPI']):\n",
    "    for j, run in enumerate(['ctrl', 'lpd']):\n",
    "        fn = f'{path_samoc}/SST/{idx}_spatial_correlations_segments_to_mean_{run}.nc'\n",
    "        da = xr.open_dataarray(fn)\n",
    "        da.plot(label=idx, ax=ax[j])\n",
    "        ax[j].set_xlabel('starting year of segment')\n",
    "        ax[j].text(da.time[0], .7, run.upper())\n",
    "        ax[j].tick_params()\n",
    "        ax[j].axhline(0, c='k', lw=.3)\n",
    "\n",
    "ax[0].legend(ncol=3, loc=8)\n",
    "ax[0].set_ylabel('spatial correlation coefficient')\n",
    "plt.savefig(f'{path_results}/SST/spatial_correlation(t)_segments_to_mean_ctrl_lpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
