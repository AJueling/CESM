{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacific variability - PDO / IPO\n",
    "\n",
    "original definition by _Mantua et al. (1997)_\n",
    "\n",
    "> The leading EOF of monthly SST anomalies over the North Pacific (after removing the global mean SST anomaly) and its associated PC time series are termed the Pacific Decadal Oscillation (PDO)\n",
    "\n",
    "---\n",
    "\n",
    "0. create xr dataarrays of monthly Pacific data only  (from rect data for high res)\n",
    "    1. North of 20 N\n",
    "    2. North of Equator\n",
    "    3. North of 38S\n",
    "\n",
    "1. deseasonalize, detrend monthly SST data  (emphasis on consistency with other data analysis and not necessarily original definition)\n",
    "    - HadISST:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. two factor detrending with natural and anthropogenic forcing estimates at each grid point\n",
    "    - CESM output:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. remove quadratic trend at each grid point  (for different time segment)\n",
    "\n",
    "2. EOF analysis of data\n",
    "\n",
    "3. create annual index, lowpass filter index\n",
    "\n",
    "4. analysis\n",
    "    - spectra\n",
    "    - regression patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cmocean\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from paths import path_results, path_samoc, path_prace, file_HadISST\n",
    "from filters import chebychev\n",
    "from regions import boolean_mask, global_ocean, gl_ocean_rect, gl_ocean_low, mask_box_in_region\n",
    "from timeseries import IterateOutputCESM\n",
    "from xr_DataArrays import xr_AREA\n",
    "from xr_regression import xr_quadtrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bd_analysis_indices import AnalyzeIndex as AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate monthly SST fields into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lpd:  18 mins, years 154-566, 2.3 GB\n",
    "# DS().generate_monthly_SST_files('ctrl')  # when all SST rect data available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load monthly and yearly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yearly ocn rect SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ctrl.nc')\n",
    "monthly_ctrl = monthly_ctrl.assign_coords(time=np.arange(1+1/24, 301, 1/12))\n",
    "monthly_lpd  = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_lpd.nc')  # proper datetime\n",
    "monthly_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 44.3 s\n",
    "# t_bins = np.arange(0,len(monthly_ctrl)+1,12)\n",
    "# yrly_ctrl = monthly_ctrl.groupby_bins('time', t_bins, right=False).mean(dim='time')\n",
    "# yrly_ctrl = yrly_ctrl.assign_coords(time_bins=np.arange(1, 301)).rename({'time_bins':'time'})\n",
    "# yrly_ctrl.to_netcdf(f'{path_prace}/SST/SST_yrly_rect_ctrl.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrly_ctrl = xr.open_dataarray(f'{path_prace}/SST_yrly_rect_ctrl.nc')\n",
    "yrly_lpd  = xr.open_dataarray(f'{path_samoc}/SST/SST_yrly_lpd.nc')\n",
    "yrly_had  = xr.open_dataarray(f'{path_samoc}/SST/SST_yrly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrly_ctrl.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. deseasonalize and detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deseasonalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(monthly_had.isel(time=slice(0,-1,12)).assign_coords(time=yrly_had.time)-yrly_had).mean(dim='time').plot()\n",
    "plt.title('avg January SST diff to yearly mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrlys    = [yrly_ctrl, yrly_lpd, yrly_had]\n",
    "monthlys = [monthly_ctrl, monthly_lpd, monthly_had]\n",
    "runs     = ['ctrl', 'lpd', 'had']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 1min 52s for ctrl\n",
    "# for i in range(1):\n",
    "#     print(runs[i])\n",
    "#     monthly = monthlys[i]\n",
    "#     yrly    = yrlys[i]\n",
    "#     assert len(monthly)/len(yrly) == 12.0\n",
    "#     temp = monthly.copy()\n",
    "#     for j in tqdm(range(12)):\n",
    "#         m = monthly.isel(time=slice(j,len(monthly)+1,12))\n",
    "#         temp[j::12] -= (m-yrly.assign_coords(time=m.time)).mean(dim='time')\n",
    "#     temp.to_netcdf(f'{path_prace}/SST/SST_monthly_deseasonalized_{runs[i]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_ctrl.nc')\n",
    "monthly_ds_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_lpd.nc' , decode_times=False)\n",
    "monthly_ds_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_ctrl[900:1100,100,100].plot()\n",
    "monthly_ctrl[900:1100,100,100].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctrl/lpd: quadratic detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1min 26s for lpd\n",
    "for i, da  in enumerate([monthly_ds_ctrl, monthly_ds_lpd]):\n",
    "    print(i)\n",
    "    if i==1: continue\n",
    "    (da-xr_quadtrend(da)).to_netcdf(f'{path_prace}/SST/SST_monthly_ds_dt_{[\"ctrl\",\"lpd\"][i]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_dt_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_dt_ctrl.nc')\n",
    "monthly_ds_dt_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_dt_lpd.nc' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detrending for different time segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### had: two-factor detrending with natural and anthropogenic forcing signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMM_natural = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_natural.nc', decode_times=False)\n",
    "MMM_anthro  = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_anthro.nc' , decode_times=False)\n",
    "monthly_MMM_natural = np.repeat(MMM_natural, 12)\n",
    "monthly_MMM_anthro  = np.repeat(MMM_anthro , 12)\n",
    "monthly_MMM_natural = monthly_MMM_natural.assign_coords(time=monthly_had.time)\n",
    "monthly_MMM_anthro  = monthly_MMM_anthro .assign_coords(time=monthly_had.time)\n",
    "monthly_MMM_natural.plot()\n",
    "monthly_MMM_anthro .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 04:38\n",
    "# forcings = monthly_MMM_natural.to_dataframe(name='natural').join(\n",
    "#             monthly_MMM_anthro.to_dataframe(name='anthro'))\n",
    "\n",
    "# SST_stacked = monthly_ds_had.stack(z=('latitude', 'longitude'))\n",
    "# ds_anthro   = SST_stacked[0,:].squeeze().copy()\n",
    "# ds_natural  = SST_stacked[0,:].squeeze().copy()\n",
    "\n",
    "# # multiple linear regression\n",
    "# X = sm.add_constant(forcings[['anthro', 'natural']])\n",
    "# for i, coordinate in tqdm(enumerate(SST_stacked.z)):\n",
    "#     y = SST_stacked[:, i].values\n",
    "#     model = sm.OLS(y, X).fit()\n",
    "#     ds_anthro[i] = model.params['anthro']\n",
    "#     ds_natural[i] = model.params['natural']\n",
    "\n",
    "# beta_anthro  = ds_anthro .unstack('z')\n",
    "# beta_natural = ds_natural.unstack('z')\n",
    "\n",
    "# ds = xr.merge([{'forcing_anthro': monthly_MMM_anthro}, {'beta_anthro': beta_anthro}])\n",
    "# ds.to_netcdf(f'{path_prace}/SST/SST_beta_anthro_MMM_monthly_had.nc')\n",
    "\n",
    "# ds = xr.merge([{'forcing_natural': monthly_MMM_natural}, {'beta_natural':beta_natural}])\n",
    "# ds.to_netcdf(f'{path_prace}/SST/SST_beta_natural_MMM_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "beta_natural.plot(ax=ax[0])\n",
    "beta_anthro.plot(ax=ax[1])\n",
    "ax[0].set_title('natural')\n",
    "ax[1].set_title('anthropogenic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monthly_ds_dt_had = monthly_ds_had.assign_coords(time=monthly_MMM_anthro.time) \\\n",
    "                    - beta_anthro*monthly_MMM_anthro \\\n",
    "                    - beta_natural*monthly_MMM_natural\n",
    "monthly_ds_dt_had.to_netcdf(f'{path_prace}/SST/SST_monthly_ds_tfdt_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_dt_had = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_tfdt_had.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EOF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subselect Pacific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_had(da):\n",
    "    \"\"\" shifts lons to [0,360] to make Pacific contiguous \"\"\"\n",
    "    return da.assign_coords(longitude=(da.longitude+360)%360).roll(longitude=180, roll_coords=True)\n",
    "\n",
    "def focus_data(da):\n",
    "    \"\"\" drops data outside rectangle around Pacific \"\"\"\n",
    "    if 't_lat' in da.coords:  # ctrl\n",
    "        lat, lon = 't_lat', 't_lon'\n",
    "    elif 'nlat' in da.coords:  # lpd\n",
    "        lat, lon = 'nlat', 'nlon'\n",
    "    elif 'latitude' in da.coords:  # had\n",
    "        lat, lon = 'latitude', 'longitude'\n",
    "    else:  raise ValueError('xr DataArray does not have the right lat/lon coords.')\n",
    "    da = da.dropna(dim=lat, how='all')\n",
    "    da = da.dropna(dim=lon, how='all')\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_had(monthly_ds_dt_had[0,:,:]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pacific Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_dt = [monthly_ds_dt_ctrl, monthly_ds_dt_lpd, monthly_ds_dt_had]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min 15s\n",
    "f, ax = plt.subplots(3,3, figsize=(12,8), sharex='col')\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    if extent=='38S':     latS, lonE = -38, 300\n",
    "    elif extent=='Eq':    latS, lonE =   0, 285\n",
    "    elif extent=='20N':   latS, lonE =  20, 255\n",
    "    for j, domain in enumerate(['ocn_rect', 'ocn_low', 'ocn_had']):\n",
    "        run = ['ctrl', 'lpd', 'had'][j]\n",
    "        da = monthly_ds_dt[j]\n",
    "        AREA = xr_AREA(domain=domain)\n",
    "        Pac_MASK = mask_box_in_region(domain=domain, mask_nr=2,\n",
    "                                      bounding_lats=(latS,68),\n",
    "                                      bounding_lons=(110,lonE))\n",
    "        area = AREA.where(Pac_MASK)\n",
    "        if j==2:  area = shift_had(area)\n",
    "        area = focus_data(area)\n",
    "        area.to_netcdf(f'{path_prace}/geometry/AREA_{extent}_{domain}.nc')\n",
    "        \n",
    "        Pac_MASK.plot(ax=ax[i,j])\n",
    "        print(f'{domain:10}, {extent:10}, {AREA.where(Pac_MASK).sum().values:5.2e}')\n",
    "        \n",
    "        da = da.where(Pac_MASK)\n",
    "        if j==2:  da = shift_had(da)\n",
    "        da = focus_data(da)\n",
    "        da.to_netcdf(f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_{run}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actual EOF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4:45 for 38S_ctrl, 5:07 for 38S_lpd, 3:42 for 38S_had : total 11:08\n",
    "# 2:50 for Eq_ctrl,  : total 11:08\n",
    "# total: 22min 19s\n",
    "for i, extent in tqdm(enumerate(['38S', 'Eq', '20N'])):\n",
    "    for j, domain in tqdm(enumerate(['ocn_rect', 'ocn_low', 'ocn_had'])):\n",
    "        run = ['ctrl', 'lpd', 'had'][j]\n",
    "        da = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_{run}.nc')\n",
    "        AREA = xr.open_dataarray(f'{path_prace}/geometry/AREA_{extent}_{domain}.nc')\n",
    "        fn = f'{path_prace}/SST/PMV_EOF_{extent}_{run}.nc'\n",
    "        AI().EOF_SST_analysis(xa=da, weights=AREA, neofs=1, npcs=1, fn=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eof, pc = PMV_EOF_indices(run='lpd', extent='20N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMV_38S_ctrl = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_38S_ctrl.nc', decode_times=False)\n",
    "PMV_38S_lpd  = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_38S_lpd.nc' , decode_times=False)\n",
    "PMV_38S_had  = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_38S_had.nc' , decode_times=False)\n",
    "PMV_Eq_ctrl  = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_Eq_ctrl.nc' , decode_times=False)\n",
    "PMV_Eq_lpd   = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_Eq_lpd.nc'  , decode_times=False)\n",
    "PMV_Eq_had   = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_Eq_had.nc'  , decode_times=False)\n",
    "PMV_20N_ctrl = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_20N_ctrl.nc', decode_times=False)\n",
    "PMV_20N_lpd  = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_20N_lpd.nc' , decode_times=False)\n",
    "PMV_20N_had  = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_20N_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPI_ctrl = xr.open_dataarray(f'{path_prace}/SST/TPI_ctrl.nc', decode_times=False)\n",
    "TPI_lpd  = xr.open_dataarray(f'{path_prace}/SST/TPI_lpd.nc' , decode_times=False)\n",
    "TPI_had  = xr.open_dataarray(f'{path_prace}/SST/TPI_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPI_had.time/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PMV_38S_ctrl.time[7:-7]    +100,  PMV_38S_ctrl.pcs[7:-7], c='C0', lw=2, ls='--', label='PC 38S')\n",
    "plt.plot(PMV_38S_ctrl.time[7:-7]    +100,  chebychev(PMV_38S_ctrl.pcs, 13*12)[7:-7], c='C0', lw=2, ls='--', label='PC 38S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.axhline(0, c='k', lw=.5)\n",
    "L11, = plt.plot(PMV_38S_ctrl.time[7:-7]    +100,  chebychev(PMV_38S_ctrl.pcs, 13*12)[7:-7], c='C0', lw=2, ls='--', label='PC 38S')\n",
    "L12, = plt.plot(PMV_38S_lpd .time[7:-7]/365+250,  chebychev(PMV_38S_lpd .pcs, 13*12)[7:-7], c='C1', lw=2, ls='--' )\n",
    "L13, = plt.plot(PMV_38S_had .time[7:-7]/365    ,  chebychev(PMV_38S_had .pcs, 13*12)[7:-7], c='C2', lw=2, ls='--' )\n",
    "L21, = plt.plot(PMV_Eq_ctrl .time[7:-7]    +100,  chebychev(PMV_Eq_ctrl .pcs, 13*12)[7:-7], c='C0', lw=2, ls=':' , label='PC Eq.')\n",
    "L22, = plt.plot(PMV_Eq_lpd  .time[7:-7]/365+250,  chebychev(PMV_Eq_lpd  .pcs, 13*12)[7:-7], c='C1', lw=2, ls=':'  )\n",
    "L23, = plt.plot(PMV_Eq_had  .time[7:-7]/365    ,  chebychev(PMV_Eq_had  .pcs, 13*12)[7:-7], c='C2', lw=2, ls=':'  )\n",
    "L31, = plt.plot(PMV_20N_ctrl.time[7:-7]    +100,  chebychev(PMV_20N_ctrl.pcs, 13*12)[7:-7], c='C0', lw=2, ls='-.' , label='PC 20N')\n",
    "L32, = plt.plot(PMV_20N_lpd .time[7:-7]/365+250, -chebychev(PMV_20N_lpd .pcs, 13*12)[7:-7], c='C1', lw=2, ls='-.'  )\n",
    "L33, = plt.plot(PMV_20N_had .time[7:-7]/365    ,  chebychev(PMV_20N_had .pcs, 13*12)[7:-7], c='C2', lw=2, ls='-.'  )\n",
    "\n",
    "L41, = plt.plot(TPI_ctrl.time[7:-7]/365+100, 5*chebychev(TPI_ctrl, 13)[7:-7]+1, c='C0', lw=2, ls='-', label='TPI')\n",
    "L42, = plt.plot(TPI_lpd .time[7:-7]/365+250, 5*chebychev(TPI_lpd , 13)[7:-7]+1, c='C1', lw=2, ls='-')\n",
    "L43, = plt.plot(TPI_had .time[7:-7]/365    , 5*chebychev(TPI_had , 13)[7:-7]+1, c='C2', lw=2, ls='-')\n",
    "\n",
    "plt.xlabel('time [years]')\n",
    "plt.ylabel('PDO/IPO/TPI indices')\n",
    "plt.legend(handles=[L11, L21, L31, L41], ncol=4)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'{path_results}/SST/SST_PMV_ctrl_rcp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# SST_rect_ctrl = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ctrl.nc', decode_times=False)\n",
    "# SST_rect_rcp  = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_rcp.nc' , decode_times=False)\n",
    "# SST_rect_ds_dt_ctrl = lowpass(lowpass(notch(SST_rect_ctrl, 12), 12), 12) - SST_gm_rect_ds_ctrl[:-7]\n",
    "# SST_rect_ds_dt_rcp  = lowpass(lowpass(notch(SST_rect_rcp , 12), 12), 12) - SST_gm_rect_ds_rcp[:-1]\n",
    "# SST_rect_ds_dt_ctrl.to_netcdf(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_ctrl.nc')\n",
    "# SST_rect_ds_dt_rcp .to_netcdf(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_rcp.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_rect_ds_dt_ctrl = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_ctrl.nc', decode_times=False)\n",
    "SST_rect_ds_dt_rcp  = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_rcp.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2:25 min\n",
    "# ds_20N_ctrl = lag_linregress_3D(Pac_20N_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_ctrl = lag_linregress_3D(Pac_38S_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "# ds_20N_rcp  = lag_linregress_3D(-Pac_20N_rcp.pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_rcp  = lag_linregress_3D(Pac_38S_rcp .pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [ds_20N_ctrl, ds_38S_ctrl]:\n",
    "    ds.attrs['first_year'] = 102\n",
    "    ds.attrs['last_year']  = 297\n",
    "for ds in [ds_20N_rcp, ds_38S_rcp]:\n",
    "    ds.attrs['first_year'] = 2002\n",
    "    ds.attrs['last_year']  = 2097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_20N_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_ctrl, index='PDO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_ctrl, index='IPO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_rcp, index='PDO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_rcp, index='IPO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartopy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
