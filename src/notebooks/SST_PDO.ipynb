{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacific variability - PDO / IPO\n",
    "\n",
    "original definition by _Mantua et al. (1997)_\n",
    "\n",
    "> The leading EOF of monthly SST anomalies over the North Pacific (after removing the global mean SST anomaly) and its associated PC time series are termed the Pacific Decadal Oscillation (PDO)\n",
    "\n",
    "---\n",
    "\n",
    "0. create xr dataarrays of monthly Pacific data only  (from rect data for high res)\n",
    "    1. North of 20 N\n",
    "    2. North of Equator\n",
    "    3. North of 38S\n",
    "\n",
    "1. deseasonalize, detrend monthly SST data  (emphasis on consistency with other data analysis and not necessarily original definition)\n",
    "    - HadISST:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. two factor detrending with natural and anthropogenic forcing estimates at each grid point\n",
    "    - CESM output:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. remove quadratic trend at each grid point  (for different time segment)\n",
    "\n",
    "2. EOF analysis of data\n",
    "\n",
    "3. create annual index, lowpass filter index\n",
    "\n",
    "4. analysis\n",
    "    - spectra\n",
    "    - regression patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cmocean\n",
    "import cartopy\n",
    "import warnings\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file')\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "from paths import path_results, path_prace, file_HadISST\n",
    "from filters import chebychev, lowpass\n",
    "from regions import boolean_mask, global_ocean, gl_ocean_rect, gl_ocean_low, mask_box_in_region\n",
    "from timeseries import IterateOutputCESM\n",
    "from xr_DataArrays import xr_AREA, dll_dims_names\n",
    "from xr_regression import xr_quadtrend\n",
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bd_analysis_indices import AnalyzeIndex as AI\n",
    "from SST_index_generation import times_ctrl, times_lpd, times_had"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data preparation\n",
    "\n",
    "- deseasonalize monthly simulation output:\n",
    "`DS().deseasonalize_monthly_data(run)`  (1min 52s for ctrl)\n",
    "- detrend quadratically monthly simulation output:\n",
    "`DS().detrend_monthly_data_pointwise(run)`  (ca 20min for ctrl, 4min 51s for lpd)\n",
    "- two factor detrending of monthly HadISST data:\n",
    "`DS().detrend_monthly_obs_two_factor()`  (4min 38sec)\n",
    "- subselecting Pacific data\n",
    "`DS().isolate_Pacific_SSTs(run, extent)`\n",
    "- EOF analysis\n",
    "`AI().Pacific_EOF_analysis(run, extent)`  (22min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "DS().isolate_Pacific_SSTs(run='ctrl', extent='20N', time=times_ctrl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_dt_ctrl_{times_ctrl[0][0]}_{times_ctrl[0][1]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = xr.open_dataarray(f'{path_prace}/geometry/AREA_20N_ocn_rect.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = monthly.where(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ctrl.nc')\n",
    "monthly_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_lpd.nc', decode_times=False)  # proper datetime\n",
    "monthly_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrly_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_rect_ctrl.nc')\n",
    "yrly_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_lpd.nc')\n",
    "yrly_had  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "monthly_ds_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_ctrl_51_301.nc')\n",
    "monthly_ds_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_lpd_154_404.nc' , decode_times=False)\n",
    "monthly_ds_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_ctrl[900:1200,100,100].plot()\n",
    "monthly_ctrl[900:1200,100,100].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. deseasonalize and detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_dt_had = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ds_tfdt_had.nc')\n",
    "beta_anthro  = xr.open_dataset(f'{path_prace}/SST/SST_beta_anthro_MMM_monthly_had.nc')\n",
    "beta_natural = xr.open_dataset(f'{path_prace}/SST/SST_beta_natural_MMM_monthly_had.nc')\n",
    "\n",
    "f, ax = plt.subplots(2,2, figsize=(8,5))\n",
    "beta_natural.forcing_natural.plot(ax=ax[0,0])\n",
    "beta_anthro. forcing_anthro .plot(ax=ax[0,1])\n",
    "beta_natural.beta_natural   .plot(ax=ax[1,0])\n",
    "beta_anthro. beta_anthro    .plot(ax=ax[1,1])\n",
    "ax[0,0].set_title('natural')\n",
    "ax[0,1].set_title('anthropogenic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EOF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subselect Pacific data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = plt.gca()\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    EOF_fns       = [[f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_had.nc']]\n",
    "    EOF_fns_yrly  = [[f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_had.nc']]\n",
    "    ax.text(-20, 35*i+25, extent)\n",
    "    ls = '-'\n",
    "    for j, domain in enumerate(['ocn_rect', 'ocn_low', 'ocn_had']):\n",
    "        (d, lat, lon) = dll_dims_names(['ocn_rect', 'ocn', 'ocn_had'][j])\n",
    "        if j==0: continue\n",
    "        c = f'C{j}'\n",
    "        tf = [1,365,365][j]  # time factor\n",
    "        to = [130,300,0][j]  # time offset\n",
    "        EOF_fns_ = EOF_fns[j]\n",
    "        EOF_fns_yrly_ = EOF_fns_yrly[j]\n",
    "        for k, fn in enumerate(EOF_fns_):\n",
    "            assert os.path.exists(fn)\n",
    "#             assert os.path.exists(EOF_fns_yrly_[k])\n",
    "            da = xr.open_dataset(fn, decode_times=False).pcs\n",
    "            ax.plot(da.time/tf+to, lowpass(da,5*12)+3*k+35*i, c=c, ls=ls)\n",
    "for i in range(3):\n",
    "    ax.text([70, 300, 575][i], 105, ['OBS', 'HIGH', 'LOW'][i])\n",
    "    plt.yticks([])\n",
    "plt.ylim((-4,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPI_ctrl = xr.open_dataarray(f'{path_prace}/SST/TPI_ctrl.nc', decode_times=False)\n",
    "TPI_lpd  = xr.open_dataarray(f'{path_prace}/SST/TPI_lpd_154_404.nc' , decode_times=False)\n",
    "TPI_had  = xr.open_dataarray(f'{path_prace}/SST/TPI_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = plt.gca()\n",
    "for i in range(4):\n",
    "    ax.axhline(i, c='grey', lw=.5)\n",
    "TPI_fns = [f'{path_prace}/SST/TPI_ctrl.nc',\n",
    "           f'{path_prace}/SST/TPI_lpd.nc', \n",
    "           f'{path_prace}/SST/TPI_had.nc']\n",
    "for i, fn in enumerate(TPI_fns):\n",
    "    tf = [1,365,365][i]  # time factor\n",
    "    to = [130,300,0][i]  # time offset\n",
    "    da = xr.open_dataarray(fn, decode_times=False)\n",
    "    ax.plot(da.time[:250]/365+to, 4*da[:250]+3, c=f'C{i}', lw=.3, alpha=.3)\n",
    "    ax.plot(da.time[:250]/365+to, 4*lowpass(da[:250],13)+3, c=f'C{i}')\n",
    "    \n",
    "labels = []\n",
    "\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    EOF_fns       = [f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_51_301.nc',\n",
    "                     f'{path_prace}/SST/PMV_EOF_{extent}_lpd_154_404.nc',\n",
    "                     f'{path_prace}/SST/PMV_EOF_{extent}_had.nc']\n",
    "    for j, fn in enumerate(EOF_fns):\n",
    "        (d, lat, lon) = dll_dims_names(['ocn_rect', 'ocn', 'ocn_had'][j])\n",
    "        tf = [1,365,365][j]  # time factor\n",
    "        to = [130,300,0][j]  # time offset\n",
    "        da = xr.open_dataset(fn, decode_times=False).pcs\n",
    "        ax.plot(da.time/tf+to, da+i, c=f'C{j}', lw=.3, alpha=.3)\n",
    "        ax.plot(da.time/tf+to, lowpass(da,13*12)+i, c=f'C{j}')\n",
    "    ax.text([70, 300, 575][i], 3.7, ['OBS', 'HIGH', 'LOW'][i])\n",
    "    labels.append(f'PC(>{extent})')\n",
    "labels.append('TPI (x4)')\n",
    "\n",
    "plt.xlim((-30,750))\n",
    "plt.ylim((-.8,4))\n",
    "ax.set_yticks(range(4))\n",
    "ax.set_yticklabels(labels)\n",
    "plt.xlabel('time [years]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bb_analysis_timeseries import AnalyzeTimeSeries as ATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(8,8), sharex=True, sharey=True)\n",
    "\n",
    "for i, extent in enumerate(['20N', 'Eq', '38S']):\n",
    "    EOF_fns = [f'{path_prace}/SST/PMV_EOF_{extent}_had.nc',\n",
    "               f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_51_301.nc',\n",
    "               f'{path_prace}/SST/PMV_EOF_{extent}_lpd_154_404.nc']\n",
    "    ax[i,0].set_ylabel(extent)\n",
    "    for j, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "#         if i>0 or j>0:  continue\n",
    "        ax[i,j].axvline(1/5/12, c='grey', lw=.5)\n",
    "        ax[i,j].set_xscale('log')\n",
    "        ax[i,j].set_yscale('log')\n",
    "        ts = xr.open_dataset(EOF_fns[j], decode_times=False).pcs.squeeze()\n",
    "        if j>0:  ts = ts.assign_coords(time=ts.time.values/365)\n",
    "            \n",
    "#         f, Pxx_den = sp.signal.welch(ts.values)\n",
    "#         ax[i,j].plot(f, Pxx_den, ls=':', c='C1')\n",
    "#         f, Pxx_den = sp.signal.welch(lowpass(ts,5).values)\n",
    "#         ax[i,j].plot(f, Pxx_den, ls=':', c='C1')\n",
    "        \n",
    "        (spec, freq, _) = ATS(ts).spectrum()\n",
    "        ax[i,j].plot(freq, spec, c='C0')\n",
    "        (spec, freq, _) = ATS(lowpass(ts,5*12)).spectrum()\n",
    "        ax[i,j].plot(freq, spec, c='C0')\n",
    "        AR_spectrum = ATS(ts).mc_ar1_spectrum(filter_type=None, filter_cutoff=None)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[0,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[2,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[3,:], ls='--', c='C3', lw=.5)\n",
    "        \n",
    "        AR_spectrum = ATS(ts).mc_ar1_spectrum(filter_type='lowpass', filter_cutoff=5*12)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[0,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[2,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[3,:], ls='--', c='C3', lw=.5)\n",
    "        if i==0:\n",
    "            ax[i,j].set_title(['HIST', 'HIGH', 'LOW'][j])\n",
    "            ax[2,j].set_xlabel(r'frequency [month$^{-1}$]')\n",
    "#         ax[i,j].set_xlim((2,120))\n",
    "        ax[i,j].set_ylim((1e-2,2e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(8,8), sharex=True, sharey=True)\n",
    "\n",
    "for i, extent in enumerate(['20N', 'Eq', '38S']):\n",
    "    EOF_fns = [f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_had.nc',\n",
    "               f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_ctrl_51_301.nc',\n",
    "               f'{path_prace}/SST/PMV_EOF_{extent}_raw_yrly_lpd_154_404.nc']\n",
    "    ax[i,0].set_ylabel(extent)\n",
    "    for j, run in enumerate(['had', 'ctrl', 'lpd']):\n",
    "#         if i>0 or j>0:  continue\n",
    "        ax[i,j].axvline(1/5, c='grey', lw=.5)\n",
    "        ax[i,j].set_xscale('log')\n",
    "        ax[i,j].set_yscale('log')\n",
    "        ts = xr.open_dataarray(EOF_fns[j], decode_times=False).squeeze()\n",
    "        if j>0:  ts = ts.assign_coords(time=ts.time.values/365)\n",
    "            \n",
    "#         f, Pxx_den = sp.signal.welch(ts.values)\n",
    "#         ax[i,j].plot(f, Pxx_den, ls=':', c='C1')\n",
    "#         f, Pxx_den = sp.signal.welch(lowpass(ts,5).values)\n",
    "#         ax[i,j].plot(f, Pxx_den, ls=':', c='C1')\n",
    "        \n",
    "        (spec, freq, _) = ATS(ts).spectrum()\n",
    "        ax[i,j].plot(freq, spec, c='C0')\n",
    "        (spec, freq, _) = ATS(lowpass(ts,5)).spectrum()\n",
    "        ax[i,j].plot(freq, spec, c='C0')\n",
    "        AR_spectrum = ATS(ts).mc_ar1_spectrum(filter_type=None, filter_cutoff=None)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[0,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[2,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[3,:], ls='--', c='C3', lw=.5)\n",
    "        \n",
    "        AR_spectrum = ATS(ts).mc_ar1_spectrum(filter_type='lowpass', filter_cutoff=5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[0,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[2,:], ls='--', c='C3', lw=.5)\n",
    "        ax[i,j].plot(AR_spectrum[1,:], AR_spectrum[3,:], ls='--', c='C3', lw=.5)\n",
    "        if i==0:\n",
    "            ax[i,j].set_title(['HIST', 'HIGH', 'LOW'][j])\n",
    "            ax[2,j].set_xlabel(r'frequency [year$^{-1}$]')\n",
    "#         ax[i,j].set_xlim((2,120))\n",
    "        ax[i,j].set_ylim((1e-2,5e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autocorrelation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bc_analysis_fields import AnalyzeField as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ctrl: create yrly files of segments\n",
    "for i, run in enumerate(['ctrl', 'lpd']):\n",
    "    for j, time in enumerate([times_ctrl, times_lpd][i]):\n",
    "        print(time)\n",
    "        fn     = f'{path_prace}/SST/SST_monthly_ds_dt_{run}_{time[0]}_{time[1]}.nc'\n",
    "        fn_out = f'{path_prace}/SST/SST_yrly_from_monthly_ds_dt_{run}_{time[0]}_{time[1]}.nc'\n",
    "        DS().generate_yrly_SST_ctrl_rect(fn=fn, fn_out=fn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ctrl.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST regression plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# SST_rect_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_rect_ctrl.nc', decode_times=False)\n",
    "# SST_rect_rcp  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_rect_rcp.nc' , decode_times=False)\n",
    "# SST_rect_ds_dt_ctrl = lowpass(lowpass(notch(SST_rect_ctrl, 12), 12), 12) - SST_gm_rect_ds_ctrl[:-7]\n",
    "# SST_rect_ds_dt_rcp  = lowpass(lowpass(notch(SST_rect_rcp , 12), 12), 12) - SST_gm_rect_ds_rcp[:-1]\n",
    "# SST_rect_ds_dt_ctrl.to_netcdf(f'{path_prace}/SST/SST_monthly_rect_ds_dt_ctrl.nc')\n",
    "# SST_rect_ds_dt_rcp .to_netcdf(f'{path_prace}/SST/SST_monthly_rect_ds_dt_rcp.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_rect_ds_dt_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_rect_ds_dt_ctrl.nc', decode_times=False)\n",
    "SST_rect_ds_dt_rcp  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_rect_ds_dt_rcp.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2:25 min\n",
    "# ds_20N_ctrl = lag_linregress_3D(Pac_20N_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_ctrl = lag_linregress_3D(Pac_38S_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "# ds_20N_rcp  = lag_linregress_3D(-Pac_20N_rcp.pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_rcp  = lag_linregress_3D(Pac_38S_rcp .pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [ds_20N_ctrl, ds_38S_ctrl]:\n",
    "    ds.attrs['first_year'] = 102\n",
    "    ds.attrs['last_year']  = 297\n",
    "for ds in [ds_20N_rcp, ds_38S_rcp]:\n",
    "    ds.attrs['first_year'] = 2002\n",
    "    ds.attrs['last_year']  = 2097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_20N_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_ctrl, index='PDO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_ctrl, index='IPO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_rcp, index='PDO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_rcp, index='IPO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartopy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
