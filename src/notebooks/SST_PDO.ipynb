{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacific variability - PDO / IPO\n",
    "\n",
    "original definition by _Mantua et al. (1997)_\n",
    "\n",
    "> The leading EOF of monthly SST anomalies over the North Pacific (after removing the global mean SST anomaly) and its associated PC time series are termed the Pacific Decadal Oscillation (PDO)\n",
    "\n",
    "---\n",
    "\n",
    "0. create xr dataarrays of monthly Pacific data only  (from rect data for high res)\n",
    "    1. North of 20 N\n",
    "    2. North of Equator\n",
    "    3. North of 38S\n",
    "\n",
    "1. deseasonalize, detrend monthly SST data  (emphasis on consistency with other data analysis and not necessarily original definition)\n",
    "    - HadISST:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. two factor detrending with natural and anthropogenic forcing estimates at each grid point\n",
    "    - CESM output:\n",
    "        1. calculate monthly deviations (i.e. average difference) from annual mean, then remove this seasonal cycle\n",
    "        2. remove quadratic trend at each grid point  (for different time segment)\n",
    "\n",
    "2. EOF analysis of data\n",
    "\n",
    "3. create annual index, lowpass filter index\n",
    "\n",
    "4. analysis\n",
    "    - spectra\n",
    "    - regression patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cmocean\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "matplotlib.rc_file('../rc_file')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport - numpy - scipy - matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from paths import path_results, path_samoc, path_prace, file_HadISST\n",
    "from filters import chebychev, lowpass\n",
    "from regions import boolean_mask, global_ocean, gl_ocean_rect, gl_ocean_low, mask_box_in_region\n",
    "from timeseries import IterateOutputCESM\n",
    "from xr_DataArrays import xr_AREA, dll_dims_names\n",
    "from xr_regression import xr_quadtrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ab_derivation_SST import times_ctrl, times_lpd\n",
    "from ab_derivation_SST import DeriveSST as DS\n",
    "from bd_analysis_indices import AnalyzeIndex as AI\n",
    "print(times_ctrl)\n",
    "print(times_lpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data preparation\n",
    "\n",
    "- concatenate monthly SST fields into single file:\n",
    "`DS().generate_monthly_SST_files('ctrl')  # when all SST rect data available` (lpd:  18 mins, years 154-566, 2.3 GB)\n",
    "- generate yrly avg file for ocn_rect ctrl data:\n",
    "`DS().generate_yrly_SST_ctrl_rect()`  (43 sec)\n",
    "- deseasonalize:\n",
    "`DS().deseasonalize_monthly_data(run)`  (1min 52s for ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_ctrl.nc')\n",
    "monthly_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_lpd.nc')  # proper datetime\n",
    "monthly_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrly_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_rect_ctrl.nc')\n",
    "yrly_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_lpd.nc')\n",
    "yrly_had  = xr.open_dataarray(f'{path_prace}/SST/SST_yrly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_ctrl = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_ctrl.nc')\n",
    "monthly_ds_lpd  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_lpd.nc' , decode_times=False)\n",
    "monthly_ds_had  = xr.open_dataarray(f'{path_prace}/SST/SST_monthly_deseasonalized_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ds_ctrl[900:1200,100,100].plot()\n",
    "monthly_ctrl[900:1200,100,100].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. deseasonalize and detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctrl/lpd: quadratic detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 24min 3s total\n",
    "# # 4min 51s for lpd\n",
    "# for i, da  in enumerate([monthly_ds_ctrl, monthly_ds_lpd]):\n",
    "#     if i==1:  continue\n",
    "#     print(i)\n",
    "#     run = [\"ctrl\",\"lpd\"][i]\n",
    "#     times = [times_ctrl, times_lpd][i]\n",
    "#     for j in tqdm(range(len(times))):\n",
    "#         if j==0:  continue\n",
    "#         time = times[j]\n",
    "        \n",
    "#         if i==0:     # ctrl\n",
    "#             print(i, j)\n",
    "#             da_sel = da.sel(time=slice(time[0], time[1]))\n",
    "#             if time[0]<100:  # fix February of year 99 by interpolating Jan and Mar, something went wrong with the high to low res interpolation\n",
    "#                 print('time[0]<100')\n",
    "#                 da_sel.sel(time=99+1/8, method='nearest').values = (da_sel.sel(time=99+1/24, method='nearest').values\\\n",
    "#                                                                     +da_sel.sel(time=99+5/24, method='nearest').values)/2\n",
    "#             else:  continue\n",
    "        \n",
    "#         elif i==1:   # lpd\n",
    "#             da_sel = da.sel(time=slice(time[0]*365, time[1]*365))#+1e-4))\n",
    "#             if len(da_sel.time) not in [1788, 3000]:\n",
    "#                 da_sel = da.sel(time=slice(time[0]*365, time[1]*365+1e-4))\n",
    "#             y1, y2 = int(time[0]/365), int(time[0]/365)\n",
    "            \n",
    "#         print(time, time[0], time[1], len(da_sel.time), da_sel.time[0].values, da_sel.time[-1].values)\n",
    "#         (da_sel-xr_quadtrend(da_sel)).to_netcdf(f'{path_prace}/SST/SST_monthly_ds_dt_{run}_{time[0]}_{time[1]}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### had: two-factor detrending with natural and anthropogenic forcing signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMM_natural = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_natural.nc', decode_times=False)\n",
    "MMM_anthro  = xr.open_dataarray(f'{path_samoc}/GMST/CMIP5_anthro.nc' , decode_times=False)\n",
    "monthly_MMM_natural = np.repeat(MMM_natural, 12)\n",
    "monthly_MMM_anthro  = np.repeat(MMM_anthro , 12)\n",
    "monthly_MMM_natural = monthly_MMM_natural.assign_coords(time=monthly_had.time)\n",
    "monthly_MMM_anthro  = monthly_MMM_anthro .assign_coords(time=monthly_had.time)\n",
    "monthly_MMM_natural.plot()\n",
    "monthly_MMM_anthro .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 04:38\n",
    "# forcings = monthly_MMM_natural.to_dataframe(name='natural').join(\n",
    "#             monthly_MMM_anthro.to_dataframe(name='anthro'))\n",
    "\n",
    "# SST_stacked = monthly_ds_had.stack(z=('latitude', 'longitude'))\n",
    "# ds_anthro   = SST_stacked[0,:].squeeze().copy()\n",
    "# ds_natural  = SST_stacked[0,:].squeeze().copy()\n",
    "\n",
    "# # multiple linear regression\n",
    "# X = sm.add_constant(forcings[['anthro', 'natural']])\n",
    "# for i, coordinate in tqdm(enumerate(SST_stacked.z)):\n",
    "#     y = SST_stacked[:, i].values\n",
    "#     model = sm.OLS(y, X).fit()\n",
    "#     ds_anthro[i] = model.params['anthro']\n",
    "#     ds_natural[i] = model.params['natural']\n",
    "\n",
    "# beta_anthro  = ds_anthro .unstack('z')\n",
    "# beta_natural = ds_natural.unstack('z')\n",
    "\n",
    "# ds = xr.merge([{'forcing_anthro': monthly_MMM_anthro}, {'beta_anthro': beta_anthro}])\n",
    "# ds.to_netcdf(f'{path_prace}/SST/SST_beta_anthro_MMM_monthly_had.nc')\n",
    "\n",
    "# ds = xr.merge([{'forcing_natural': monthly_MMM_natural}, {'beta_natural':beta_natural}])\n",
    "# ds.to_netcdf(f'{path_prace}/SST/SST_beta_natural_MMM_monthly_had.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "beta_natural.plot(ax=ax[0])\n",
    "beta_anthro.plot(ax=ax[1])\n",
    "ax[0].set_title('natural')\n",
    "ax[1].set_title('anthropogenic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monthly_ds_dt_had = monthly_ds_had.assign_coords(time=monthly_MMM_anthro.time) \\\n",
    "                    - beta_anthro*monthly_MMM_anthro \\\n",
    "                    - beta_natural*monthly_MMM_natural\n",
    "monthly_ds_dt_had.to_netcdf(f'{path_prace}/SST/SST_monthly_ds_tfdt_had.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EOF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subselect Pacific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_had(da):\n",
    "    \"\"\" shifts lons to [0,360] to make Pacific contiguous \"\"\"\n",
    "    return da.assign_coords(longitude=(da.longitude+360)%360).roll(longitude=180, roll_coords=True)\n",
    "\n",
    "def focus_data(da):\n",
    "    \"\"\" drops data outside rectangle around Pacific \"\"\"\n",
    "    if 't_lat' in da.coords:  # ctrl\n",
    "        lat, lon = 't_lat', 't_lon'\n",
    "    elif 'nlat' in da.coords:  # lpd\n",
    "        lat, lon = 'nlat', 'nlon'\n",
    "    elif 'latitude' in da.coords:  # had\n",
    "        lat, lon = 'latitude', 'longitude'\n",
    "    else:  raise ValueError('xr DataArray does not have the right lat/lon coords.')\n",
    "    da = da.dropna(dim=lat, how='all')\n",
    "    da = da.dropna(dim=lon, how='all')\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4min 15s\n",
    "f, ax = plt.subplots(3,3, figsize=(12,8), sharex='col')\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    if extent=='38S':     latS, lonE = -38, 300\n",
    "    elif extent=='Eq':    latS, lonE =   0, 285\n",
    "    elif extent=='20N':   latS, lonE =  20, 255\n",
    "    for j, domain in enumerate(['ocn_rect', 'ocn_low', 'ocn_had']):\n",
    "        run = ['ctrl', 'lpd', 'had'][j]\n",
    "        AREA = xr_AREA(domain=domain)\n",
    "        Pac_MASK = mask_box_in_region(domain=domain, mask_nr=2,\n",
    "                                      bounding_lats=(latS,68),\n",
    "                                      bounding_lons=(110,lonE))\n",
    "        area = AREA.where(Pac_MASK)\n",
    "        if j==2:  area = shift_had(area)\n",
    "        area = focus_data(area)\n",
    "        area.to_netcdf(f'{path_prace}/geometry/AREA_{extent}_{domain}.nc')\n",
    "        Pac_MASK.plot(ax=ax[i,j])\n",
    "        print(f'{domain:10}, {extent:10}, {AREA.where(Pac_MASK).sum().values:5.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # ca 15 mins per extent\n",
    "# monthly_ds_dt = [[f'{path_prace}/SST/SST_monthly_ds_dt_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "#                  [f'{path_prace}/SST/SST_monthly_ds_dt_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "#                  [f'{path_prace}/SST/SST_monthly_ds_tfdt_had.nc']]\n",
    "\n",
    "# for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "#     if i>0: continue\n",
    "#     for j, domain in enumerate(['ocn_rect', 'ocn_low', 'ocn_had']):\n",
    "#         if j>0: continue\n",
    "#         run = ['ctrl', 'lpd', 'had'][j]\n",
    "#         area = xr.open_dataarray(f'{path_prace}/geometry/AREA_{extent}_{domain}.nc')\n",
    "#         monthly_fns = monthly_ds_dt[j]\n",
    "#         for k, fn in tqdm(enumerate(monthly_fns)):\n",
    "#             if k<10: continue\n",
    "#             da = xr.open_dataarray(fn)\n",
    "#             if j==2: da = shift_had(da)\n",
    "#             da = focus_data(da)\n",
    "#             da = da.where(area)\n",
    "#             if j<2:\n",
    "#                 time = [times_ctrl, times_lpd][j][k]\n",
    "#                 fn = f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_{run}_{time[0]}_{time[1]}.nc'\n",
    "#             else:\n",
    "#                 fn = f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_{run}.nc'\n",
    "#             da.to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actual EOF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 4:45 for 38S_ctrl, 5:07 for 38S_lpd, 3:42 for 38S_had : total 11:08\n",
    "# # 2:50 for Eq_ctrl,  : total 11:08\n",
    "# # total: 22min 19s\n",
    "# for i, extent in tqdm(enumerate(['38S', 'Eq', '20N'])):\n",
    "#     if i!=0:  continue\n",
    "#     monthly_ds_dt = [[f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "#                      [f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "#                      [f'{path_prace}/SST/SST_monthly_ds_dt_{extent}_had.nc']]\n",
    "    \n",
    "#     EOF_fns       = [[f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "#                      [f'{path_prace}/SST/PMV_EOF_{extent}_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "#                      [f'{path_prace}/SST/PMV_EOF_{extent}_had.nc']]\n",
    "    \n",
    "#     for j, domain in tqdm(enumerate(['ocn_rect', 'ocn_low', 'ocn_had'])):\n",
    "#         if j>0:  continue\n",
    "#         area = xr.open_dataarray(f'{path_prace}/geometry/AREA_{extent}_{domain}.nc')\n",
    "#         monthly_fns = monthly_ds_dt[j]\n",
    "#         for k, fn in tqdm(enumerate(monthly_fns)):\n",
    "#             if k > 4 and k<10: continue\n",
    "#             fn = monthly_fns[k]\n",
    "#             fn_EOF = EOF_fns[j][k]\n",
    "#             da = xr.open_dataarray(fn)\n",
    "#             AI().EOF_SST_analysis(xa=da, weights=area, neofs=1, npcs=1, fn=fn_EOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_38S_lpd_154_404.nc').eofs\n",
    "da.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.open_dataset(f'{path_prace}/SST/PMV_EOF_20N_lpd_154_404.nc').eofs\n",
    "da.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if files are present\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.gca()\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    EOF_fns       = [[f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_{time[0]}_{time[1]}.nc' for time in times_ctrl],\n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_lpd_{time[0]}_{time[1]}.nc' for time in times_lpd], \n",
    "                     [f'{path_prace}/SST/PMV_EOF_{extent}_had.nc']]\n",
    "    ax.text(-20, 35*i+25, extent)\n",
    "    ls = '-'\n",
    "    for j, domain in enumerate(['ocn_rect', 'ocn_low', 'ocn_had']):\n",
    "        (d, lat, lon) = dll_dims_names(['ocn_rect', 'ocn', 'ocn_had'][j])\n",
    "        c = f'C{j}'\n",
    "        tf = [1,365,365][j]  # time factor\n",
    "        to = [130,300,0][j]  # time offset\n",
    "        EOF_fns_ = EOF_fns[j]\n",
    "        for k, fn in enumerate(EOF_fns_):\n",
    "            assert os.path.exists(fn)\n",
    "            cov = xr.open_dataset(fn, decode_times=False).eofs.mean(dim=[lat,lon])\n",
    "            if cov<0:  factor=-1\n",
    "            else:      factor= 1\n",
    "            if j==1 and i==2: factor = factor*-1\n",
    "            da = xr.open_dataset(fn, decode_times=False).pcs*factor\n",
    "            ax.plot(da.time/tf+to, lowpass(da,5*12)+3*k+35*i, c=c, ls=ls)\n",
    "for i in range(3):\n",
    "    ax.text([70, 300, 575][i], 105, ['OBS', 'HIGH', 'LOW'][i])\n",
    "    plt.yticks([])\n",
    "plt.ylim((-4,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPI_ctrl = xr.open_dataarray(f'{path_prace}/SST/TPI_ctrl.nc', decode_times=False)\n",
    "TPI_lpd  = xr.open_dataarray(f'{path_prace}/SST/TPI_lpd.nc' , decode_times=False)\n",
    "TPI_had  = xr.open_dataarray(f'{path_prace}/SST/TPI_had.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = plt.gca()\n",
    "for i in range(4):\n",
    "    ax.axhline(i, c='grey', lw=.5)\n",
    "TPI_fns = [f'{path_prace}/SST/TPI_ctrl.nc',\n",
    "           f'{path_prace}/SST/TPI_lpd.nc', \n",
    "           f'{path_prace}/SST/TPI_had.nc']\n",
    "for i, fn in enumerate(TPI_fns):\n",
    "    tf = [1,365,365][i]  # time factor\n",
    "    to = [130,300,0][i]  # time offset\n",
    "    da = xr.open_dataarray(fn, decode_times=False)\n",
    "    ax.plot(da.time[:250]/365+to, 4*lowpass(da[:250],13)+3, c=f'C{i}')\n",
    "labels = []\n",
    "\n",
    "for i, extent in enumerate(['38S', 'Eq', '20N']):\n",
    "    EOF_fns       = [f'{path_prace}/SST/PMV_EOF_{extent}_ctrl_51_301.nc',\n",
    "                     f'{path_prace}/SST/PMV_EOF_{extent}_lpd_154_404.nc',\n",
    "                     f'{path_prace}/SST/PMV_EOF_{extent}_had.nc']\n",
    "    for j, fn in enumerate(EOF_fns):\n",
    "        (d, lat, lon) = dll_dims_names(['ocn_rect', 'ocn', 'ocn_had'][j])\n",
    "        tf = [1,365,365][j]  # time factor\n",
    "        to = [130,300,0][j]  # time offset\n",
    "        cov = xr.open_dataset(fn, decode_times=False).eofs.mean(dim=[lat,lon])\n",
    "        if cov<0:  factor=-1\n",
    "        else:      factor= 1\n",
    "        if j==1 and i==2: factor = factor*-1\n",
    "        if j==2 and i==2: factor = factor*-1\n",
    "        da = xr.open_dataset(fn, decode_times=False).pcs*factor\n",
    "        ax.plot(da.time/tf+to, lowpass(da,13*12)+i, c=f'C{j}')\n",
    "    ax.text([70, 300, 575][i], 3.7, ['OBS', 'HIGH', 'LOW'][i])\n",
    "    labels.append(f'PC(>{extent})')\n",
    "labels.append('TPI (x4)')\n",
    "\n",
    "plt.xlim((-70,750))\n",
    "plt.ylim((-1,4))\n",
    "ax.set_yticks(range(4))\n",
    "ax.set_yticklabels(labels)\n",
    "plt.xlabel('time [years]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# SST_rect_ctrl = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ctrl.nc', decode_times=False)\n",
    "# SST_rect_rcp  = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_rcp.nc' , decode_times=False)\n",
    "# SST_rect_ds_dt_ctrl = lowpass(lowpass(notch(SST_rect_ctrl, 12), 12), 12) - SST_gm_rect_ds_ctrl[:-7]\n",
    "# SST_rect_ds_dt_rcp  = lowpass(lowpass(notch(SST_rect_rcp , 12), 12), 12) - SST_gm_rect_ds_rcp[:-1]\n",
    "# SST_rect_ds_dt_ctrl.to_netcdf(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_ctrl.nc')\n",
    "# SST_rect_ds_dt_rcp .to_netcdf(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_rcp.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_rect_ds_dt_ctrl = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_ctrl.nc', decode_times=False)\n",
    "SST_rect_ds_dt_rcp  = xr.open_dataarray(f'{path_samoc}/SST/SST_monthly_rect_ds_dt_rcp.nc' , decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2:25 min\n",
    "# ds_20N_ctrl = lag_linregress_3D(Pac_20N_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_ctrl = lag_linregress_3D(Pac_38S_ctrl.pcs[:-7,0], SST_rect_ds_dt_ctrl[24:-(24+7)], dof_corr=1./(12*13))\n",
    "# ds_20N_rcp  = lag_linregress_3D(-Pac_20N_rcp.pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n",
    "ds_38S_rcp  = lag_linregress_3D(Pac_38S_rcp .pcs[:-7,0], SST_rect_ds_dt_rcp [24:-(24+7)], dof_corr=1./(12*13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [ds_20N_ctrl, ds_38S_ctrl]:\n",
    "    ds.attrs['first_year'] = 102\n",
    "    ds.attrs['last_year']  = 297\n",
    "for ds in [ds_20N_rcp, ds_38S_rcp]:\n",
    "    ds.attrs['first_year'] = 2002\n",
    "    ds.attrs['last_year']  = 2097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_20N_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_ctrl, index='PDO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_ctrl, index='IPO', run='ctrl', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_20N_rcp, index='PDO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_map(ds=ds_38S_rcp, index='IPO', run='rcp', fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartopy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
